{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate using sample questions: Llama Stack vs. LlamaIndex\n",
    "\n",
    "This notebook starts with sample questions and reference answers in the format generated by [make-sample-questions.ipynb](./make-sample-questions.ipynb). It then does the following:\n",
    "\n",
    "1. It runs RAG with Llama Stack to generate answers.\n",
    "2. It runs RAG with LlamaIndex to generate answers.\n",
    "3. It uses Ragas to evaluate the outputs given the generated answers, and the reference answers.  This step depends on having a very powerful model to do the evaluation.  We are using gpt-4o for that purpose.\n",
    "4. It determines whether the results are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation_utilities\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import copy\n",
    "import importlib\n",
    "\n",
    "from ragas.metrics import (\n",
    "    AnswerAccuracy,\n",
    ")\n",
    "from ragas.metrics._domain_specific_rubrics import RubricsScore\n",
    "\n",
    "from llama_index.llms.openai import OpenAI as LlamaIndexOpenAI\n",
    "from ragas.llms import LlamaIndexLLMWrapper\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.ibm import WatsonxLLM\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.types import UserMessage\n",
    "from llama_stack_client import RAGDocument\n",
    "from llama_stack_client import Agent\n",
    "\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation_utilities' from '/Users/bmurdock/lls-comparisons/evaluation_utilities.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rerun this cell whenever you change evaluation_utilities\n",
    "importlib.reload(evaluation_utilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and initialize models\n",
    "\n",
    "The main configuration options for this notebook are in the following cell, so you may want to edit some values there before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_id': 'meta-llama/llama-3-3-70b-instruct',\n",
       "  'project_id': 'cef5787a-161d-47e0-a549-2a7ecf2fb355',\n",
       "  'max_new_tokens': 4096,\n",
       "  'additional_params': {'time_limit': 10000}}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reuse_client and max_retries are useful for preventing Ragas from failing due to rate limiting\n",
    "EVALUATOR_MODEL={\"model\": \"gpt-4o\", \"reuse_client\": False, \"max_retries\": 10}\n",
    "\n",
    "EMBED_MODEL_ID_FOR_LLAMAINDEX=\"ibm-granite/granite-embedding-125m-english\"\n",
    "EMBED_MODEL_ID_FOR_LLAMA_STACK=\"granite-embedding-125m\"\n",
    "\n",
    "WATSONX_PROJECT_ID=os.environ.get(\"WATSONX_PROJECT_ID\")\n",
    "\n",
    "LLAMA_INDEX_RAG_MODELS_INFO_WATSONX= [ {\"model_id\": \"meta-llama/llama-3-3-70b-instruct\", \"project_id\": WATSONX_PROJECT_ID, \"max_new_tokens\": 4096, \"additional_params\": {\"time_limit\": 10000}}]\n",
    "LLAMA_STACK_RAG_MODELS_INFO_WATSONX = [\"meta-llama/llama-3-3-70b-instruct\"]\n",
    "\n",
    "\n",
    "CONTENT_URLS=[\"https://www.ibm.com/downloads/documents/us-en/1227c12d3a38b173\"]\n",
    "CONTENT_LOCATION=\"./docs/\"\n",
    "\n",
    "TEST_DATA_FILES = [\"questions_and_reference_answers-ibm-50-10-1495.json\"]\n",
    "\n",
    "NUMBER_OF_SEARCH_RESULTS=5\n",
    "\n",
    "LLAMA_INDEX_RAG_MODELS_INFO_WATSONX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_watsonx_ai.client:Client successfully initialized\n",
      "INFO:httpx:HTTP Request: GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-05-21&project_id=cef5787a-161d-47e0-a549-2a7ecf2fb355&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200 \"HTTP/1.1 200 OK\"\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-05-21&project_id=cef5787a-161d-47e0-a549-2a7ecf2fb355&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: ibm-granite/granite-embedding-125m-english\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LLAMA_INDEX_RAG_MODELS = {}\n",
    "for info in LLAMA_INDEX_RAG_MODELS_INFO_WATSONX:\n",
    "    model_id = info[\"model_id\"]\n",
    "    watsonx_llm = WatsonxLLM(**info)\n",
    "    LLAMA_INDEX_RAG_MODELS[model_id] = watsonx_llm\n",
    "\n",
    "EMBED_MODEL_FOR_LLAMAINDEX = HuggingFaceEmbedding(model_name=EMBED_MODEL_ID_FOR_LLAMAINDEX)\n",
    "\n",
    "evaluator_model = LlamaIndexOpenAI(**EVALUATOR_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WatsonxLLM(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x330304310>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x11e0cd6c0>, completion_to_prompt=<function default_completion_to_prompt at 0x11e5e7380>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model_id='meta-llama/llama-3-3-70b-instruct', deployment_id=None, temperature=None, max_new_tokens=4096, additional_params={'time_limit': 10000}, project_id='cef5787a-161d-47e0-a549-2a7ecf2fb355', space_id=None, url=SecretStr('**********'), apikey=SecretStr('**********'), token=None, password=None, username=None, instance_id=None, version=None, verify=None, validate_model=True, persistent_connection=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLAMA_INDEX_RAG_MODELS[\"meta-llama/llama-3-3-70b-instruct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: World War I, also known as the Great War, began in 1914 and was the result of a complex interplay of factors that had been building up over several decades. Here are some of the key reasons why the war started:\n",
      "\n",
      "1. **Assassination of Archduke Franz Ferdinand**: The immediate catalyst for the war was the assassination of Archduke Franz Ferdinand of Austria-Hungary and his wife, Sophie, on June 28, 1914, by Gavrilo Princip, a Bosnian Serb nationalist. This event set off a chain reaction of diplomatic and military mobilizations.\n",
      "\n",
      "2. **Alliance System**: Europe was divided into two major alliance systems. The Triple Entente, consisting of France, Russia, and the United Kingdom, and the Triple Alliance, made up of Germany, Austria-Hungary, and Italy. These alliances were meant to provide mutual defense and deter aggression, but they also meant that a conflict involving one country could quickly involve others.\n",
      "\n",
      "3. **Militarism**: There was a significant build-up of military forces and an arms race, particularly between Germany and the United Kingdom. This militarism created an environment where war was seen as a viable means of resolving disputes and achieving national goals.\n",
      "\n",
      "4. **Nationalism**: Nationalistic fervor was on the rise across Europe, with various ethnic groups seeking independence or greater autonomy. This was particularly pronounced in the Balkans, where Slavic nationalism threatened the stability of Austria-Hungary.\n",
      "\n",
      "5. **Imperial Rivalries**: European powers were competing for colonies and influence around the world. This imperial competition created tensions and conflicts, particularly in Africa and Asia, which contributed to the overall climate of hostility.\n",
      "\n",
      "6. **Crisis Management Failures**: The diplomatic crisis following the assassination of Franz Ferdinand was poorly managed. Austria-Hungary, with the backing of Germany, issued an ultimatum to Serbia, which led to a series of mobilizations and declarations of war.\n",
      "\n",
      "7. **The July Crisis**: The month following the assassination saw a series of diplomatic failures and miscommunications, known as the July Crisis. Austria-Hungary's declaration of war on Serbia on July 28, 1914, set off a chain reaction of alliances being activated, leading to a full-scale war.\n",
      "\n",
      "These factors, among others, created a volatile situation in Europe that ultimately led to the outbreak of World War I. The war lasted until 1918 and resulted in significant political, social, and economic changes worldwide.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"Explain why WW1 started\"),\n",
    "]\n",
    "print(evaluator_model.chat(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bmurdock/lls-comparisons/venv-llscomp-311/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/base_model_inference.py:1172: UserWarning: Parameters [max_new_tokens] is/are not recognized and will be ignored.\n",
      "  warn(invalid_params_warning)\n",
      "INFO:httpx:HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/chat?version=2025-05-21 \"HTTP/1.1 200 OK\"\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished chat for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/chat?version=2025-05-21'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/llama-3-3-70b-instruct: assistant: The start of World War I was a complex and multifaceted event, involving various factors and parties. \n",
      "\n",
      "One major factor was the system of alliances between European countries, including the Triple Entente (France, Britain, and Russia) and the Triple Alliance (Germany, Austria-Hungary, and Italy). These alliances created a situation in which a small conflict between two countries could quickly escalate into a larger war.\n",
      "\n",
      "Another key factor was the rise of nationalism and imperialism in various European countries, which led to increased tensions and competition for resources and territory. The Balkans, in particular, were a region of significant tension, with various ethnic and national groups seeking independence or greater autonomy.\n",
      "\n",
      "The immediate trigger for the war was the assassination of Archduke Franz Ferdinand, the heir to the throne of Austria-Hungary, by a group of Serbian nationalists in June 1914. This event led Austria-Hungary to declare war on Serbia, which in turn led Russia to mobilize its military in support of Serbia. Germany, allied with Austria-Hungary, declared war on Russia and France, and Britain eventually entered the war in support of France.\n",
      "\n",
      "Overall, the start of World War I was the result of a combination of factors, including the complex system of alliances, the rise of nationalism and imperialism, and the spark of the Archduke's assassination.\n"
     ]
    }
   ],
   "source": [
    "for label, model in LLAMA_INDEX_RAG_MODELS.items():\n",
    "    print(f\"{label}: {model.chat(messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/inference/chat-completion \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello World!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = LlamaStackClient(base_url=\"http://localhost:8321\", timeout=12000)\n",
    "\n",
    "message = UserMessage(\n",
    "    content=\"Say 'Hello World'\",\n",
    "    role=\"user\",\n",
    ")\n",
    "client.inference.chat_completion(\n",
    "    model_id=LLAMA_STACK_RAG_MODELS_INFO_WATSONX[0],\n",
    "    messages=[message],\n",
    "    stream=False\n",
    ").completion_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the evaluation questions with reference answers\n",
    "\n",
    "This loads the outputs of [make-sample-questions.ipynb](./make-sample-questions.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'user_input': \"Based on IBM's 2024 Annual Report, how might the company's financial performance and strategic initiatives influence its ability to sustain or increase dividend payouts to shareholders?\",\n",
       "  'reference': \"Based on IBM's 2024 Annual Report, the company's financial performance and strategic initiatives appear to support its ability to sustain or potentially increase dividend payouts to shareholders. Here are some key points from the report that influence this assessment:\\n\\n1. **Revenue Growth and Cash Flow**: IBM reported $62.8 billion in revenue, with a 3% increase at constant currency, and generated $12.7 billion in free cash flow, an increase of $1.5 billion year-over-year. Strong revenue growth and cash flow generation provide a solid foundation for sustaining dividend payouts.\\n\\n2. **Investment in Growth Areas**: IBM has made significant investments in AI and hybrid cloud, which are expected to drive future growth. The company allocated over $7 billion to research and development and completed 11 acquisitions to enhance its capabilities. These strategic initiatives are likely to contribute to long-term revenue growth and profitability, supporting dividend sustainability.\\n\\n3. **Profitability and Margin Expansion**: IBM expanded its operating gross profit margin by 130 basis points in 2024, driven by a focus on high-value offerings and productivity initiatives. Improved profitability and margin expansion enhance the company's ability to generate cash, which can be used for dividend payments.\\n\\n4. **Shareholder Returns**: In 2024, IBM returned more than $6 billion to shareholders through dividends. This demonstrates the company's commitment to returning value to shareholders and suggests a focus on maintaining or potentially increasing dividend payouts.\\n\\n5. **Strong Operating Performance**: The operating (non-GAAP) pre-tax income from continuing operations increased by 8.7% year-over-year, and the operating (non-GAAP) pre-tax margin increased by 1.2 points to 17.9%. This strong operating performance indicates a healthy financial position, supporting dividend payments.\\n\\nOverall, IBM's strategic focus on growth areas, strong cash flow generation, and commitment to shareholder returns suggest that the company is well-positioned to sustain or potentially increase its dividend payouts in the future.\",\n",
       "  'reference_contexts': ['## Dear\\xa0IBM\\xa0Investor:\\n\\nIn 2024, IBM made significant progress\\xa0in\\xa0becoming\\xa0a\\xa0higher\\xa0growth, higher\\xa0margin\\xa0business.\\xa0We\\xa0made\\xa0this progress\\xa0by\\xa0combining\\xa0technology innovation\\xa0and\\xa0consulting\\xa0expertise to\\xa0drive\\xa0growth,\\xa0improve\\xa0productivity, and enhance operational efficiency -for\\xa0our\\xa0clients,\\xa0and\\xa0our\\xa0own\\xa0company.\\n\\nOur\\xa0strategy\\xa0continues\\xa0to\\xa0build\\xa0upon\\xa0the\\xa0two\\xa0technological foundations\\xa0of\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud,\\xa0which\\xa0clients\\xa0need\\xa0to unlock\\xa0the\\xa0full\\xa0value\\xa0of\\xa0their\\xa0data.\\xa0We\\xa0have\\xa0made\\xa0a\\xa0series\\xa0of investments\\xa0to\\xa0accelerate\\xa0the\\xa0delivery\\xa0of\\xa0that\\xa0value\\xa0to\\xa0our clients,\\xa0from\\xa0transforming\\xa0the\\xa0way\\xa0we\\xa0work\\xa0to\\xa0reorienting\\xa0our portfolio around powerful, AI-based solutions.\\n\\nAs\\xa0this\\xa0report\\xa0demonstrates,\\xa0these\\xa0investments\\xa0are\\xa0paying off,\\xa0delivering\\xa0meaningful\\xa0returns\\xa0for\\xa0our\\xa0shareholders, clients, and partners. Today, IBM is a software-led, fully integrated\\xa0platform\\xa0company,\\xa0built\\xa0to\\xa0grow\\xa0sustainably.\\xa0This is\\xa0the\\xa0ROI\\xa0of\\xa0IBM.',\n",
       "   \"## 2024\\xa0Performance\\n\\nFor\\xa0the\\xa0year,\\xa0IBM\\xa0generated\\xa0$62.8\\xa0billion\\xa0in\\xa0revenue,\\xa0up\\xa03% at\\xa0constant\\xa0currency,\\xa0and\\xa0$12.7\\xa0billion\\xa0in\\xa0free\\xa0cash\\xa0flow\\xa0-\\xa0an increase of $1.5 billion year-over-year. Our generative AI book\\xa0of\\xa0business\\xa0now\\xa0stands\\xa0at\\xa0more\\xa0than\\xa0$5\\xa0billion\\xa0since inception.\\xa0This\\xa0revenue\\xa0growth\\xa0and\\xa0cash\\xa0generation\\xa0enabled us to make significant investments in the business and deliver value\\xa0to\\xa0our\\xa0shareholders.\\xa0In\\xa02024,\\xa0we\\xa0allocated\\xa0more\\xa0than\\xa0$7 billion\\xa0to\\xa0research\\xa0and\\xa0development,\\xa0closed\\xa011\\xa0acquisitions to\\xa0enhance\\xa0our\\xa0capabilities,\\xa0and\\xa0returned\\xa0more\\xa0than\\xa0$6\\xa0billion\\n\\nto\\xa0shareholders\\xa0through\\xa0dividends.\\xa0IBM\\xa0expanded\\xa0operating gross profit margin by 130 basis points in 2024, driven by a focus on high-value offerings and productivity initiatives.\\n\\nSoftware revenue\\xa0grew\\xa09%\\xa0at\\xa0constant\\xa0currency,\\xa0reflecting strong\\xa0demand\\xa0for\\xa0our\\xa0advanced\\xa0capabilities\\xa0in\\xa0hybrid\\xa0cloud, data\\xa0and\\xa0AI,\\xa0automation,\\xa0transaction\\xa0processing,\\xa0and\\xa0security. Red\\xa0Hat\\xa0performed\\xa0well\\xa0as\\xa0clients\\xa0embraced\\xa0its\\xa0open\\xa0hybrid cloud\\xa0platform.\\n\\nConsulting revenue\\xa0increased\\xa01%\\xa0at\\xa0constant\\xa0currency, demonstrating\\xa0our\\xa0clients'\\xa0continued\\xa0need\\xa0for\\xa0expertise\\xa0in\\xa0AI deployment,\\xa0digital\\xa0transformation,\\xa0and\\xa0cloud\\xa0modernization, despite\\xa0a\\xa0dynamic\\xa0market\\xa0environment.\\n\\nIBM\\xa0has\\xa0established\\xa0an\\xa0early\\xa0leadership\\xa0position\\xa0in\\xa0this regard,\\xa0building\\xa0a\\xa0portfolio\\xa0of\\xa0enterprise\\xa0AI\\xa0offerings\\xa0focused on\\xa0generating\\xa0ROI\\xa0through\\xa0productivity\\xa0improvements\\xa0and automation.\\xa0IBM\\xa0watsonx\\xa0provides\\xa0a\\xa0robust\\xa0portfolio\\xa0of AI\\xa0products\\xa0for\\xa0developing\\xa0AI\\xa0apps,\\xa0managing\\xa0data,\\xa0and governing\\xa0the\\xa0entire\\xa0lifecycle\\xa0of\\xa0AI\\xa0models.\\xa0AI\\xa0assistants manage\\xa0key\\xa0tasks,\\xa0including\\xa0customer\\xa0service\\xa0and\\xa0writing code. We are developing pre-built AI agents that deliver multitask reasoning for specific business domains. And our Granite family of fit-for-purpose AI models, when tuned with proprietary data, can deliver enterprise-grade generative AI with up to 90% improved cost efficiency. Granite allows clients to\\xa0bring\\xa0their\\xa0own\\xa0data\\xa0into\\xa0the\\xa0models,\\xa0and\\xa0can\\xa0be\\xa0trained\\xa0on that\\xa0data\\xa0in\\xa0weeks,\\xa0not\\xa0months.\\n\\nInfrastructure revenue\\xa0declined\\xa03%\\xa0at\\xa0constant\\xa0currency,\\xa0in line\\xa0with\\xa0product\\xa0cycle\\xa0expectations.\\xa0IBM\\xa0z16\\xa0is\\xa0now\\xa0the\\xa0most successful\\xa0mainframe\\xa0program\\xa0in\\xa0our\\xa0history,\\xa0highlighting\\xa0its enduring\\xa0value\\xa0to\\xa0clients.\",\n",
       "   \"## Financial Performance Summary\\n\\nIn 2024, we reported $62.8 billion in revenue, income from continuing operations of $6.0 billion, which includes the impact of the pension  settlement  charges  of  $3.1  billion  ($2.4  billion  net  of  tax),  and  operating  (non-GAAP)  earnings  of  $9.7  billion,  which excludes the impact of the pension settlement charges. Refer to 'Organization of Information,' for additional information. Diluted earnings per share from continuing operations was $6.42 as reported, including an impact of $2.57 from the pension settlement charges, and diluted earnings per share was $10.33 on an operating (non-GAAP) basis. We generated $13.4 billion in cash from operations  and  $12.7  billion  in  free  cash  flow,  and  returned  $6.1  billion  to  shareholders  in  dividends.  We  are  pleased  with  the progress we made in 2024, delivering revenue growth in our re-positioned business and strong cash flow generation. Our 2024 performance demonstrates the success of our focused strategy, enhanced portfolio and sustainable revenue growth. We increased our  investment  in  innovation  and  talent  and  completed  eleven  acquisitions  in  2024,  strengthening  our  hybrid  cloud  and  AI capabilities, all while continuing to return value to shareholders through our dividend.\\n\\nTotal revenue grew 1.4 percent year to year as reported and 3 percent adjusted for currency compared to the prior year, led by our Software performance. Software revenue increased 8.3 percent as reported and 9.0 percent adjusted for currency, with strength across our portfolio. Hybrid Platform &amp; Solutions increased 8.1 percent as reported and 8.7 percent adjusted for currency, reflecting growth across all lines of business with double-digit revenue growth in Red Hat and Automation. Transaction Processing increased 8.7 percent as reported and 9.6 percent adjusted for currency, with growth in both recurring and transactional revenue. Consulting revenue decreased 0.9 percent as reported but grew 0.6 percent adjusted for currency, and continued to be impacted by a dynamic market environment as clients reprioritized spending. Infrastructure decreased 3.9 percent year to year as reported and 2.7 percent adjusted for currency, reflecting product cycle dynamics.\\n\\nFrom  a  geographic  perspective,  Americas  revenue  decreased  1.3  percent  year  to  year  as  reported  (0.7  percent  adjusted  for currency).  Europe/Middle East/Africa (EMEA) increased 5.1 percent as reported (4.7 percent adjusted for currency). Asia Pacific grew 3.0 percent as reported (7.9 percent adjusted for currency).\\n\\nGross  margin  of  56.7  percent  increased  1.2  points  year  to  year,  with  continued  margin  expansion  driven  by  portfolio  mix  and ongoing productivity initiatives. Operating (non-GAAP) gross margin of 57.8 percent increased 1.3 points versus the prior year, due to the same dynamics.\\n\\nTotal expense and other (income) increased 16.2 percent in 2024 versus the prior year primarily driven by the pension settlement charges of $3.1 billion in 2024, higher spending reflecting our continued investment in portfolio innovation to drive our strategy and higher  workforce rebalancing charges. This was partially offset by a gain from the sale of certain QRadar Software-as-a-Service (SaaS) assets, the gain on the divestiture of The Weather Company assets, the benefits from productivity and the actions taken to transform  our  operations,  and  the  effects  of  currency.  Total  operating  (non-GAAP)  expense  and  other  (income)  increased  1.8 percent year to year, driven primarily by the factors described above, excluding the pension settlement charges.\\n\\nPre-tax income from continuing operations was $5.8 billion in 2024 compared with $8.7 billion in the prior year and pre-tax margin was  9.2  percent,  a  decrease  of  4.8  points  versus  2023.  The  year-to-year  performance  was  primarily  driven  by  the  pension settlement charges in 2024 partially offset by our gross margin expansion and the benefits from productivity and the actions taken to transform our operations which enabled investments to drive innovation. The continuing operations effective tax rate for 2024 was (3.8) percent compared to 13.5 percent in 2023. The current-year effective tax rate was primarily driven by the tax impact of the pension settlement charges and the resolution of certain tax audit matters. Net income from continuing operations was $6.0 billion in 2024 compared with $7.5 billion in the prior year and net income from continuing operations margin was 9.6 percent, a decrease of 2.6 points year to year. Operating (non-GAAP) pre-tax income from continuing operations of $11.2 billion increased 8.7 percent year to year and the operating (non-GAAP) pre-tax margin from continuing operations increased 1.2 points to 17.9 percent. Our revenue growth, portfolio mix and productivity initiatives resulted in strong operating (non-GAAP) pre-tax income growth in 2024 compared to the prior year. The operating (non-GAAP) effective tax rate for 2024 was 13.6 percent compared to 14.0 percent\"]},\n",
       " {'user_input': 'Based on the trends and projections outlined in the IBM 2024 Annual Report, what strategic initiatives is IBM likely to prioritize to enhance its competitive position in the technology sector over the next five years?',\n",
       "  'reference': 'Based on the trends and projections outlined in the IBM 2024 Annual Report, IBM is likely to prioritize the following strategic initiatives to enhance its competitive position in the technology sector over the next five years:\\n\\n1. **Focus on AI and Hybrid Cloud**: IBM will continue to build upon its technological foundations of AI and hybrid cloud, as these are seen as transformative technologies that unlock the full value of data for clients. This includes further development and deployment of AI solutions like watsonx and the Granite family of AI models.\\n\\n2. **Expansion of Software and Consulting Services**: With approximately 75 percent of its business mix in Software and Consulting, IBM will likely continue to expand these areas. This includes enhancing its software offerings, particularly in hybrid cloud, data and AI, automation, and security, as well as growing its consulting services to support AI deployment and digital transformation.\\n\\n3. **Investment in Research and Development**: IBM allocated more than $7 billion to research and development in 2024, and this trend is likely to continue. This investment will support innovation in AI, hybrid cloud, and other high-value offerings.\\n\\n4. **Acquisitions and Partnerships**: IBM closed 11 acquisitions in 2024 to enhance its capabilities. Continuing this strategy will help IBM expand its technological expertise and market reach. Additionally, maintaining a broad ecosystem of partners and alliances will be crucial for delivering integrated solutions.\\n\\n5. **Enhancing Operational Efficiency and Productivity**: IBM aims to improve productivity and operational efficiency, both for itself and its clients. This includes leveraging AI for automation and productivity improvements, as well as optimizing IT spending and reducing operational complexity through solutions like OpenShift and Ansible.\\n\\n6. **Sustainable Growth and Value Delivery**: IBM is focused on becoming a software-led, fully integrated platform company built for sustainable growth. This involves delivering meaningful returns for shareholders, clients, and partners through strategic investments and innovation.\\n\\nBy prioritizing these initiatives, IBM aims to strengthen its leadership position in the technology sector and drive long-term growth.',\n",
       "  'reference_contexts': [\"## 2024\\xa0Performance\\n\\nFor\\xa0the\\xa0year,\\xa0IBM\\xa0generated\\xa0$62.8\\xa0billion\\xa0in\\xa0revenue,\\xa0up\\xa03% at\\xa0constant\\xa0currency,\\xa0and\\xa0$12.7\\xa0billion\\xa0in\\xa0free\\xa0cash\\xa0flow\\xa0-\\xa0an increase of $1.5 billion year-over-year. Our generative AI book\\xa0of\\xa0business\\xa0now\\xa0stands\\xa0at\\xa0more\\xa0than\\xa0$5\\xa0billion\\xa0since inception.\\xa0This\\xa0revenue\\xa0growth\\xa0and\\xa0cash\\xa0generation\\xa0enabled us to make significant investments in the business and deliver value\\xa0to\\xa0our\\xa0shareholders.\\xa0In\\xa02024,\\xa0we\\xa0allocated\\xa0more\\xa0than\\xa0$7 billion\\xa0to\\xa0research\\xa0and\\xa0development,\\xa0closed\\xa011\\xa0acquisitions to\\xa0enhance\\xa0our\\xa0capabilities,\\xa0and\\xa0returned\\xa0more\\xa0than\\xa0$6\\xa0billion\\n\\nto\\xa0shareholders\\xa0through\\xa0dividends.\\xa0IBM\\xa0expanded\\xa0operating gross profit margin by 130 basis points in 2024, driven by a focus on high-value offerings and productivity initiatives.\\n\\nSoftware revenue\\xa0grew\\xa09%\\xa0at\\xa0constant\\xa0currency,\\xa0reflecting strong\\xa0demand\\xa0for\\xa0our\\xa0advanced\\xa0capabilities\\xa0in\\xa0hybrid\\xa0cloud, data\\xa0and\\xa0AI,\\xa0automation,\\xa0transaction\\xa0processing,\\xa0and\\xa0security. Red\\xa0Hat\\xa0performed\\xa0well\\xa0as\\xa0clients\\xa0embraced\\xa0its\\xa0open\\xa0hybrid cloud\\xa0platform.\\n\\nConsulting revenue\\xa0increased\\xa01%\\xa0at\\xa0constant\\xa0currency, demonstrating\\xa0our\\xa0clients'\\xa0continued\\xa0need\\xa0for\\xa0expertise\\xa0in\\xa0AI deployment,\\xa0digital\\xa0transformation,\\xa0and\\xa0cloud\\xa0modernization, despite\\xa0a\\xa0dynamic\\xa0market\\xa0environment.\\n\\nIBM\\xa0has\\xa0established\\xa0an\\xa0early\\xa0leadership\\xa0position\\xa0in\\xa0this regard,\\xa0building\\xa0a\\xa0portfolio\\xa0of\\xa0enterprise\\xa0AI\\xa0offerings\\xa0focused on\\xa0generating\\xa0ROI\\xa0through\\xa0productivity\\xa0improvements\\xa0and automation.\\xa0IBM\\xa0watsonx\\xa0provides\\xa0a\\xa0robust\\xa0portfolio\\xa0of AI\\xa0products\\xa0for\\xa0developing\\xa0AI\\xa0apps,\\xa0managing\\xa0data,\\xa0and governing\\xa0the\\xa0entire\\xa0lifecycle\\xa0of\\xa0AI\\xa0models.\\xa0AI\\xa0assistants manage\\xa0key\\xa0tasks,\\xa0including\\xa0customer\\xa0service\\xa0and\\xa0writing code. We are developing pre-built AI agents that deliver multitask reasoning for specific business domains. And our Granite family of fit-for-purpose AI models, when tuned with proprietary data, can deliver enterprise-grade generative AI with up to 90% improved cost efficiency. Granite allows clients to\\xa0bring\\xa0their\\xa0own\\xa0data\\xa0into\\xa0the\\xa0models,\\xa0and\\xa0can\\xa0be\\xa0trained\\xa0on that\\xa0data\\xa0in\\xa0weeks,\\xa0not\\xa0months.\\n\\nInfrastructure revenue\\xa0declined\\xa03%\\xa0at\\xa0constant\\xa0currency,\\xa0in line\\xa0with\\xa0product\\xa0cycle\\xa0expectations.\\xa0IBM\\xa0z16\\xa0is\\xa0now\\xa0the\\xa0most successful\\xa0mainframe\\xa0program\\xa0in\\xa0our\\xa0history,\\xa0highlighting\\xa0its enduring\\xa0value\\xa0to\\xa0clients.\",\n",
       "   '## Dear\\xa0IBM\\xa0Investor:\\n\\nIn 2024, IBM made significant progress\\xa0in\\xa0becoming\\xa0a\\xa0higher\\xa0growth, higher\\xa0margin\\xa0business.\\xa0We\\xa0made\\xa0this progress\\xa0by\\xa0combining\\xa0technology innovation\\xa0and\\xa0consulting\\xa0expertise to\\xa0drive\\xa0growth,\\xa0improve\\xa0productivity, and enhance operational efficiency -for\\xa0our\\xa0clients,\\xa0and\\xa0our\\xa0own\\xa0company.\\n\\nOur\\xa0strategy\\xa0continues\\xa0to\\xa0build\\xa0upon\\xa0the\\xa0two\\xa0technological foundations\\xa0of\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud,\\xa0which\\xa0clients\\xa0need\\xa0to unlock\\xa0the\\xa0full\\xa0value\\xa0of\\xa0their\\xa0data.\\xa0We\\xa0have\\xa0made\\xa0a\\xa0series\\xa0of investments\\xa0to\\xa0accelerate\\xa0the\\xa0delivery\\xa0of\\xa0that\\xa0value\\xa0to\\xa0our clients,\\xa0from\\xa0transforming\\xa0the\\xa0way\\xa0we\\xa0work\\xa0to\\xa0reorienting\\xa0our portfolio around powerful, AI-based solutions.\\n\\nAs\\xa0this\\xa0report\\xa0demonstrates,\\xa0these\\xa0investments\\xa0are\\xa0paying off,\\xa0delivering\\xa0meaningful\\xa0returns\\xa0for\\xa0our\\xa0shareholders, clients, and partners. Today, IBM is a software-led, fully integrated\\xa0platform\\xa0company,\\xa0built\\xa0to\\xa0grow\\xa0sustainably.\\xa0This is\\xa0the\\xa0ROI\\xa0of\\xa0IBM.',\n",
       "   \"## IBM Strategy\\n\\nOver the past 5 years, IBM has shifted to higher growth areas, with approximately 75 percent of our business mix in Software and Consulting. Our strategic focus is hybrid cloud and artificial intelligence (AI), today's most transformative technologies. As clients drive business growth using their existing technology and investing in new ones, they seek flexibility across distributed technology environments and the need to realize value from AI. We have shaped our business to focus on those client needs.\",\n",
       "   \"## Management Discussion\\n\\nInternational Business Machines Corporation and Subsidiary Companies\\n\\nSoftware revenue of $27,085 million increased 8.3 percent as reported (9.0 percent adjusted for currency) in 2024 compared to the prior year, reflecting growth across all lines of business with double-digit growth in Red Hat and Automation and high single-digit growth  in  Transaction  Processing.  This  revenue  performance  reflects  the  investments  we  have  been  making  in  Software,  both organically and through acquisitions. Our investments in generative AI are contributing to growth, as we had strong demand for our generative AI products such as watsonx, Concert and our AI assistants. We also launched new products in the fourth quarter of 2024  including  our  next  generation  of  watsonx  Code  Assistant  and  Guardium  Quantum  Safe.  In  2024,  we  also  had  increased revenue contribution from acquisitions compared to the prior year, including Apptio and StreamSets and webMethods. In addition, we  had  solid  growth  in  our  recurring  revenue  and  double-digit  growth  in  our  transactional  software  revenue  in  2024,  as  we accelerated growth through innovation across our Software portfolio.\\n\\nHybrid Platform &amp; Solutions revenue of $18,808 million increased 8.1 percent as reported (8.7 percent adjusted for currency) in 2024 compared to the prior year. Within Hybrid Platform &amp; Solutions, Red Hat revenue increased 11.4 percent as reported (12.0 percent  adjusted  for  currency),  which  reflects  the  continued  demand  for  our  hybrid  cloud  solutions  as  clients  are  prioritizing application modernization on OpenShift containers and Ansible automation to optimize their IT spending and reduce operational complexity. In 2024, we had double-digit revenue growth in OpenShift and Ansible, and high single-digit revenue growth in RHEL. The  growth  in  OpenShift  revenue  reflects  increased  volume  in  OpenShift  Virtualization  engagements,  and  we  exited  2024  with OpenShift annual recurring revenue of $1.4 billion. Automation revenue increased 14.2 percent as reported (14.8 percent adjusted for  currency),  driven  by  our  SaaS  subscription  offerings  such  as  AIOps  and  Management,  which  includes  the  higher  revenue contribution  from Apptio.  Data  &amp;  AI  revenue  increased  1.6  percent  as  reported  (2.2  percent  adjusted  for  currency),  with  strong growth in  Data  Fabric  and  our  AI  assistant  for  Customer  Care,  driven  by  client  demand  for  our  watsonx  platform  offerings,  and strength  in  asset  and  supply  chain  management  software  which  helps  clients  run  sustainable  operations.  Security  revenue increased 0.8 percent as reported (1.5 percent adjusted for currency), with revenue growth in data security and identity and access management, partially offset by a revenue decline in security threat management.\\n\\nAcross Hybrid Platform &amp; Solutions, our annual recurring revenue (ARR) was $15.3 billion exiting 2024, growing at a double-digit rate compared to the prior year. ARR is a key performance metric management uses to assess the health and growth trajectory of our  Hybrid  Platform  &amp;  Solutions  business  within  the  Software  segment.  The  metric  was  updated  in  the  first  quarter  of 2024  to reflect the organizational changes described in the 'Organization of Information' section above, and to simplify the calculation. ARR is  calculated  by  using  the  current  quarter's  recurring  revenue  and  then  multiplying  that  value  by  four.  This  value  includes  the following  consumption  models:  (1)  software  subscription  agreements,  including  committed  term  licenses,  (2)  as-a-service arrangements such as SaaS and PaaS, and (3) maintenance and support contracts. ARR should be viewed independently of revenue as this performance metric and its inputs may not represent revenue that will be recognized in future periods.\\n\\nTransaction Processing revenue of $8,277 million increased 8.7 percent as reported (9.6 percent adjusted for currency) in 2024 compared to the prior year. The performance in 2024 is the result of the combination of clients' growing capacity demands, solid renewal rates,  and  increased  contribution  from  our  generative  AI  products,  including  watsonx  code  assistant  for  Z.  This  growth reflects the innovation and value of our transaction processing software, which helps our clients manage their most mission-critical workloads.\",\n",
       "   \"## DESCRIPTION OF BUSINESS\\n\\nPlease refer to IBM's Annual Report on Form 10-K filed with the SEC on February\\xa025, 2025, for Item 1A. entitled 'Risk Factors.'\\n\\nIBM is addressing the hybrid cloud and AI opportunity with a platform-centric approach, focused on providing client value through a combination of technology and business expertise. We provide integrated solutions and products that leverage: data, information technology, deep expertise in industries and business processes, with trust and security and a broad ecosystem of partners and alliances. Our hybrid cloud platform and AI technology and services capabilities support clients' digital transformations and help them  engage  with  their  customers  and  employees  in  new  ways.  These  solutions  draw  from  an  industry-leading  portfolio  of capabilities in software, consulting services and a deep incumbency in mission-critical systems, all bolstered by one of the world's leading research organizations.\"]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data = []\n",
    "\n",
    "for f in TEST_DATA_FILES:\n",
    "    data = evaluation_utilities.read_json(f)\n",
    "    loaded_data = loaded_data + data\n",
    "print(len(loaded_data))\n",
    "loaded_data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706 of 1495\n"
     ]
    }
   ],
   "source": [
    "loaded_data_with_reference_contexts = list(filter(lambda element : len(element[\"reference_contexts\"]) > 0, loaded_data))\n",
    "#evaluation_utilities.write_json(loaded_data_with_reference_answers, \"questions_and_reference_answers_combined.json\")\n",
    "print(f\"{len(loaded_data_with_reference_contexts)} of {len(loaded_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary code to cut scope for quick testing.  Uncomment this line to run a mini-test of the notebook.\n",
    "# \n",
    "# #loaded_data_with_reference_contexts = loaded_data_with_reference_contexts[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706\n"
     ]
    }
   ],
   "source": [
    "count = len(loaded_data_with_reference_contexts)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Agentic RAG with Llama Stack\n",
    "\n",
    "This attempts to recreate the flow in https://llama-stack.readthedocs.io/en/latest/building_applications/rag.html#using-the-rag-tool , i.e., the RAG that a naive user getting started with the getting-started documentation would build EXCEPT that it is configured with the following elements:\n",
    "\n",
    "- Content is from the URLs configured in CONTENT_URLS at the top of this notebook\n",
    "- Milvus-lite inline vector IO provider\n",
    "- granite-embedding-125m embedding model\n",
    "- meta-llama/llama-3-3-70b-instruct generative model using the watsonx inference provider\n",
    "- max_tokens for output is 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/vector-dbs \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Register a vector db\n",
    "vector_db_id = f\"rag-eval-{uuid.uuid4().hex}\"\n",
    "response = client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    embedding_model=EMBED_MODEL_ID_FOR_LLAMA_STACK,\n",
    "    embedding_dimension=768,\n",
    "    provider_id=\"milvus\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'document_id': 'num-0',\n",
       "  'content': 'https://www.ibm.com/downloads/documents/us-en/1227c12d3a38b173',\n",
       "  'mime_type': 'application/pdf',\n",
       "  'metadata': {'url': 'https://www.ibm.com/downloads/documents/us-en/1227c12d3a38b173'}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap the URLs as Llama Stack RAGDocument objects\n",
    "\n",
    "documents = [\n",
    "    RAGDocument(\n",
    "        document_id=f\"num-{i}\",\n",
    "        content=url,\n",
    "        mime_type=\"application/pdf\",\n",
    "        metadata={\"url\": url},\n",
    "    )\n",
    "    for i, url in enumerate(CONTENT_URLS)\n",
    "]\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/tool-runtime/rag-tool/insert \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Insert those Llama Stack RAGDocument objects into the vector database\n",
    "\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/tool-runtime/rag-tool/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QueryResult(metadata={'document_ids': ['num-0', 'num-0', 'num-0', 'num-0', 'num-0']}, content=[TextContentItem(text='knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n', type='text'), TextContentItem(text=\"Result 1\\nContent: -year amounts have been reclassified to conform to the change in 2024 presentation.\\nFrom the perspective of how management views cash flow, in 2024, after investing $1.1 billion in net capital investments, we \\ngenerated free cash flow of $12.7 billion, an increase of $1.5 billion versus the prior year. The year-to-year increase in free cash \\nflow primarily reflects current year performance-related improvements within net income and sustainable lower cash requirements\\nthrough changes in our retirement plans. In 2024, net capital expenditures and net cash from operating activities include $0.4 \\nbillion and $0.1 billion, respectively, of cash proceeds from the sale of certain QRadar SaaS assets. This benefit to net capital \\nexpenditures, net cash from operating activities and to free cash flow represented only a nominal net benefit to current-year cash \\nflows due to payments for structural actions and foregone profit from the QRadar business. Refer to note E, “Acquisitions & \\nDivestitures,” for additional information. In 2024, we continued to return value to shareholders with $6.1 billion in dividends and \\ninvested $3.3 billion in acquisitions. \\nIBM’s Board of Directors considers the dividend payment on a quarterly basis. In the second quarter of 2024, the Board of Directors \\nincreased the company’s quarterly common stock dividend from $1.66 to $1.67 per share. Beginning in the first quarter of 2025, we \\nexpect to file our quarterly reports on Form 10-Q closer to the timing of our quarterly earnings release, which may not coincide with \\nthe timing of our Board of Directors meeting. If the company’s Board of Directors approves a common stock dividend following the \\nfiling, the company will disclose this event in a current report on Form 8-K.\\nEvents that could temporarily change the historical cash flow dynamics discussed previously include significant changes in \\noperating results, material changes in geographic sources of cash, unexpected adverse impacts from litigation, future pension \\nManagement Discussion\\nInternational Business Machines Corporation and Subsidiary Companies\\n35\\nfunding requirements during periods of severe downturn in the capital markets or the timing of tax payments. Whether any litigation \\nhas such an adverse impact will depend on a number of variables, which are more completely described in note Q, “Commitments & \\nContingencies.”\\nWith respect to pension funding, in 2024, we contributed $79 million to our non-U.S. defined benefit plans\\nMetadata: {'url': 'https://www.ibm.com/downloads/documents/us-en/1227c12d3a38b173', 'document_id': 'num-0'}\\n\", type='text'), TextContentItem(text=\"Result 2\\nContent:  pension \\nplans; improves visibility to management decisions and their impacts on operational performance; enables better comparison to \\npeer companies; and allows us to provide a long-term strategic view of the business going forward. In addition, these non-GAAP \\nmeasures provide a perspective consistent with areas of interest we routinely receive from investors and analysts. \\nFORWARD-LOOKING AND CAUTIONARY STATEMENTS\\nCertain statements contained in this Annual Report may constitute forward-looking statements within the meaning of the Private \\nSecurities Litigation Reform Act of 1995. Any forward-looking statement in this Annual Report speaks only as of the date on which it \\nis made; IBM assumes no obligation to update or revise any such statements except as required by law. Forward-looking \\nstatements are based on IBM’s current assumptions regarding future business and financial performance; these statements, by \\ntheir nature, address matters that are uncertain to different degrees. Forward-looking statements involve a number of risks, \\nuncertainties and other factors that could cause actual results to be materially different, as discussed more fully elsewhere in this \\nAnnual Report and in the company’s filings with the Securities and Exchange Commission (SEC), including IBM’s 2024 Form 10-K \\nfiled on February\\xa025, 2025.\\nManagement Discussion\\nInternational Business Machines Corporation and Subsidiary Companies\\n7\\nMANAGEMENT DISCUSSION SNAPSHOT\\n($ and shares in millions except per share amounts)\\nFor year ended December 31: 2024 (2) 2023\\nYr.-to-Yr. \\nPercent/Margin \\nChange\\nRevenue (1) $ 62,753 $ 61,860  1.4 %     \\nGross profit margin  56.7 %  55.4 %  1.2 pts. \\nTotal expense and other (income) $ 29,754 $ 25,610  16.2 %     \\nIncome from continuing operations before income taxes $ 5,797 $ 8,690  (33.3) %     \\nProvision for/(benefit from) income taxes from continuing operations $ (218) $ 1,176  NM \\nIncome from continuing operations $ 6,015 $ 7,514  (19.9) %     \\nIncome from continuing operations margin  9.6 %  12.1 %  (2.6) pts.  \\nIncome/(Loss) from discontinued operations, net of tax $ 8 $ (12)  NM \\nNet income $ \\nMetadata: {'url': 'https://www.ibm.com/downloads/documents/us-en/1227c12d3a38b173', 'document_id': 'num-0'}\\n\", type='text'), TextContentItem(text=\"Result 3\\nContent: Let’s\\xa0Create\\n2024\\xa0Annual\\xa0Report\\n\\n\\nIBM\\xa02024\\xa0Annual\\xa0Report 1\\nArvind\\xa0Krishna\\nChairman, President and Chief Executive Officer\\nDear\\xa0IBM\\xa0Investor:\\nIn 2024, IBM made significant \\nprogress\\xa0in\\xa0becoming\\xa0a\\xa0higher\\xa0growth,\\xa0\\nhigher\\xa0margin\\xa0business.\\xa0We\\xa0made\\xa0this\\xa0\\nprogress\\xa0by\\xa0combining\\xa0technology\\xa0\\ninnovation\\xa0and\\xa0consulting\\xa0expertise\\xa0\\nto\\xa0drive\\xa0growth,\\xa0improve\\xa0productivity,\\xa0\\nand enhance operational efficiency -- \\nfor\\xa0our\\xa0clients,\\xa0and\\xa0our\\xa0own\\xa0company.\\xa0\\nOur\\xa0strategy\\xa0continues\\xa0to\\xa0build\\xa0upon\\xa0the\\xa0two\\xa0technological\\xa0\\nfoundations\\xa0of\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud,\\xa0which\\xa0clients\\xa0need\\xa0to\\xa0\\nunlock\\xa0the\\xa0full\\xa0value\\xa0of\\xa0their\\xa0data.\\xa0We\\xa0have\\xa0made\\xa0a\\xa0series\\xa0of\\xa0\\ninvestments\\xa0to\\xa0accelerate\\xa0the\\xa0delivery\\xa0of\\xa0that\\xa0value\\xa0to\\xa0our\\xa0\\nclients,\\xa0from\\xa0transforming\\xa0the\\xa0way\\xa0we\\xa0work\\xa0to\\xa0reorienting\\xa0our\\xa0\\nportfolio around powerful, AI-based solutions. \\nAs\\xa0this\\xa0report\\xa0demonstrates,\\xa0these\\xa0investments\\xa0are\\xa0paying\\xa0\\noff,\\xa0delivering\\xa0meaningful\\xa0returns\\xa0for\\xa0our\\xa0shareholders,\\xa0\\nclients, and partners. Today, IBM is a software-led, fully \\nintegrated\\xa0platform\\xa0company,\\xa0built\\xa0to\\xa0grow\\xa0sustainably.\\xa0This\\xa0\\nis\\xa0the\\xa0ROI\\xa0of\\xa0IBM.\\n2024\\xa0Performance\\nFor\\xa0the\\xa0year,\\xa0IBM\\xa0generated\\xa0$62.8\\xa0billion\\xa0in\\xa0revenue,\\xa0up\\xa03%\\xa0\\nat\\xa0constant\\xa0currency,\\xa0and\\xa0$12.7\\xa0billion\\xa0in\\xa0free\\xa0cash\\xa0flow\\xa0—\\xa0an\\xa0\\nincrease of $1.5 billion year-over-year. Our generative AI \\nbook\\xa0of\\xa0business\\xa0now\\xa0stands\\xa0at\\xa0more\\xa0than\\xa0$5\\xa0billion\\xa0since\\xa0\\ninception.\\xa0This\\xa0revenue\\xa0growth\\xa0and\\xa0cash\\xa0generation\\xa0enabled\\xa0\\nus to make significant investments in the business and deliver \\nvalue\\xa0to\\xa0our\\xa0shareholders.\\xa0In\\xa02024,\\xa0we\\xa0allocated\\xa0more\\xa0than\\xa0$7\\xa0\\nbillion\\xa0to\\xa0research\\xa0and\\nMetadata: {'url': 'https://www.ibm.com/downloads/documents/us-en/1227c12d3a38b173', 'document_id': 'num-0'}\\n\", type='text'), TextContentItem(text=\"Result 4\\nContent:  receivables declined year to year from business variability, we had performance-related improvements within \\nnet income driving an increase within cash from operating activities. Our free cash flow for 2024 was $12,749 million, an increase of \\n$1,538 million versus the prior year. Refer to page 35 for additional information on free cash flow. Our cash generation enables us to \\ncontinue investing in innovation and expertise across the portfolio, while returning value to shareholders through dividends.  We \\ninvested $3,289 million in acquisitions and returned $6,147 million to shareholders through dividends in 2024. \\nConsistent with accounting standards, the company remeasured the funded status of our retirement and postretirement plans at \\nDecember 31. The overall net underfunded position at December\\xa031, 2024  was $2,657 million, a decrease of $1,348 million from \\nthe prior-year end, primarily due to higher discount rates. At year end, our qualified defined benefit pension plans were well funded \\nand the required contributions related to these plans and multi-employer plans are expected to be $100 million in 2025. In 2024, \\nthe return on the U.S. Personal Pension Plan assets was 2.6 percent and the plan was 136 percent funded at December\\xa031, 2024. \\nOverall, global asset returns were 2.0 percent and the qualified defined benefit plans worldwide were 116 percent funded at \\nDecember\\xa031, 2024. \\nIBM Working Capital\\n($ in millions)\\nAt December 31: 2024 2023\\nCurrent assets $ 34,482 $ 32,908 \\nCurrent liabilities $ 33,142 $ 34,122 \\nWorking capital $ 1,340 $ (1,214) \\nCurrent ratio 1.04:1    0.96:1    \\nWorking capital increased $2,554 million from the year-end 2023 position. Current assets increased $1,574 million ($2,707 million\\nadjusted for currency) primarily in cash and cash equivalents, and short-term financing receivables. Current liabilities decreased \\n$980 million (increased $37 million adjusted for currency) as a result of a decrease in short-term debt mainly due to maturities; \\npartially offset by an increase in deferred income.\\nReceivables and Allowances\\nRoll Forward of Total IBM Receivables Allowance for Credit Losses\\n($ in millions)\\nJanuary \\nMetadata: {'url': 'https://www.ibm.com/downloads/documents/us-en/1227c12d3a38b173', 'document_id': 'num-0'}\\n\", type='text'), TextContentItem(text=\"Result 5\\nContent:  \\nfinancial well-being.\\nIn 2024, a resilience-building tool and a digital well-being solution were made available to all IBM employees worldwide. These \\nresources offer a personalized approach to assist IBMers with making small changes – with big results. These resources foster \\nhealthier habits focused on physical, mental, and emotional well-being.\\nManagement Discussion\\nInternational Business Machines Corporation and Subsidiary Companies\\n15\\nYEAR IN REVIEW\\nResults of Continuing Operations\\nSegment Details  \\nAs discussed in the “Organization of Information” section, we made changes to our organizational structure and management \\nsystem in the first quarter of 2024. With these changes, we revised our reportable segments and updated the title of our segment \\nperformance metric from pre-tax income from continuing operations to segment profit. Prior-year results have been recast to reflect \\nthe January 2024 segment changes as described in note D, “Segments.”\\nThe table below presents each reportable segment’s revenue and gross margin results, followed by an analysis of the 2024  versus \\n2023 reportable segment results. The segment details below are presented under our historical reported revenue categories. Refer \\nto “Looking Forward” for changes to the revenue categories reported within our Software and Consulting reportable segments \\neffective in the first quarter of 2025. These changes will not impact our Consolidated Financial Statements or our reportable \\nsegments.\\n($ in millions)\\nFor the year ended December 31: 2024 2023 (1)\\nYr.-to-Yr. \\nPercent/\\nMargin \\nChange\\nYr.-to-Yr.\\nPercent Change\\nAdjusted for\\nCurrency\\nRevenue\\nSoftware $ 27,085 $ 25,011  8.3 %  9.0 %\\nGross margin  83.7 %  82.9 %  0.8 pts.\\nConsulting  20,692  20,884  (0.9) %    0.6 %\\nGross margin  27.0 %  26.8 %  0.3 pts.\\nInfrastructure  14,020  14,593  (3.9) %    (2.7) %\\nGross margin  55.8 %  56.1 %  (0.3) pts.\\nFinancing  713  741  (3.7) %    (2.5) %\\nGross margin  47.9 %  48.1 %  (0\\nMetadata: {'url': 'https://www.ibm.com/downloads/documents/us-en/1227c12d3a38b173', 'document_id': 'num-0'}\\n\", type='text'), TextContentItem(text='END of knowledge_search tool results.\\n', type='text'), TextContentItem(text='The above results were retrieved to help answer the user\\'s query: \"Based on IBM\\'s 2024 Annual Report, how might the company\\'s financial performance and strategic initiatives influence its ability to sustain or increase dividend payouts to shareholders?\". Use them as supporting information only in answering this query.\\n', type='text')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query documents\n",
    "\n",
    "results = client.tool_runtime.rag_tool.query(\n",
    "    vector_db_ids=[vector_db_id],\n",
    "    content=\"Based on IBM's 2024 Annual Report, how might the company's financial performance and strategic initiatives influence its ability to sustain or increase dividend payouts to shareholders?\",\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/tools?toolgroup_id=builtin%3A%3Arag%2Fknowledge_search \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Register a RAG Agent in Llama Stack using the vector database\n",
    "\n",
    "sampling_params = {\n",
    "    \"max_tokens\": 4096\n",
    "}\n",
    "\n",
    "# Create agent with memory\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=LLAMA_STACK_RAG_MODELS_INFO_WATSONX[0],\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    sampling_params=sampling_params,\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"builtin::rag/knowledge_search\",\n",
    "            \"args\": {\n",
    "                \"vector_db_ids\": [vector_db_id],\n",
    "                \"query_config\": {\n",
    "                    \"chunk_size_in_tokens\": 512,\n",
    "                    \"chunk_overlap_in_tokens\": 0,\n",
    "                    \"max_chunks\": NUMBER_OF_SEARCH_RESULTS,\n",
    "                    \"chunk_template\": \"Result {index}\\nContent: {chunk.content}\\nMetadata: {metadata}\\n\",\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/d1793085-930b-453d-81aa-ebdb070e0c3b/session \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/d1793085-930b-453d-81aa-ebdb070e0c3b/session/27c57397-cde7-4a43-8640-2cd556357720/turn \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "session_id = agent.create_session(f\"rag_session-{uuid.uuid4().hex}\")\n",
    "\n",
    "\n",
    "# Ask questions about documents in the vector db, and the agent will query the db to answer the question.\n",
    "response = agent.create_turn(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Based on IBM's 2024 Annual Report, how might the company's financial performance and strategic initiatives influence its ability to sustain or increase dividend payouts to shareholders?\"}],\n",
    "    session_id=session_id,\n",
    "    stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the 2024 Annual Report, IBM's financial performance and strategic initiatives may influence its ability to sustain or increase dividend payouts to shareholders in several ways:\\n\\n1. **Revenue growth**: IBM's revenue increased by 3% at constant currency in 2024, which could provide a stable foundation for dividend payments.\\n2. **Free cash flow**: The company generated $12.7 billion in free cash flow, an increase of $1.5 billion year-over-year, which could be used to fund dividend payments.\\n3. **Dividend payments**: IBM returned $6.1 billion to shareholders through dividends in 2024, and the company's Board of Directors increased the quarterly common stock dividend from $1.66 to $1.67 per share in the second quarter of 2024.\\n4. **Investments in innovation**: IBM invested $3.3 billion in acquisitions and $7 billion in research and development, which could drive future growth and potentially increase dividend payments.\\n5. **Retirement-related plans**: The company's retirement-related plans are in a strong financial position, with qualified plans funded 116% and expected contributions of approximately $1.3 billion in 2025, which could reduce the burden on the company's cash flow.\\n6. **Liquidity and capital resources**: IBM has generated strong cash flow from operations and has access to global funding sources, committed global credit facilities, and other committed and uncommitted lines of credit, which could provide additional liquidity to support dividend payments.\\n\\nHowever, there are also potential risks and uncertainties that could impact IBM's ability to sustain or increase dividend payouts, such as:\\n\\n1. **Market variability**: Changes in market conditions, including fluctuations in revenue and cash flow, could impact the company's ability to maintain or increase dividend payments.\\n2. **Litigation and contingencies**: Unexpected adverse impacts from litigation or contingencies could affect the company's cash flow and ability to pay dividends.\\n3. **Pension funding requirements**: While IBM's retirement-related plans are currently well-funded, changes in pension plan assumptions or funding requirements could impact the company's cash flow and ability to pay dividends.\\n\\nOverall, based on the 2024 Annual Report, IBM's financial performance and strategic initiatives suggest that the company is well-positioned to sustain or increase dividend payouts to shareholders, but the company's ability to do so will depend on various factors, including its future financial performance, market conditions, and other risks and uncertainties.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait 30 seconds after a failure in the hopes that any temporary server glitches will be sorted out by then.\n",
    "DELAY=30\n",
    "\n",
    "# If it fails more than 15 times, give up.\n",
    "MAX_RETRIES=15\n",
    "\n",
    "def run_lls_rag(data, generator_model_ids, vector_db_id, instructions=\"You are a helpful assistant\", label=\"Llama Stack\"):\n",
    "    datasets = {}\n",
    "    i = 1\n",
    "    sampling_params = {\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "\n",
    "    for generator_model_id in generator_model_ids:\n",
    "        dataset_for_test_model = copy.deepcopy(data)\n",
    "        # Create agent with memory\n",
    "        agent = Agent(\n",
    "            client,\n",
    "            model=generator_model_id,\n",
    "            instructions=instructions,\n",
    "            sampling_params=sampling_params,\n",
    "            tools=[\n",
    "                {\n",
    "                    \"name\": \"builtin::rag/knowledge_search\",\n",
    "                    \"args\": {\n",
    "                        \"vector_db_ids\": [vector_db_id],\n",
    "                        # Defaults\n",
    "                        \"query_config\": {\n",
    "                            \"chunk_size_in_tokens\": 512,\n",
    "                            \"chunk_overlap_in_tokens\": 0,\n",
    "                            \"max_chunks\": NUMBER_OF_SEARCH_RESULTS,\n",
    "                            \"chunk_template\": \"Result {index}\\nContent: {chunk.content}\\nMetadata: {metadata}\\n\",\n",
    "                        },\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "        count = len(dataset_for_test_model)\n",
    "        for entry in dataset_for_test_model:\n",
    "            clear_output(wait=True)\n",
    "            print(generator_model_id)\n",
    "            print(f\"{i} / {count}\")\n",
    "            i += 1\n",
    "            question = entry[\"user_input\"]\n",
    "            \n",
    "            session_id = agent.create_session(f\"rag_session-{uuid.uuid4().hex}\")\n",
    "            response = evaluation_utilities.run_with_retries(\n",
    "                lambda: agent.create_turn(\n",
    "                    messages=[{\"role\": \"user\", \"content\": question}],\n",
    "                    session_id=session_id,\n",
    "                    stream=False\n",
    "                ),\n",
    "                MAX_RETRIES,\n",
    "                DELAY)\n",
    "            text = response.output_message.content\n",
    "            entry[\"response\"] = text\n",
    "\n",
    "        datasets[label + \":\" + generator_model_id] = dataset_for_test_model\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/2026027d-ab6c-4a4c-ba29-559e513cc82a/session \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/2026027d-ab6c-4a4c-ba29-559e513cc82a/session/1ff005d5-cfbd-4e9d-b361-f87633ecfcde/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706\n"
     ]
    }
   ],
   "source": [
    "lls_datasets = run_lls_rag(loaded_data_with_reference_contexts, LLAMA_STACK_RAG_MODELS_INFO_WATSONX, vector_db_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_input': \"Based on IBM's 2024 Annual Report, how might the company's financial performance and strategic initiatives influence its ability to sustain or increase dividend payouts to shareholders?\",\n",
       "  'reference': \"Based on IBM's 2024 Annual Report, the company's financial performance and strategic initiatives appear to support its ability to sustain or potentially increase dividend payouts to shareholders. Here are some key points from the report that influence this assessment:\\n\\n1. **Revenue Growth and Cash Flow**: IBM reported $62.8 billion in revenue, with a 3% increase at constant currency, and generated $12.7 billion in free cash flow, an increase of $1.5 billion year-over-year. Strong revenue growth and cash flow generation provide a solid foundation for sustaining dividend payouts.\\n\\n2. **Investment in Growth Areas**: IBM has made significant investments in AI and hybrid cloud, which are expected to drive future growth. The company allocated over $7 billion to research and development and completed 11 acquisitions to enhance its capabilities. These strategic initiatives are likely to contribute to long-term revenue growth and profitability, supporting dividend sustainability.\\n\\n3. **Profitability and Margin Expansion**: IBM expanded its operating gross profit margin by 130 basis points in 2024, driven by a focus on high-value offerings and productivity initiatives. Improved profitability and margin expansion enhance the company's ability to generate cash, which can be used for dividend payments.\\n\\n4. **Shareholder Returns**: In 2024, IBM returned more than $6 billion to shareholders through dividends. This demonstrates the company's commitment to returning value to shareholders and suggests a focus on maintaining or potentially increasing dividend payouts.\\n\\n5. **Strong Operating Performance**: The operating (non-GAAP) pre-tax income from continuing operations increased by 8.7% year-over-year, and the operating (non-GAAP) pre-tax margin increased by 1.2 points to 17.9%. This strong operating performance indicates a healthy financial position, supporting dividend payments.\\n\\nOverall, IBM's strategic focus on growth areas, strong cash flow generation, and commitment to shareholder returns suggest that the company is well-positioned to sustain or potentially increase its dividend payouts in the future.\",\n",
       "  'reference_contexts': ['## Dear\\xa0IBM\\xa0Investor:\\n\\nIn 2024, IBM made significant progress\\xa0in\\xa0becoming\\xa0a\\xa0higher\\xa0growth, higher\\xa0margin\\xa0business.\\xa0We\\xa0made\\xa0this progress\\xa0by\\xa0combining\\xa0technology innovation\\xa0and\\xa0consulting\\xa0expertise to\\xa0drive\\xa0growth,\\xa0improve\\xa0productivity, and enhance operational efficiency -for\\xa0our\\xa0clients,\\xa0and\\xa0our\\xa0own\\xa0company.\\n\\nOur\\xa0strategy\\xa0continues\\xa0to\\xa0build\\xa0upon\\xa0the\\xa0two\\xa0technological foundations\\xa0of\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud,\\xa0which\\xa0clients\\xa0need\\xa0to unlock\\xa0the\\xa0full\\xa0value\\xa0of\\xa0their\\xa0data.\\xa0We\\xa0have\\xa0made\\xa0a\\xa0series\\xa0of investments\\xa0to\\xa0accelerate\\xa0the\\xa0delivery\\xa0of\\xa0that\\xa0value\\xa0to\\xa0our clients,\\xa0from\\xa0transforming\\xa0the\\xa0way\\xa0we\\xa0work\\xa0to\\xa0reorienting\\xa0our portfolio around powerful, AI-based solutions.\\n\\nAs\\xa0this\\xa0report\\xa0demonstrates,\\xa0these\\xa0investments\\xa0are\\xa0paying off,\\xa0delivering\\xa0meaningful\\xa0returns\\xa0for\\xa0our\\xa0shareholders, clients, and partners. Today, IBM is a software-led, fully integrated\\xa0platform\\xa0company,\\xa0built\\xa0to\\xa0grow\\xa0sustainably.\\xa0This is\\xa0the\\xa0ROI\\xa0of\\xa0IBM.',\n",
       "   \"## 2024\\xa0Performance\\n\\nFor\\xa0the\\xa0year,\\xa0IBM\\xa0generated\\xa0$62.8\\xa0billion\\xa0in\\xa0revenue,\\xa0up\\xa03% at\\xa0constant\\xa0currency,\\xa0and\\xa0$12.7\\xa0billion\\xa0in\\xa0free\\xa0cash\\xa0flow\\xa0-\\xa0an increase of $1.5 billion year-over-year. Our generative AI book\\xa0of\\xa0business\\xa0now\\xa0stands\\xa0at\\xa0more\\xa0than\\xa0$5\\xa0billion\\xa0since inception.\\xa0This\\xa0revenue\\xa0growth\\xa0and\\xa0cash\\xa0generation\\xa0enabled us to make significant investments in the business and deliver value\\xa0to\\xa0our\\xa0shareholders.\\xa0In\\xa02024,\\xa0we\\xa0allocated\\xa0more\\xa0than\\xa0$7 billion\\xa0to\\xa0research\\xa0and\\xa0development,\\xa0closed\\xa011\\xa0acquisitions to\\xa0enhance\\xa0our\\xa0capabilities,\\xa0and\\xa0returned\\xa0more\\xa0than\\xa0$6\\xa0billion\\n\\nto\\xa0shareholders\\xa0through\\xa0dividends.\\xa0IBM\\xa0expanded\\xa0operating gross profit margin by 130 basis points in 2024, driven by a focus on high-value offerings and productivity initiatives.\\n\\nSoftware revenue\\xa0grew\\xa09%\\xa0at\\xa0constant\\xa0currency,\\xa0reflecting strong\\xa0demand\\xa0for\\xa0our\\xa0advanced\\xa0capabilities\\xa0in\\xa0hybrid\\xa0cloud, data\\xa0and\\xa0AI,\\xa0automation,\\xa0transaction\\xa0processing,\\xa0and\\xa0security. Red\\xa0Hat\\xa0performed\\xa0well\\xa0as\\xa0clients\\xa0embraced\\xa0its\\xa0open\\xa0hybrid cloud\\xa0platform.\\n\\nConsulting revenue\\xa0increased\\xa01%\\xa0at\\xa0constant\\xa0currency, demonstrating\\xa0our\\xa0clients'\\xa0continued\\xa0need\\xa0for\\xa0expertise\\xa0in\\xa0AI deployment,\\xa0digital\\xa0transformation,\\xa0and\\xa0cloud\\xa0modernization, despite\\xa0a\\xa0dynamic\\xa0market\\xa0environment.\\n\\nIBM\\xa0has\\xa0established\\xa0an\\xa0early\\xa0leadership\\xa0position\\xa0in\\xa0this regard,\\xa0building\\xa0a\\xa0portfolio\\xa0of\\xa0enterprise\\xa0AI\\xa0offerings\\xa0focused on\\xa0generating\\xa0ROI\\xa0through\\xa0productivity\\xa0improvements\\xa0and automation.\\xa0IBM\\xa0watsonx\\xa0provides\\xa0a\\xa0robust\\xa0portfolio\\xa0of AI\\xa0products\\xa0for\\xa0developing\\xa0AI\\xa0apps,\\xa0managing\\xa0data,\\xa0and governing\\xa0the\\xa0entire\\xa0lifecycle\\xa0of\\xa0AI\\xa0models.\\xa0AI\\xa0assistants manage\\xa0key\\xa0tasks,\\xa0including\\xa0customer\\xa0service\\xa0and\\xa0writing code. We are developing pre-built AI agents that deliver multitask reasoning for specific business domains. And our Granite family of fit-for-purpose AI models, when tuned with proprietary data, can deliver enterprise-grade generative AI with up to 90% improved cost efficiency. Granite allows clients to\\xa0bring\\xa0their\\xa0own\\xa0data\\xa0into\\xa0the\\xa0models,\\xa0and\\xa0can\\xa0be\\xa0trained\\xa0on that\\xa0data\\xa0in\\xa0weeks,\\xa0not\\xa0months.\\n\\nInfrastructure revenue\\xa0declined\\xa03%\\xa0at\\xa0constant\\xa0currency,\\xa0in line\\xa0with\\xa0product\\xa0cycle\\xa0expectations.\\xa0IBM\\xa0z16\\xa0is\\xa0now\\xa0the\\xa0most successful\\xa0mainframe\\xa0program\\xa0in\\xa0our\\xa0history,\\xa0highlighting\\xa0its enduring\\xa0value\\xa0to\\xa0clients.\",\n",
       "   \"## Financial Performance Summary\\n\\nIn 2024, we reported $62.8 billion in revenue, income from continuing operations of $6.0 billion, which includes the impact of the pension  settlement  charges  of  $3.1  billion  ($2.4  billion  net  of  tax),  and  operating  (non-GAAP)  earnings  of  $9.7  billion,  which excludes the impact of the pension settlement charges. Refer to 'Organization of Information,' for additional information. Diluted earnings per share from continuing operations was $6.42 as reported, including an impact of $2.57 from the pension settlement charges, and diluted earnings per share was $10.33 on an operating (non-GAAP) basis. We generated $13.4 billion in cash from operations  and  $12.7  billion  in  free  cash  flow,  and  returned  $6.1  billion  to  shareholders  in  dividends.  We  are  pleased  with  the progress we made in 2024, delivering revenue growth in our re-positioned business and strong cash flow generation. Our 2024 performance demonstrates the success of our focused strategy, enhanced portfolio and sustainable revenue growth. We increased our  investment  in  innovation  and  talent  and  completed  eleven  acquisitions  in  2024,  strengthening  our  hybrid  cloud  and  AI capabilities, all while continuing to return value to shareholders through our dividend.\\n\\nTotal revenue grew 1.4 percent year to year as reported and 3 percent adjusted for currency compared to the prior year, led by our Software performance. Software revenue increased 8.3 percent as reported and 9.0 percent adjusted for currency, with strength across our portfolio. Hybrid Platform &amp; Solutions increased 8.1 percent as reported and 8.7 percent adjusted for currency, reflecting growth across all lines of business with double-digit revenue growth in Red Hat and Automation. Transaction Processing increased 8.7 percent as reported and 9.6 percent adjusted for currency, with growth in both recurring and transactional revenue. Consulting revenue decreased 0.9 percent as reported but grew 0.6 percent adjusted for currency, and continued to be impacted by a dynamic market environment as clients reprioritized spending. Infrastructure decreased 3.9 percent year to year as reported and 2.7 percent adjusted for currency, reflecting product cycle dynamics.\\n\\nFrom  a  geographic  perspective,  Americas  revenue  decreased  1.3  percent  year  to  year  as  reported  (0.7  percent  adjusted  for currency).  Europe/Middle East/Africa (EMEA) increased 5.1 percent as reported (4.7 percent adjusted for currency). Asia Pacific grew 3.0 percent as reported (7.9 percent adjusted for currency).\\n\\nGross  margin  of  56.7  percent  increased  1.2  points  year  to  year,  with  continued  margin  expansion  driven  by  portfolio  mix  and ongoing productivity initiatives. Operating (non-GAAP) gross margin of 57.8 percent increased 1.3 points versus the prior year, due to the same dynamics.\\n\\nTotal expense and other (income) increased 16.2 percent in 2024 versus the prior year primarily driven by the pension settlement charges of $3.1 billion in 2024, higher spending reflecting our continued investment in portfolio innovation to drive our strategy and higher  workforce rebalancing charges. This was partially offset by a gain from the sale of certain QRadar Software-as-a-Service (SaaS) assets, the gain on the divestiture of The Weather Company assets, the benefits from productivity and the actions taken to transform  our  operations,  and  the  effects  of  currency.  Total  operating  (non-GAAP)  expense  and  other  (income)  increased  1.8 percent year to year, driven primarily by the factors described above, excluding the pension settlement charges.\\n\\nPre-tax income from continuing operations was $5.8 billion in 2024 compared with $8.7 billion in the prior year and pre-tax margin was  9.2  percent,  a  decrease  of  4.8  points  versus  2023.  The  year-to-year  performance  was  primarily  driven  by  the  pension settlement charges in 2024 partially offset by our gross margin expansion and the benefits from productivity and the actions taken to transform our operations which enabled investments to drive innovation. The continuing operations effective tax rate for 2024 was (3.8) percent compared to 13.5 percent in 2023. The current-year effective tax rate was primarily driven by the tax impact of the pension settlement charges and the resolution of certain tax audit matters. Net income from continuing operations was $6.0 billion in 2024 compared with $7.5 billion in the prior year and net income from continuing operations margin was 9.6 percent, a decrease of 2.6 points year to year. Operating (non-GAAP) pre-tax income from continuing operations of $11.2 billion increased 8.7 percent year to year and the operating (non-GAAP) pre-tax margin from continuing operations increased 1.2 points to 17.9 percent. Our revenue growth, portfolio mix and productivity initiatives resulted in strong operating (non-GAAP) pre-tax income growth in 2024 compared to the prior year. The operating (non-GAAP) effective tax rate for 2024 was 13.6 percent compared to 14.0 percent\"],\n",
       "  'response': \"Based on the 2024 Annual Report, IBM's financial performance and strategic initiatives may influence its ability to sustain or increase dividend payouts to shareholders in several ways:\\n\\n1. **Revenue growth**: IBM's revenue increased by 3% at constant currency in 2024, which could provide a stable foundation for dividend payments.\\n2. **Free cash flow**: The company generated $12.7 billion in free cash flow, an increase of $1.5 billion year-over-year, which could be used to fund dividend payments.\\n3. **Dividend payments**: IBM returned $6.1 billion to shareholders through dividends in 2024, and the company's Board of Directors increased the quarterly common stock dividend from $1.66 to $1.67 per share in the second quarter of 2024.\\n4. **Investments in innovation and expertise**: IBM invested $3.3 billion in acquisitions and $7 billion in research and development, which could drive future growth and potentially increase dividend payments.\\n5. **Retirement-related plans**: The company's retirement-related plans are in a strong financial position, with qualified plans funded 116% and expected contributions of approximately $1.3 billion in 2025, which could reduce the burden on the company's cash flow and allow for more dividend payments.\\n6. **Liquidity and capital resources**: IBM has generated strong cash flow from operations and has access to global funding sources, committed global credit facilities, and other committed and uncommitted lines of credit, which could provide additional liquidity to support dividend payments.\\n\\nHowever, there are also potential risks and uncertainties that could impact IBM's ability to sustain or increase dividend payouts, such as:\\n\\n1. **Market variability**: Changes in market conditions, including fluctuations in revenue and cash flow, could impact the company's ability to maintain or increase dividend payments.\\n2. **Litigation and regulatory risks**: Unexpected adverse impacts from litigation or regulatory changes could affect the company's cash flow and ability to pay dividends.\\n3. **Pension funding requirements**: While IBM's retirement-related plans are currently well-funded, changes in pension plan assumptions or funding requirements could impact the company's cash flow and ability to pay dividends.\\n\\nOverall, based on the 2024 Annual Report, IBM's financial performance and strategic initiatives suggest that the company is well-positioned to sustain or increase dividend payouts to shareholders, but the company's ability to do so will depend on various factors, including its future financial performance, market conditions, and regulatory environment.\"},\n",
       " {'user_input': 'Based on the trends and projections outlined in the IBM 2024 Annual Report, what strategic initiatives is IBM likely to prioritize to enhance its competitive position in the technology sector over the next five years?',\n",
       "  'reference': 'Based on the trends and projections outlined in the IBM 2024 Annual Report, IBM is likely to prioritize the following strategic initiatives to enhance its competitive position in the technology sector over the next five years:\\n\\n1. **Focus on AI and Hybrid Cloud**: IBM will continue to build upon its technological foundations of AI and hybrid cloud, as these are seen as transformative technologies that unlock the full value of data for clients. This includes further development and deployment of AI solutions like watsonx and the Granite family of AI models.\\n\\n2. **Expansion of Software and Consulting Services**: With approximately 75 percent of its business mix in Software and Consulting, IBM will likely continue to expand these areas. This includes enhancing its software offerings, particularly in hybrid cloud, data and AI, automation, and security, as well as growing its consulting services to support AI deployment and digital transformation.\\n\\n3. **Investment in Research and Development**: IBM allocated more than $7 billion to research and development in 2024, and this trend is likely to continue. This investment will support innovation in AI, hybrid cloud, and other high-value offerings.\\n\\n4. **Acquisitions and Partnerships**: IBM closed 11 acquisitions in 2024 to enhance its capabilities. Continuing this strategy will help IBM expand its technological expertise and market reach. Additionally, maintaining a broad ecosystem of partners and alliances will be crucial for delivering integrated solutions.\\n\\n5. **Enhancing Operational Efficiency and Productivity**: IBM aims to improve productivity and operational efficiency, both for itself and its clients. This includes leveraging AI for automation and productivity improvements, as well as optimizing IT spending and reducing operational complexity through solutions like OpenShift and Ansible.\\n\\n6. **Sustainable Growth and Value Delivery**: IBM is focused on becoming a software-led, fully integrated platform company built for sustainable growth. This involves delivering meaningful returns for shareholders, clients, and partners through strategic investments and innovation.\\n\\nBy prioritizing these initiatives, IBM aims to strengthen its leadership position in the technology sector and drive long-term growth.',\n",
       "  'reference_contexts': [\"## 2024\\xa0Performance\\n\\nFor\\xa0the\\xa0year,\\xa0IBM\\xa0generated\\xa0$62.8\\xa0billion\\xa0in\\xa0revenue,\\xa0up\\xa03% at\\xa0constant\\xa0currency,\\xa0and\\xa0$12.7\\xa0billion\\xa0in\\xa0free\\xa0cash\\xa0flow\\xa0-\\xa0an increase of $1.5 billion year-over-year. Our generative AI book\\xa0of\\xa0business\\xa0now\\xa0stands\\xa0at\\xa0more\\xa0than\\xa0$5\\xa0billion\\xa0since inception.\\xa0This\\xa0revenue\\xa0growth\\xa0and\\xa0cash\\xa0generation\\xa0enabled us to make significant investments in the business and deliver value\\xa0to\\xa0our\\xa0shareholders.\\xa0In\\xa02024,\\xa0we\\xa0allocated\\xa0more\\xa0than\\xa0$7 billion\\xa0to\\xa0research\\xa0and\\xa0development,\\xa0closed\\xa011\\xa0acquisitions to\\xa0enhance\\xa0our\\xa0capabilities,\\xa0and\\xa0returned\\xa0more\\xa0than\\xa0$6\\xa0billion\\n\\nto\\xa0shareholders\\xa0through\\xa0dividends.\\xa0IBM\\xa0expanded\\xa0operating gross profit margin by 130 basis points in 2024, driven by a focus on high-value offerings and productivity initiatives.\\n\\nSoftware revenue\\xa0grew\\xa09%\\xa0at\\xa0constant\\xa0currency,\\xa0reflecting strong\\xa0demand\\xa0for\\xa0our\\xa0advanced\\xa0capabilities\\xa0in\\xa0hybrid\\xa0cloud, data\\xa0and\\xa0AI,\\xa0automation,\\xa0transaction\\xa0processing,\\xa0and\\xa0security. Red\\xa0Hat\\xa0performed\\xa0well\\xa0as\\xa0clients\\xa0embraced\\xa0its\\xa0open\\xa0hybrid cloud\\xa0platform.\\n\\nConsulting revenue\\xa0increased\\xa01%\\xa0at\\xa0constant\\xa0currency, demonstrating\\xa0our\\xa0clients'\\xa0continued\\xa0need\\xa0for\\xa0expertise\\xa0in\\xa0AI deployment,\\xa0digital\\xa0transformation,\\xa0and\\xa0cloud\\xa0modernization, despite\\xa0a\\xa0dynamic\\xa0market\\xa0environment.\\n\\nIBM\\xa0has\\xa0established\\xa0an\\xa0early\\xa0leadership\\xa0position\\xa0in\\xa0this regard,\\xa0building\\xa0a\\xa0portfolio\\xa0of\\xa0enterprise\\xa0AI\\xa0offerings\\xa0focused on\\xa0generating\\xa0ROI\\xa0through\\xa0productivity\\xa0improvements\\xa0and automation.\\xa0IBM\\xa0watsonx\\xa0provides\\xa0a\\xa0robust\\xa0portfolio\\xa0of AI\\xa0products\\xa0for\\xa0developing\\xa0AI\\xa0apps,\\xa0managing\\xa0data,\\xa0and governing\\xa0the\\xa0entire\\xa0lifecycle\\xa0of\\xa0AI\\xa0models.\\xa0AI\\xa0assistants manage\\xa0key\\xa0tasks,\\xa0including\\xa0customer\\xa0service\\xa0and\\xa0writing code. We are developing pre-built AI agents that deliver multitask reasoning for specific business domains. And our Granite family of fit-for-purpose AI models, when tuned with proprietary data, can deliver enterprise-grade generative AI with up to 90% improved cost efficiency. Granite allows clients to\\xa0bring\\xa0their\\xa0own\\xa0data\\xa0into\\xa0the\\xa0models,\\xa0and\\xa0can\\xa0be\\xa0trained\\xa0on that\\xa0data\\xa0in\\xa0weeks,\\xa0not\\xa0months.\\n\\nInfrastructure revenue\\xa0declined\\xa03%\\xa0at\\xa0constant\\xa0currency,\\xa0in line\\xa0with\\xa0product\\xa0cycle\\xa0expectations.\\xa0IBM\\xa0z16\\xa0is\\xa0now\\xa0the\\xa0most successful\\xa0mainframe\\xa0program\\xa0in\\xa0our\\xa0history,\\xa0highlighting\\xa0its enduring\\xa0value\\xa0to\\xa0clients.\",\n",
       "   '## Dear\\xa0IBM\\xa0Investor:\\n\\nIn 2024, IBM made significant progress\\xa0in\\xa0becoming\\xa0a\\xa0higher\\xa0growth, higher\\xa0margin\\xa0business.\\xa0We\\xa0made\\xa0this progress\\xa0by\\xa0combining\\xa0technology innovation\\xa0and\\xa0consulting\\xa0expertise to\\xa0drive\\xa0growth,\\xa0improve\\xa0productivity, and enhance operational efficiency -for\\xa0our\\xa0clients,\\xa0and\\xa0our\\xa0own\\xa0company.\\n\\nOur\\xa0strategy\\xa0continues\\xa0to\\xa0build\\xa0upon\\xa0the\\xa0two\\xa0technological foundations\\xa0of\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud,\\xa0which\\xa0clients\\xa0need\\xa0to unlock\\xa0the\\xa0full\\xa0value\\xa0of\\xa0their\\xa0data.\\xa0We\\xa0have\\xa0made\\xa0a\\xa0series\\xa0of investments\\xa0to\\xa0accelerate\\xa0the\\xa0delivery\\xa0of\\xa0that\\xa0value\\xa0to\\xa0our clients,\\xa0from\\xa0transforming\\xa0the\\xa0way\\xa0we\\xa0work\\xa0to\\xa0reorienting\\xa0our portfolio around powerful, AI-based solutions.\\n\\nAs\\xa0this\\xa0report\\xa0demonstrates,\\xa0these\\xa0investments\\xa0are\\xa0paying off,\\xa0delivering\\xa0meaningful\\xa0returns\\xa0for\\xa0our\\xa0shareholders, clients, and partners. Today, IBM is a software-led, fully integrated\\xa0platform\\xa0company,\\xa0built\\xa0to\\xa0grow\\xa0sustainably.\\xa0This is\\xa0the\\xa0ROI\\xa0of\\xa0IBM.',\n",
       "   \"## IBM Strategy\\n\\nOver the past 5 years, IBM has shifted to higher growth areas, with approximately 75 percent of our business mix in Software and Consulting. Our strategic focus is hybrid cloud and artificial intelligence (AI), today's most transformative technologies. As clients drive business growth using their existing technology and investing in new ones, they seek flexibility across distributed technology environments and the need to realize value from AI. We have shaped our business to focus on those client needs.\",\n",
       "   \"## Management Discussion\\n\\nInternational Business Machines Corporation and Subsidiary Companies\\n\\nSoftware revenue of $27,085 million increased 8.3 percent as reported (9.0 percent adjusted for currency) in 2024 compared to the prior year, reflecting growth across all lines of business with double-digit growth in Red Hat and Automation and high single-digit growth  in  Transaction  Processing.  This  revenue  performance  reflects  the  investments  we  have  been  making  in  Software,  both organically and through acquisitions. Our investments in generative AI are contributing to growth, as we had strong demand for our generative AI products such as watsonx, Concert and our AI assistants. We also launched new products in the fourth quarter of 2024  including  our  next  generation  of  watsonx  Code  Assistant  and  Guardium  Quantum  Safe.  In  2024,  we  also  had  increased revenue contribution from acquisitions compared to the prior year, including Apptio and StreamSets and webMethods. In addition, we  had  solid  growth  in  our  recurring  revenue  and  double-digit  growth  in  our  transactional  software  revenue  in  2024,  as  we accelerated growth through innovation across our Software portfolio.\\n\\nHybrid Platform &amp; Solutions revenue of $18,808 million increased 8.1 percent as reported (8.7 percent adjusted for currency) in 2024 compared to the prior year. Within Hybrid Platform &amp; Solutions, Red Hat revenue increased 11.4 percent as reported (12.0 percent  adjusted  for  currency),  which  reflects  the  continued  demand  for  our  hybrid  cloud  solutions  as  clients  are  prioritizing application modernization on OpenShift containers and Ansible automation to optimize their IT spending and reduce operational complexity. In 2024, we had double-digit revenue growth in OpenShift and Ansible, and high single-digit revenue growth in RHEL. The  growth  in  OpenShift  revenue  reflects  increased  volume  in  OpenShift  Virtualization  engagements,  and  we  exited  2024  with OpenShift annual recurring revenue of $1.4 billion. Automation revenue increased 14.2 percent as reported (14.8 percent adjusted for  currency),  driven  by  our  SaaS  subscription  offerings  such  as  AIOps  and  Management,  which  includes  the  higher  revenue contribution  from Apptio.  Data  &amp;  AI  revenue  increased  1.6  percent  as  reported  (2.2  percent  adjusted  for  currency),  with  strong growth in  Data  Fabric  and  our  AI  assistant  for  Customer  Care,  driven  by  client  demand  for  our  watsonx  platform  offerings,  and strength  in  asset  and  supply  chain  management  software  which  helps  clients  run  sustainable  operations.  Security  revenue increased 0.8 percent as reported (1.5 percent adjusted for currency), with revenue growth in data security and identity and access management, partially offset by a revenue decline in security threat management.\\n\\nAcross Hybrid Platform &amp; Solutions, our annual recurring revenue (ARR) was $15.3 billion exiting 2024, growing at a double-digit rate compared to the prior year. ARR is a key performance metric management uses to assess the health and growth trajectory of our  Hybrid  Platform  &amp;  Solutions  business  within  the  Software  segment.  The  metric  was  updated  in  the  first  quarter  of 2024  to reflect the organizational changes described in the 'Organization of Information' section above, and to simplify the calculation. ARR is  calculated  by  using  the  current  quarter's  recurring  revenue  and  then  multiplying  that  value  by  four.  This  value  includes  the following  consumption  models:  (1)  software  subscription  agreements,  including  committed  term  licenses,  (2)  as-a-service arrangements such as SaaS and PaaS, and (3) maintenance and support contracts. ARR should be viewed independently of revenue as this performance metric and its inputs may not represent revenue that will be recognized in future periods.\\n\\nTransaction Processing revenue of $8,277 million increased 8.7 percent as reported (9.6 percent adjusted for currency) in 2024 compared to the prior year. The performance in 2024 is the result of the combination of clients' growing capacity demands, solid renewal rates,  and  increased  contribution  from  our  generative  AI  products,  including  watsonx  code  assistant  for  Z.  This  growth reflects the innovation and value of our transaction processing software, which helps our clients manage their most mission-critical workloads.\",\n",
       "   \"## DESCRIPTION OF BUSINESS\\n\\nPlease refer to IBM's Annual Report on Form 10-K filed with the SEC on February\\xa025, 2025, for Item 1A. entitled 'Risk Factors.'\\n\\nIBM is addressing the hybrid cloud and AI opportunity with a platform-centric approach, focused on providing client value through a combination of technology and business expertise. We provide integrated solutions and products that leverage: data, information technology, deep expertise in industries and business processes, with trust and security and a broad ecosystem of partners and alliances. Our hybrid cloud platform and AI technology and services capabilities support clients' digital transformations and help them  engage  with  their  customers  and  employees  in  new  ways.  These  solutions  draw  from  an  industry-leading  portfolio  of capabilities in software, consulting services and a deep incumbency in mission-critical systems, all bolstered by one of the world's leading research organizations.\"],\n",
       "  'response': \"Based on the IBM 2024 Annual Report, the company is likely to prioritize strategic initiatives that focus on hybrid cloud and AI technologies to enhance its competitive position in the technology sector over the next five years. These initiatives include:\\n\\n1. Investing in research and development to accelerate the delivery of AI and hybrid cloud solutions to clients.\\n2. Expanding its portfolio of AI-based solutions, such as generative AI, to help clients unlock the full value of their data.\\n3. Enhancing its hybrid cloud platform to enable clients to operate, manage, and optimize their IT resources and business processes within hybrid, multi-cloud environments.\\n4. Building on its legacy of transforming innovation in computing into client-grade solutions, such as the development of the Heron quantum chip and the launch of Qiskit 1.0 software development kit.\\n5. Accelerating its strategy and client value with inorganic investments, such as the acquisition of assets from Software AG and Neural Magic, to bolster its automation, data, and AI portfolios.\\n6. Collaborating with clients and ecosystem partners to create value through the application of AI and hybrid cloud technologies, such as the Partner Plus program and co-investing with strategic partners.\\n7. Focusing on helping clients transform their core operations and create new sources of competitive advantage through the application of AI and hybrid cloud technologies.\\n\\nThese initiatives are expected to drive growth, improve productivity, and enhance operational efficiency for IBM's clients, as well as deliver meaningful returns for its shareholders.\"}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lls_datasets['Llama Stack:meta-llama/llama-3-3-70b-instruct'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "evaluation_utilities.write_json(lls_datasets, f\"./questions_and_reference_answers_and_system_answers-lls-{count}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run RAG with LlamaIndex\n",
    "\n",
    "This attempts to recreate the flow in https://docs.llamaindex.ai/en/stable/understanding/rag/ , i.e., the RAG that a naive user getting started with the getting-started documentation would build EXCEPT that it is configured with the following elements:\n",
    "\n",
    "- Content is from the URLs configured in CONTENT_URLS at the top of this notebook\n",
    "- Milvus vector IO provider\n",
    "- granite-embedding-125m embedding model\n",
    "- meta-llama/llama-3-3-70b-instruct generative model using the watsonx inference provider\n",
    "- max_tokens for output is 4096\n",
    "- number of search results to return is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 44 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 46 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 49 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 58 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 766 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 768 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 784 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 786 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 788 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 791 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 796 0 (offset 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x3e586f710>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(CONTENT_LOCATION).load_data()\n",
    "vector_index = VectorStoreIndex.from_documents(documents=documents, embed_model=EMBED_MODEL_FOR_LLAMAINDEX)\n",
    "vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(llm=LLAMA_INDEX_RAG_MODELS['meta-llama/llama-3-3-70b-instruct'], similarity_top_k=NUMBER_OF_SEARCH_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-05-21 \"HTTP/1.1 200 OK\"\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-05-21'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'IBM exists to help clients unlock their next chapter of technology-led business growth, built across hybrid multi-cloud and leveraging AI, by providing integrated solutions and products that leverage data, information technology, deep expertise in industries and business processes, with trust and security and a broad ecosystem of partners and alliances.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Why does IBM exist?\"\n",
    "result = query_engine.query(question)\n",
    "result.response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_li_rag(qna, generator_models, idx, number_of_search_results):\n",
    "    outputs = {}\n",
    "    for generator_model_id, generator_model in generator_models.items():\n",
    "        dataset = copy.deepcopy(qna)\n",
    "\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=idx,\n",
    "            similarity_top_k=number_of_search_results,\n",
    "        )\n",
    "\n",
    "        query_engine = RetrieverQueryEngine(\n",
    "            retriever=retriever,\n",
    "            response_synthesizer=get_response_synthesizer(llm = generator_model)\n",
    "        )\n",
    "\n",
    "        i = 1\n",
    "        count = len(dataset)\n",
    "        for entry in dataset:\n",
    "            clear_output(wait=True)\n",
    "            print(generator_model_id)\n",
    "            print(f\"{i} / {count}\")\n",
    "            i += 1\n",
    "            question = entry[\"user_input\"]\n",
    "            result = evaluation_utilities.run_with_retries(\n",
    "                    lambda: query_engine.query(question),\n",
    "                    MAX_RETRIES,\n",
    "                    DELAY\n",
    "                )\n",
    "            query_engine.query(question)\n",
    "            entry[\"response\"] = result.response.strip()\n",
    "            entry[\"retrieved_contexts\"] = [n.text for n in result.source_nodes]\n",
    "        outputs[\"LlamaIndex\" + \":\" + generator_model_id] = dataset\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/llama-3-3-70b-instruct\n",
      "706 / 706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-05-21 \"HTTP/1.1 200 OK\"\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-05-21'\n",
      "INFO:httpx:HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-05-21 \"HTTP/1.1 200 OK\"\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-05-21'\n"
     ]
    }
   ],
   "source": [
    "li_datasets = run_li_rag(loaded_data_with_reference_contexts, LLAMA_INDEX_RAG_MODELS, vector_index, number_of_search_results=NUMBER_OF_SEARCH_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_input': \"Based on IBM's 2024 Annual Report, how might the company's financial performance and strategic initiatives influence its ability to sustain or increase dividend payouts to shareholders?\",\n",
       "  'reference': \"Based on IBM's 2024 Annual Report, the company's financial performance and strategic initiatives appear to support its ability to sustain or potentially increase dividend payouts to shareholders. Here are some key points from the report that influence this assessment:\\n\\n1. **Revenue Growth and Cash Flow**: IBM reported $62.8 billion in revenue, with a 3% increase at constant currency, and generated $12.7 billion in free cash flow, an increase of $1.5 billion year-over-year. Strong revenue growth and cash flow generation provide a solid foundation for sustaining dividend payouts.\\n\\n2. **Investment in Growth Areas**: IBM has made significant investments in AI and hybrid cloud, which are expected to drive future growth. The company allocated over $7 billion to research and development and completed 11 acquisitions to enhance its capabilities. These strategic initiatives are likely to contribute to long-term revenue growth and profitability, supporting dividend sustainability.\\n\\n3. **Profitability and Margin Expansion**: IBM expanded its operating gross profit margin by 130 basis points in 2024, driven by a focus on high-value offerings and productivity initiatives. Improved profitability and margin expansion enhance the company's ability to generate cash, which can be used for dividend payments.\\n\\n4. **Shareholder Returns**: In 2024, IBM returned more than $6 billion to shareholders through dividends. This demonstrates the company's commitment to returning value to shareholders and suggests a focus on maintaining or potentially increasing dividend payouts.\\n\\n5. **Strong Operating Performance**: The operating (non-GAAP) pre-tax income from continuing operations increased by 8.7% year-over-year, and the operating (non-GAAP) pre-tax margin increased by 1.2 points to 17.9%. This strong operating performance indicates a healthy financial position, supporting dividend payments.\\n\\nOverall, IBM's strategic focus on growth areas, strong cash flow generation, and commitment to shareholder returns suggest that the company is well-positioned to sustain or potentially increase its dividend payouts in the future.\",\n",
       "  'reference_contexts': ['## Dear\\xa0IBM\\xa0Investor:\\n\\nIn 2024, IBM made significant progress\\xa0in\\xa0becoming\\xa0a\\xa0higher\\xa0growth, higher\\xa0margin\\xa0business.\\xa0We\\xa0made\\xa0this progress\\xa0by\\xa0combining\\xa0technology innovation\\xa0and\\xa0consulting\\xa0expertise to\\xa0drive\\xa0growth,\\xa0improve\\xa0productivity, and enhance operational efficiency -for\\xa0our\\xa0clients,\\xa0and\\xa0our\\xa0own\\xa0company.\\n\\nOur\\xa0strategy\\xa0continues\\xa0to\\xa0build\\xa0upon\\xa0the\\xa0two\\xa0technological foundations\\xa0of\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud,\\xa0which\\xa0clients\\xa0need\\xa0to unlock\\xa0the\\xa0full\\xa0value\\xa0of\\xa0their\\xa0data.\\xa0We\\xa0have\\xa0made\\xa0a\\xa0series\\xa0of investments\\xa0to\\xa0accelerate\\xa0the\\xa0delivery\\xa0of\\xa0that\\xa0value\\xa0to\\xa0our clients,\\xa0from\\xa0transforming\\xa0the\\xa0way\\xa0we\\xa0work\\xa0to\\xa0reorienting\\xa0our portfolio around powerful, AI-based solutions.\\n\\nAs\\xa0this\\xa0report\\xa0demonstrates,\\xa0these\\xa0investments\\xa0are\\xa0paying off,\\xa0delivering\\xa0meaningful\\xa0returns\\xa0for\\xa0our\\xa0shareholders, clients, and partners. Today, IBM is a software-led, fully integrated\\xa0platform\\xa0company,\\xa0built\\xa0to\\xa0grow\\xa0sustainably.\\xa0This is\\xa0the\\xa0ROI\\xa0of\\xa0IBM.',\n",
       "   \"## 2024\\xa0Performance\\n\\nFor\\xa0the\\xa0year,\\xa0IBM\\xa0generated\\xa0$62.8\\xa0billion\\xa0in\\xa0revenue,\\xa0up\\xa03% at\\xa0constant\\xa0currency,\\xa0and\\xa0$12.7\\xa0billion\\xa0in\\xa0free\\xa0cash\\xa0flow\\xa0-\\xa0an increase of $1.5 billion year-over-year. Our generative AI book\\xa0of\\xa0business\\xa0now\\xa0stands\\xa0at\\xa0more\\xa0than\\xa0$5\\xa0billion\\xa0since inception.\\xa0This\\xa0revenue\\xa0growth\\xa0and\\xa0cash\\xa0generation\\xa0enabled us to make significant investments in the business and deliver value\\xa0to\\xa0our\\xa0shareholders.\\xa0In\\xa02024,\\xa0we\\xa0allocated\\xa0more\\xa0than\\xa0$7 billion\\xa0to\\xa0research\\xa0and\\xa0development,\\xa0closed\\xa011\\xa0acquisitions to\\xa0enhance\\xa0our\\xa0capabilities,\\xa0and\\xa0returned\\xa0more\\xa0than\\xa0$6\\xa0billion\\n\\nto\\xa0shareholders\\xa0through\\xa0dividends.\\xa0IBM\\xa0expanded\\xa0operating gross profit margin by 130 basis points in 2024, driven by a focus on high-value offerings and productivity initiatives.\\n\\nSoftware revenue\\xa0grew\\xa09%\\xa0at\\xa0constant\\xa0currency,\\xa0reflecting strong\\xa0demand\\xa0for\\xa0our\\xa0advanced\\xa0capabilities\\xa0in\\xa0hybrid\\xa0cloud, data\\xa0and\\xa0AI,\\xa0automation,\\xa0transaction\\xa0processing,\\xa0and\\xa0security. Red\\xa0Hat\\xa0performed\\xa0well\\xa0as\\xa0clients\\xa0embraced\\xa0its\\xa0open\\xa0hybrid cloud\\xa0platform.\\n\\nConsulting revenue\\xa0increased\\xa01%\\xa0at\\xa0constant\\xa0currency, demonstrating\\xa0our\\xa0clients'\\xa0continued\\xa0need\\xa0for\\xa0expertise\\xa0in\\xa0AI deployment,\\xa0digital\\xa0transformation,\\xa0and\\xa0cloud\\xa0modernization, despite\\xa0a\\xa0dynamic\\xa0market\\xa0environment.\\n\\nIBM\\xa0has\\xa0established\\xa0an\\xa0early\\xa0leadership\\xa0position\\xa0in\\xa0this regard,\\xa0building\\xa0a\\xa0portfolio\\xa0of\\xa0enterprise\\xa0AI\\xa0offerings\\xa0focused on\\xa0generating\\xa0ROI\\xa0through\\xa0productivity\\xa0improvements\\xa0and automation.\\xa0IBM\\xa0watsonx\\xa0provides\\xa0a\\xa0robust\\xa0portfolio\\xa0of AI\\xa0products\\xa0for\\xa0developing\\xa0AI\\xa0apps,\\xa0managing\\xa0data,\\xa0and governing\\xa0the\\xa0entire\\xa0lifecycle\\xa0of\\xa0AI\\xa0models.\\xa0AI\\xa0assistants manage\\xa0key\\xa0tasks,\\xa0including\\xa0customer\\xa0service\\xa0and\\xa0writing code. We are developing pre-built AI agents that deliver multitask reasoning for specific business domains. And our Granite family of fit-for-purpose AI models, when tuned with proprietary data, can deliver enterprise-grade generative AI with up to 90% improved cost efficiency. Granite allows clients to\\xa0bring\\xa0their\\xa0own\\xa0data\\xa0into\\xa0the\\xa0models,\\xa0and\\xa0can\\xa0be\\xa0trained\\xa0on that\\xa0data\\xa0in\\xa0weeks,\\xa0not\\xa0months.\\n\\nInfrastructure revenue\\xa0declined\\xa03%\\xa0at\\xa0constant\\xa0currency,\\xa0in line\\xa0with\\xa0product\\xa0cycle\\xa0expectations.\\xa0IBM\\xa0z16\\xa0is\\xa0now\\xa0the\\xa0most successful\\xa0mainframe\\xa0program\\xa0in\\xa0our\\xa0history,\\xa0highlighting\\xa0its enduring\\xa0value\\xa0to\\xa0clients.\",\n",
       "   \"## Financial Performance Summary\\n\\nIn 2024, we reported $62.8 billion in revenue, income from continuing operations of $6.0 billion, which includes the impact of the pension  settlement  charges  of  $3.1  billion  ($2.4  billion  net  of  tax),  and  operating  (non-GAAP)  earnings  of  $9.7  billion,  which excludes the impact of the pension settlement charges. Refer to 'Organization of Information,' for additional information. Diluted earnings per share from continuing operations was $6.42 as reported, including an impact of $2.57 from the pension settlement charges, and diluted earnings per share was $10.33 on an operating (non-GAAP) basis. We generated $13.4 billion in cash from operations  and  $12.7  billion  in  free  cash  flow,  and  returned  $6.1  billion  to  shareholders  in  dividends.  We  are  pleased  with  the progress we made in 2024, delivering revenue growth in our re-positioned business and strong cash flow generation. Our 2024 performance demonstrates the success of our focused strategy, enhanced portfolio and sustainable revenue growth. We increased our  investment  in  innovation  and  talent  and  completed  eleven  acquisitions  in  2024,  strengthening  our  hybrid  cloud  and  AI capabilities, all while continuing to return value to shareholders through our dividend.\\n\\nTotal revenue grew 1.4 percent year to year as reported and 3 percent adjusted for currency compared to the prior year, led by our Software performance. Software revenue increased 8.3 percent as reported and 9.0 percent adjusted for currency, with strength across our portfolio. Hybrid Platform &amp; Solutions increased 8.1 percent as reported and 8.7 percent adjusted for currency, reflecting growth across all lines of business with double-digit revenue growth in Red Hat and Automation. Transaction Processing increased 8.7 percent as reported and 9.6 percent adjusted for currency, with growth in both recurring and transactional revenue. Consulting revenue decreased 0.9 percent as reported but grew 0.6 percent adjusted for currency, and continued to be impacted by a dynamic market environment as clients reprioritized spending. Infrastructure decreased 3.9 percent year to year as reported and 2.7 percent adjusted for currency, reflecting product cycle dynamics.\\n\\nFrom  a  geographic  perspective,  Americas  revenue  decreased  1.3  percent  year  to  year  as  reported  (0.7  percent  adjusted  for currency).  Europe/Middle East/Africa (EMEA) increased 5.1 percent as reported (4.7 percent adjusted for currency). Asia Pacific grew 3.0 percent as reported (7.9 percent adjusted for currency).\\n\\nGross  margin  of  56.7  percent  increased  1.2  points  year  to  year,  with  continued  margin  expansion  driven  by  portfolio  mix  and ongoing productivity initiatives. Operating (non-GAAP) gross margin of 57.8 percent increased 1.3 points versus the prior year, due to the same dynamics.\\n\\nTotal expense and other (income) increased 16.2 percent in 2024 versus the prior year primarily driven by the pension settlement charges of $3.1 billion in 2024, higher spending reflecting our continued investment in portfolio innovation to drive our strategy and higher  workforce rebalancing charges. This was partially offset by a gain from the sale of certain QRadar Software-as-a-Service (SaaS) assets, the gain on the divestiture of The Weather Company assets, the benefits from productivity and the actions taken to transform  our  operations,  and  the  effects  of  currency.  Total  operating  (non-GAAP)  expense  and  other  (income)  increased  1.8 percent year to year, driven primarily by the factors described above, excluding the pension settlement charges.\\n\\nPre-tax income from continuing operations was $5.8 billion in 2024 compared with $8.7 billion in the prior year and pre-tax margin was  9.2  percent,  a  decrease  of  4.8  points  versus  2023.  The  year-to-year  performance  was  primarily  driven  by  the  pension settlement charges in 2024 partially offset by our gross margin expansion and the benefits from productivity and the actions taken to transform our operations which enabled investments to drive innovation. The continuing operations effective tax rate for 2024 was (3.8) percent compared to 13.5 percent in 2023. The current-year effective tax rate was primarily driven by the tax impact of the pension settlement charges and the resolution of certain tax audit matters. Net income from continuing operations was $6.0 billion in 2024 compared with $7.5 billion in the prior year and net income from continuing operations margin was 9.6 percent, a decrease of 2.6 points year to year. Operating (non-GAAP) pre-tax income from continuing operations of $11.2 billion increased 8.7 percent year to year and the operating (non-GAAP) pre-tax margin from continuing operations increased 1.2 points to 17.9 percent. Our revenue growth, portfolio mix and productivity initiatives resulted in strong operating (non-GAAP) pre-tax income growth in 2024 compared to the prior year. The operating (non-GAAP) effective tax rate for 2024 was 13.6 percent compared to 14.0 percent\"],\n",
       "  'response': \"Based on IBM's 2024 Annual Report, the company's financial performance and strategic initiatives suggest a positive outlook for sustaining or increasing dividend payouts to shareholders. The report highlights IBM's strong cash generation, with $12.7 billion in free cash flow, an increase of $1.5 billion year-over-year. Additionally, the company's revenue growth, with $62.8 billion in revenue, up 3% at constant currency, and its significant investments in research and development, acquisitions, and shareholder returns, demonstrate its ability to generate cash and deliver value to shareholders. The report also mentions that the company's Board of Directors considers the dividend payment on a quarterly basis and has increased the quarterly common stock dividend in the past. Overall, IBM's financial performance and strategic initiatives suggest that the company is well-positioned to sustain or increase dividend payouts to shareholders. \\n\\nNote: The answer is based solely on the provided context information and does not take into account any external knowledge or prior information about IBM or its financial performance. \\n\\nPlease let me know if you want me to revise or expand the answer. \\n\\nAlso, I can help with any other questions or tasks you may have. \\n\\nPlease feel free to ask! \\n\\nBest regards! \\n\\nNote: I used the information from page 1, 10, 12, 27, 35, 37, 51, and 53 to answer the question. \\n\\nPlease let me know if you need any further assistance! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I tried to provide a clear and concise answer based on the provided context information. \\n\\nIf you need any further clarification or details, please let me know! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I used the information from the different pages to get a comprehensive understanding of IBM's financial performance and strategic initiatives. \\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: I hope this answer helps! \\n\\nLet me know if you have any other questions or need further clarification! \\n\\nI'm here to help! \\n\\nBest regards! \\n\\nNote: Please let me know if you need any further assistance or have any other questions! \\n\\nI'm here to help! \\n\\nBest regards!\",\n",
       "  'retrieved_contexts': ['1\\nFinancial Position\\nDynamics\\nOur balance sheet at December\\xa031, 2024 continues to provide us with flexibility to support and invest in the business. \\nCash and cash equivalents, restricted cash and marketable securities at December\\xa031, 2024 were $14,804 million, an increase of \\n$1,342 million compared to prior-year end. Total debt of $54,973 million decreased $1,574 million compared to December 31, \\n2023. We continue to manage our debt levels while being acquisitive and without sacrificing investments in our business.\\nDuring 2024, we generated $13,445 million in cash from operating activities, compared to $13,931 million in 2023. While cash \\nprovided by financing receivables declined year to year from business variability, we had performance-related improvements within \\nnet income driving an increase within cash from operating activities. Our free cash flow for 2024 was $12,749 million, an increase of \\n$1,538 million versus the prior year. Refer to page 35 for additional information on free cash flow. Our cash generation enables us to \\ncontinue investing in innovation and expertise across the portfolio, while returning value to shareholders through dividends.  We \\ninvested $3,289 million in acquisitions and returned $6,147 million to shareholders through dividends in 2024. \\nConsistent with accounting standards, the company remeasured the funded status of our retirement and postretirement plans at \\nDecember 31. The overall net underfunded position at December\\xa031, 2024  was $2,657 million, a decrease of $1,348 million from \\nthe prior-year end, primarily due to higher discount rates. At year end, our qualified defined benefit pension plans were well funded \\nand the required contributions related to these plans and multi-employer plans are expected to be $100 million in 2025. In 2024, \\nthe return on the U.S. Personal Pension Plan assets was 2.6 percent and the plan was 136 percent funded at December\\xa031, 2024. \\nOverall, global asset returns were 2.0 percent and the qualified defined benefit plans worldwide were 116 percent funded at \\nDecember\\xa031, 2024. \\nIBM Working Capital\\n($ in millions)\\nAt December 31: 2024 2023\\nCurrent assets $ 34,482 $ 32,908 \\nCurrent liabilities $ 33,142 $ 34,122 \\nWorking capital $ 1,340 $ (1,214) \\nCurrent ratio 1.04:1    0.96:1    \\nWorking capital increased $2,554 million from the year-end 2023 position. Current assets increased $1,574 million ($2,707 million\\nadjusted for currency) primarily in cash and cash equivalents, and short-term financing receivables. Current liabilities decreased \\n$980 million (increased $37 million adjusted for currency) as a result of a decrease in short-term debt mainly due to maturities; \\npartially offset by an increase in deferred income.\\nReceivables and Allowances\\nRoll Forward of Total IBM Receivables Allowance for Credit Losses\\n($ in millions)\\nJanuary 1, 2024\\nAdditions/ \\n(Releases) (1) Write-offs (2)\\nForeign currency \\nand other (3) December 31, 2024\\n$457 $(18) $(146) $(21) $273\\n(1) Additions/(Releases) for allowance for credit losses are recorded in expense.\\n(2) Refer to note A, “Significant Accounting Policies,” for additional information regarding allowance for credit loss write-offs.\\n(3) Other includes additions/(releases) related to discontinued operations.\\nExcluding receivables classified as held for sale, the total IBM receivables provision coverage was 1.4 percent  at December\\xa0 31, \\n2024, a decrease of 80 basis points compared to December\\xa0 31, 2023. The decrease in coverage is due to declines in reserves \\nprimarily driven by write-offs. The majority of the write-offs during the year were related to receivables which had been previously \\nreserved and were considered uncollectible as the related customer is no longer in operation, or there was no reasonable \\nexpectation of repossession or additional collections primarily due to the age of the receivables. Write-offs also includes about $60 \\nmillion of previously reserved receivables from discontinued operations. Refer to Financing’s “Financial Position” on page 42  for \\nadditional details regarding the Financing segment receivables and allowances. \\nManagement Discussion\\nInternational Business Machines Corporation and Subsidiary Companies\\n25',\n",
       "   'in 2023. Operating (non-GAAP) income from continuing operations of $9.7 billion increased 9.2 percent and the operating (non-\\nGAAP) income margin from continuing operations of 15.4 percent was up 1.1 points year to year. \\nDiluted earnings per share from continuing operations, which included an impact of $2.57 from the pension settlement charges, was \\n$6.42 in 2024 compared with $8.15 in 2023. Operating (non-GAAP) diluted earnings per share of $10.33 increased 7.4 percent \\nversus 2023.\\nAt December\\xa031, 2024, the balance sheet remained strong with financial flexibility to support and invest in the business. Cash and \\ncash equivalents, restricted cash and marketable securities at year end were $14.8 billion, an increase of $1.3 billion  from \\nDecember\\xa0 31, 2023. During 2024, we invested $3.3 billion in acquisitions and returned $6.1 billion to shareholders through \\ndividends. Total debt of $55.0 billion  at December\\xa0 31, 2024 decreased $1.6 billion driven by maturities partially offset by debt \\nissuances. \\nTotal assets increased $1.9 billion  ($5.2 billion adjusted for currency) from December\\xa031, 2023 primarily driven by an increase in \\ngoodwill mainly related to the StreamSets and webMethods acquisition, and higher cash and cash equivalents. Total liabilities \\ndecreased $2.8 billion (increased $0.5 billion adjusted for currency) from December\\xa031, 2023 primarily driven by a decrease in debt \\nand postretirement benefit obligations partially offset by an increase in deferred income. Total equity of $27.4 billion increased $4.8 \\nbillion from December\\xa0 31, 2023, primarily driven by net income , common stock issuances and a decrease in accumulated other \\ncomprehensive loss; partially offset by dividends. \\nDuring 2024, we generated $13.4 billion  in cash from operating activities, compared to $13.9 billion  in 2023. While cash provided \\nby financing receivables declined year to year  from business variability, we had performance-related improvements within net \\nincome driving an increase within cash from operating activities. Our free cash flow was $12.7 billion, an increase of $1.5 billion \\nversus the prior year. Refer to page 35 for additional information on free cash flow. Net cash used in investing activities of $4.9 \\nbillion decreased $2.1 billion compared to the prior year, mainly driven by a decrease in cash used in acquisitions, higher cash \\nprovided by divestitures and the proceeds from the sale of certain QRadar SaaS assets; partially offset by higher net purchases of \\nmarketable securities and other investments. Net cash used in financing activities of $7.1 billion increased $5.3 billion compared to \\n2023, mainly due to a lower level of debt issuances and a higher level of maturities in the current year.\\n10 Management Discussion\\nInternational Business Machines Corporation and Subsidiary Companies',\n",
       "   'In 2024, net capital expenditures and net cash from operating activities include $0.4 \\nbillion and $0.1 billion, respectively, of cash proceeds from the sale of certain QRadar SaaS assets. This benefit to net capital \\nexpenditures, net cash from operating activities and to free cash flow represented only a nominal net benefit to current-year cash \\nflows due to payments for structural actions and foregone profit from the QRadar business. Refer to note E, “Acquisitions & \\nDivestitures,” for additional information. In 2024, we continued to return value to shareholders with $6.1 billion in dividends and \\ninvested $3.3 billion in acquisitions. \\nIBM’s Board of Directors considers the dividend payment on a quarterly basis. In the second quarter of 2024, the Board of Directors \\nincreased the company’s quarterly common stock dividend from $1.66 to $1.67 per share. Beginning in the first quarter of 2025, we \\nexpect to file our quarterly reports on Form 10-Q closer to the timing of our quarterly earnings release, which may not coincide with \\nthe timing of our Board of Directors meeting. If the company’s Board of Directors approves a common stock dividend following the \\nfiling, the company will disclose this event in a current report on Form 8-K.\\nEvents that could temporarily change the historical cash flow dynamics discussed previously include significant changes in \\noperating results, material changes in geographic sources of cash, unexpected adverse impacts from litigation, future pension \\nManagement Discussion\\nInternational Business Machines Corporation and Subsidiary Companies\\n35',\n",
       "   '($ in millions except per share amounts)\\nCommon \\nStock and \\nAdditional \\nPaid-in \\nCapital\\nRetained \\nEarnings\\nTreasury \\nStock\\nAccumulated \\nOther \\nComprehensive \\nIncome/(Loss)\\nTotal IBM \\nStockholders’ \\nEquity\\nNon-\\nControlling \\nInterests\\nTotal \\nEquity\\n2024\\nEquity, January 1, 2024 $ 59,643 $ 151,276 $ (169,624) $ (18,761) $ 22,533 $ 80 $ 22,613 \\nNet income plus other \\ncomprehensive income/(loss)\\nNet income  6,023  6,023  6,023 \\nOther comprehensive income/\\n(loss)  3,492  3,492  3,492 \\nTotal comprehensive income $ 9,516 $ 9,516 \\nCash dividends paid—common \\nstock ($6.67 per share)  (6,147)  (6,147)  (6,147) \\nCommon stock issued under \\nemployee plans (12,253,153\\nshares)  1,737  1,737  1,737 \\nPurchases (3,430,885 shares) and \\nsales (2,454,155 shares) of \\ntreasury stock under employee \\nplans—net  11  (343)  (332)  (332) \\nChanges in noncontrolling interests  6  6 \\nEquity, December 31, 2024 $ 61,380 $ 151,163 $ (169,968) $ (15,269) $ 27,307 $ 86 $ 27,393 \\n Amounts may not add due to rounding.\\nThe accompanying notes are an integral part of the financial statements.\\nConsolidated Statement of Equity\\nInternational Business Machines Corporation and Subsidiary Companies\\n51',\n",
       "   'IBM\\xa02024\\xa0Annual\\xa0Report 1\\nArvind\\xa0Krishna\\nChairman, President and Chief Executive Officer\\nDear\\xa0IBM\\xa0Investor:\\nIn 2024, IBM made significant \\nprogress\\xa0in\\xa0becoming\\xa0a\\xa0higher\\xa0growth,\\xa0\\nhigher\\xa0margin\\xa0business.\\xa0We\\xa0made\\xa0this\\xa0\\nprogress\\xa0by\\xa0combining\\xa0technology\\xa0\\ninnovation\\xa0and\\xa0consulting\\xa0expertise\\xa0\\nto\\xa0drive\\xa0growth,\\xa0improve\\xa0productivity,\\xa0\\nand enhance operational efficiency -- \\nfor\\xa0our\\xa0clients,\\xa0and\\xa0our\\xa0own\\xa0company.\\xa0\\nOur\\xa0strategy\\xa0continues\\xa0to\\xa0build\\xa0upon\\xa0the\\xa0two\\xa0technological\\xa0\\nfoundations\\xa0of\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud,\\xa0which\\xa0clients\\xa0need\\xa0to\\xa0\\nunlock\\xa0the\\xa0full\\xa0value\\xa0of\\xa0their\\xa0data.\\xa0We\\xa0have\\xa0made\\xa0a\\xa0series\\xa0of\\xa0\\ninvestments\\xa0to\\xa0accelerate\\xa0the\\xa0delivery\\xa0of\\xa0that\\xa0value\\xa0to\\xa0our\\xa0\\nclients,\\xa0from\\xa0transforming\\xa0the\\xa0way\\xa0we\\xa0work\\xa0to\\xa0reorienting\\xa0our\\xa0\\nportfolio around powerful, AI-based solutions. \\nAs\\xa0this\\xa0report\\xa0demonstrates,\\xa0these\\xa0investments\\xa0are\\xa0paying\\xa0\\noff,\\xa0delivering\\xa0meaningful\\xa0returns\\xa0for\\xa0our\\xa0shareholders,\\xa0\\nclients, and partners. Today, IBM is a software-led, fully \\nintegrated\\xa0platform\\xa0company,\\xa0built\\xa0to\\xa0grow\\xa0sustainably.\\xa0This\\xa0\\nis\\xa0the\\xa0ROI\\xa0of\\xa0IBM.\\n2024\\xa0Performance\\nFor\\xa0the\\xa0year,\\xa0IBM\\xa0generated\\xa0$62.8\\xa0billion\\xa0in\\xa0revenue,\\xa0up\\xa03%\\xa0\\nat\\xa0constant\\xa0currency,\\xa0and\\xa0$12.7\\xa0billion\\xa0in\\xa0free\\xa0cash\\xa0flow\\xa0—\\xa0an\\xa0\\nincrease of $1.5 billion year-over-year. Our generative AI \\nbook\\xa0of\\xa0business\\xa0now\\xa0stands\\xa0at\\xa0more\\xa0than\\xa0$5\\xa0billion\\xa0since\\xa0\\ninception.\\xa0This\\xa0revenue\\xa0growth\\xa0and\\xa0cash\\xa0generation\\xa0enabled\\xa0\\nus to make significant investments in the business and deliver \\nvalue\\xa0to\\xa0our\\xa0shareholders.\\xa0In\\xa02024,\\xa0we\\xa0allocated\\xa0more\\xa0than\\xa0$7\\xa0\\nbillion\\xa0to\\xa0research\\xa0and\\xa0development,\\xa0closed\\xa011\\xa0acquisitions\\xa0\\nto\\xa0enhance\\xa0our\\xa0capabilities,\\xa0and\\xa0returned\\xa0more\\xa0than\\xa0$6\\xa0billion']},\n",
       " {'user_input': 'Based on the trends and projections outlined in the IBM 2024 Annual Report, what strategic initiatives is IBM likely to prioritize to enhance its competitive position in the technology sector over the next five years?',\n",
       "  'reference': 'Based on the trends and projections outlined in the IBM 2024 Annual Report, IBM is likely to prioritize the following strategic initiatives to enhance its competitive position in the technology sector over the next five years:\\n\\n1. **Focus on AI and Hybrid Cloud**: IBM will continue to build upon its technological foundations of AI and hybrid cloud, as these are seen as transformative technologies that unlock the full value of data for clients. This includes further development and deployment of AI solutions like watsonx and the Granite family of AI models.\\n\\n2. **Expansion of Software and Consulting Services**: With approximately 75 percent of its business mix in Software and Consulting, IBM will likely continue to expand these areas. This includes enhancing its software offerings, particularly in hybrid cloud, data and AI, automation, and security, as well as growing its consulting services to support AI deployment and digital transformation.\\n\\n3. **Investment in Research and Development**: IBM allocated more than $7 billion to research and development in 2024, and this trend is likely to continue. This investment will support innovation in AI, hybrid cloud, and other high-value offerings.\\n\\n4. **Acquisitions and Partnerships**: IBM closed 11 acquisitions in 2024 to enhance its capabilities. Continuing this strategy will help IBM expand its technological expertise and market reach. Additionally, maintaining a broad ecosystem of partners and alliances will be crucial for delivering integrated solutions.\\n\\n5. **Enhancing Operational Efficiency and Productivity**: IBM aims to improve productivity and operational efficiency, both for itself and its clients. This includes leveraging AI for automation and productivity improvements, as well as optimizing IT spending and reducing operational complexity through solutions like OpenShift and Ansible.\\n\\n6. **Sustainable Growth and Value Delivery**: IBM is focused on becoming a software-led, fully integrated platform company built for sustainable growth. This involves delivering meaningful returns for shareholders, clients, and partners through strategic investments and innovation.\\n\\nBy prioritizing these initiatives, IBM aims to strengthen its leadership position in the technology sector and drive long-term growth.',\n",
       "  'reference_contexts': [\"## 2024\\xa0Performance\\n\\nFor\\xa0the\\xa0year,\\xa0IBM\\xa0generated\\xa0$62.8\\xa0billion\\xa0in\\xa0revenue,\\xa0up\\xa03% at\\xa0constant\\xa0currency,\\xa0and\\xa0$12.7\\xa0billion\\xa0in\\xa0free\\xa0cash\\xa0flow\\xa0-\\xa0an increase of $1.5 billion year-over-year. Our generative AI book\\xa0of\\xa0business\\xa0now\\xa0stands\\xa0at\\xa0more\\xa0than\\xa0$5\\xa0billion\\xa0since inception.\\xa0This\\xa0revenue\\xa0growth\\xa0and\\xa0cash\\xa0generation\\xa0enabled us to make significant investments in the business and deliver value\\xa0to\\xa0our\\xa0shareholders.\\xa0In\\xa02024,\\xa0we\\xa0allocated\\xa0more\\xa0than\\xa0$7 billion\\xa0to\\xa0research\\xa0and\\xa0development,\\xa0closed\\xa011\\xa0acquisitions to\\xa0enhance\\xa0our\\xa0capabilities,\\xa0and\\xa0returned\\xa0more\\xa0than\\xa0$6\\xa0billion\\n\\nto\\xa0shareholders\\xa0through\\xa0dividends.\\xa0IBM\\xa0expanded\\xa0operating gross profit margin by 130 basis points in 2024, driven by a focus on high-value offerings and productivity initiatives.\\n\\nSoftware revenue\\xa0grew\\xa09%\\xa0at\\xa0constant\\xa0currency,\\xa0reflecting strong\\xa0demand\\xa0for\\xa0our\\xa0advanced\\xa0capabilities\\xa0in\\xa0hybrid\\xa0cloud, data\\xa0and\\xa0AI,\\xa0automation,\\xa0transaction\\xa0processing,\\xa0and\\xa0security. Red\\xa0Hat\\xa0performed\\xa0well\\xa0as\\xa0clients\\xa0embraced\\xa0its\\xa0open\\xa0hybrid cloud\\xa0platform.\\n\\nConsulting revenue\\xa0increased\\xa01%\\xa0at\\xa0constant\\xa0currency, demonstrating\\xa0our\\xa0clients'\\xa0continued\\xa0need\\xa0for\\xa0expertise\\xa0in\\xa0AI deployment,\\xa0digital\\xa0transformation,\\xa0and\\xa0cloud\\xa0modernization, despite\\xa0a\\xa0dynamic\\xa0market\\xa0environment.\\n\\nIBM\\xa0has\\xa0established\\xa0an\\xa0early\\xa0leadership\\xa0position\\xa0in\\xa0this regard,\\xa0building\\xa0a\\xa0portfolio\\xa0of\\xa0enterprise\\xa0AI\\xa0offerings\\xa0focused on\\xa0generating\\xa0ROI\\xa0through\\xa0productivity\\xa0improvements\\xa0and automation.\\xa0IBM\\xa0watsonx\\xa0provides\\xa0a\\xa0robust\\xa0portfolio\\xa0of AI\\xa0products\\xa0for\\xa0developing\\xa0AI\\xa0apps,\\xa0managing\\xa0data,\\xa0and governing\\xa0the\\xa0entire\\xa0lifecycle\\xa0of\\xa0AI\\xa0models.\\xa0AI\\xa0assistants manage\\xa0key\\xa0tasks,\\xa0including\\xa0customer\\xa0service\\xa0and\\xa0writing code. We are developing pre-built AI agents that deliver multitask reasoning for specific business domains. And our Granite family of fit-for-purpose AI models, when tuned with proprietary data, can deliver enterprise-grade generative AI with up to 90% improved cost efficiency. Granite allows clients to\\xa0bring\\xa0their\\xa0own\\xa0data\\xa0into\\xa0the\\xa0models,\\xa0and\\xa0can\\xa0be\\xa0trained\\xa0on that\\xa0data\\xa0in\\xa0weeks,\\xa0not\\xa0months.\\n\\nInfrastructure revenue\\xa0declined\\xa03%\\xa0at\\xa0constant\\xa0currency,\\xa0in line\\xa0with\\xa0product\\xa0cycle\\xa0expectations.\\xa0IBM\\xa0z16\\xa0is\\xa0now\\xa0the\\xa0most successful\\xa0mainframe\\xa0program\\xa0in\\xa0our\\xa0history,\\xa0highlighting\\xa0its enduring\\xa0value\\xa0to\\xa0clients.\",\n",
       "   '## Dear\\xa0IBM\\xa0Investor:\\n\\nIn 2024, IBM made significant progress\\xa0in\\xa0becoming\\xa0a\\xa0higher\\xa0growth, higher\\xa0margin\\xa0business.\\xa0We\\xa0made\\xa0this progress\\xa0by\\xa0combining\\xa0technology innovation\\xa0and\\xa0consulting\\xa0expertise to\\xa0drive\\xa0growth,\\xa0improve\\xa0productivity, and enhance operational efficiency -for\\xa0our\\xa0clients,\\xa0and\\xa0our\\xa0own\\xa0company.\\n\\nOur\\xa0strategy\\xa0continues\\xa0to\\xa0build\\xa0upon\\xa0the\\xa0two\\xa0technological foundations\\xa0of\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud,\\xa0which\\xa0clients\\xa0need\\xa0to unlock\\xa0the\\xa0full\\xa0value\\xa0of\\xa0their\\xa0data.\\xa0We\\xa0have\\xa0made\\xa0a\\xa0series\\xa0of investments\\xa0to\\xa0accelerate\\xa0the\\xa0delivery\\xa0of\\xa0that\\xa0value\\xa0to\\xa0our clients,\\xa0from\\xa0transforming\\xa0the\\xa0way\\xa0we\\xa0work\\xa0to\\xa0reorienting\\xa0our portfolio around powerful, AI-based solutions.\\n\\nAs\\xa0this\\xa0report\\xa0demonstrates,\\xa0these\\xa0investments\\xa0are\\xa0paying off,\\xa0delivering\\xa0meaningful\\xa0returns\\xa0for\\xa0our\\xa0shareholders, clients, and partners. Today, IBM is a software-led, fully integrated\\xa0platform\\xa0company,\\xa0built\\xa0to\\xa0grow\\xa0sustainably.\\xa0This is\\xa0the\\xa0ROI\\xa0of\\xa0IBM.',\n",
       "   \"## IBM Strategy\\n\\nOver the past 5 years, IBM has shifted to higher growth areas, with approximately 75 percent of our business mix in Software and Consulting. Our strategic focus is hybrid cloud and artificial intelligence (AI), today's most transformative technologies. As clients drive business growth using their existing technology and investing in new ones, they seek flexibility across distributed technology environments and the need to realize value from AI. We have shaped our business to focus on those client needs.\",\n",
       "   \"## Management Discussion\\n\\nInternational Business Machines Corporation and Subsidiary Companies\\n\\nSoftware revenue of $27,085 million increased 8.3 percent as reported (9.0 percent adjusted for currency) in 2024 compared to the prior year, reflecting growth across all lines of business with double-digit growth in Red Hat and Automation and high single-digit growth  in  Transaction  Processing.  This  revenue  performance  reflects  the  investments  we  have  been  making  in  Software,  both organically and through acquisitions. Our investments in generative AI are contributing to growth, as we had strong demand for our generative AI products such as watsonx, Concert and our AI assistants. We also launched new products in the fourth quarter of 2024  including  our  next  generation  of  watsonx  Code  Assistant  and  Guardium  Quantum  Safe.  In  2024,  we  also  had  increased revenue contribution from acquisitions compared to the prior year, including Apptio and StreamSets and webMethods. In addition, we  had  solid  growth  in  our  recurring  revenue  and  double-digit  growth  in  our  transactional  software  revenue  in  2024,  as  we accelerated growth through innovation across our Software portfolio.\\n\\nHybrid Platform &amp; Solutions revenue of $18,808 million increased 8.1 percent as reported (8.7 percent adjusted for currency) in 2024 compared to the prior year. Within Hybrid Platform &amp; Solutions, Red Hat revenue increased 11.4 percent as reported (12.0 percent  adjusted  for  currency),  which  reflects  the  continued  demand  for  our  hybrid  cloud  solutions  as  clients  are  prioritizing application modernization on OpenShift containers and Ansible automation to optimize their IT spending and reduce operational complexity. In 2024, we had double-digit revenue growth in OpenShift and Ansible, and high single-digit revenue growth in RHEL. The  growth  in  OpenShift  revenue  reflects  increased  volume  in  OpenShift  Virtualization  engagements,  and  we  exited  2024  with OpenShift annual recurring revenue of $1.4 billion. Automation revenue increased 14.2 percent as reported (14.8 percent adjusted for  currency),  driven  by  our  SaaS  subscription  offerings  such  as  AIOps  and  Management,  which  includes  the  higher  revenue contribution  from Apptio.  Data  &amp;  AI  revenue  increased  1.6  percent  as  reported  (2.2  percent  adjusted  for  currency),  with  strong growth in  Data  Fabric  and  our  AI  assistant  for  Customer  Care,  driven  by  client  demand  for  our  watsonx  platform  offerings,  and strength  in  asset  and  supply  chain  management  software  which  helps  clients  run  sustainable  operations.  Security  revenue increased 0.8 percent as reported (1.5 percent adjusted for currency), with revenue growth in data security and identity and access management, partially offset by a revenue decline in security threat management.\\n\\nAcross Hybrid Platform &amp; Solutions, our annual recurring revenue (ARR) was $15.3 billion exiting 2024, growing at a double-digit rate compared to the prior year. ARR is a key performance metric management uses to assess the health and growth trajectory of our  Hybrid  Platform  &amp;  Solutions  business  within  the  Software  segment.  The  metric  was  updated  in  the  first  quarter  of 2024  to reflect the organizational changes described in the 'Organization of Information' section above, and to simplify the calculation. ARR is  calculated  by  using  the  current  quarter's  recurring  revenue  and  then  multiplying  that  value  by  four.  This  value  includes  the following  consumption  models:  (1)  software  subscription  agreements,  including  committed  term  licenses,  (2)  as-a-service arrangements such as SaaS and PaaS, and (3) maintenance and support contracts. ARR should be viewed independently of revenue as this performance metric and its inputs may not represent revenue that will be recognized in future periods.\\n\\nTransaction Processing revenue of $8,277 million increased 8.7 percent as reported (9.6 percent adjusted for currency) in 2024 compared to the prior year. The performance in 2024 is the result of the combination of clients' growing capacity demands, solid renewal rates,  and  increased  contribution  from  our  generative  AI  products,  including  watsonx  code  assistant  for  Z.  This  growth reflects the innovation and value of our transaction processing software, which helps our clients manage their most mission-critical workloads.\",\n",
       "   \"## DESCRIPTION OF BUSINESS\\n\\nPlease refer to IBM's Annual Report on Form 10-K filed with the SEC on February\\xa025, 2025, for Item 1A. entitled 'Risk Factors.'\\n\\nIBM is addressing the hybrid cloud and AI opportunity with a platform-centric approach, focused on providing client value through a combination of technology and business expertise. We provide integrated solutions and products that leverage: data, information technology, deep expertise in industries and business processes, with trust and security and a broad ecosystem of partners and alliances. Our hybrid cloud platform and AI technology and services capabilities support clients' digital transformations and help them  engage  with  their  customers  and  employees  in  new  ways.  These  solutions  draw  from  an  industry-leading  portfolio  of capabilities in software, consulting services and a deep incumbency in mission-critical systems, all bolstered by one of the world's leading research organizations.\"],\n",
       "  'response': '1. Hybrid Cloud and AI Integration: IBM will likely prioritize the integration of hybrid cloud and AI technologies to drive business productivity and growth. This includes developing and acquiring AI-based solutions, enhancing its hybrid cloud platform, and promoting the adoption of containers for AI deployments.\\n2. Enterprise AI Offerings: IBM will focus on building a robust portfolio of enterprise AI offerings, including AI products for developing AI apps, managing data, and governing AI models. This will enable clients to generate return on investment through productivity improvements and automation.\\n3. Open Innovation Ecosystem: IBM will continue to promote an open innovation ecosystem around AI, leveraging partnerships with key industry leaders, and investing in emerging technologies like quantum computing.\\n4. Strategic Partnerships and Acquisitions: IBM will prioritize strategic partnerships and acquisitions to enhance its capabilities in hybrid cloud, data, and AI technologies, as well as to expand its reach and offerings in the market.\\n5. Client-Centric Approach: IBM will maintain a client-centric approach, focusing on delivering value to clients through its technology solutions and services, and leveraging its \"client zero\" philosophy to drive innovation and growth.\\n6. Research and Development: IBM will continue to invest in research and development, driving innovation in areas like AI, hybrid cloud, and quantum computing, and transitioning research into market-ready solutions.\\n7. Portfolio Optimization: IBM will focus on optimizing its portfolio, divesting non-core assets, and acquiring strategic assets to enhance its competitive position and drive growth.',\n",
       "  'retrieved_contexts': ['IBM\\xa02024\\xa0Annual\\xa0Report 1\\nArvind\\xa0Krishna\\nChairman, President and Chief Executive Officer\\nDear\\xa0IBM\\xa0Investor:\\nIn 2024, IBM made significant \\nprogress\\xa0in\\xa0becoming\\xa0a\\xa0higher\\xa0growth,\\xa0\\nhigher\\xa0margin\\xa0business.\\xa0We\\xa0made\\xa0this\\xa0\\nprogress\\xa0by\\xa0combining\\xa0technology\\xa0\\ninnovation\\xa0and\\xa0consulting\\xa0expertise\\xa0\\nto\\xa0drive\\xa0growth,\\xa0improve\\xa0productivity,\\xa0\\nand enhance operational efficiency -- \\nfor\\xa0our\\xa0clients,\\xa0and\\xa0our\\xa0own\\xa0company.\\xa0\\nOur\\xa0strategy\\xa0continues\\xa0to\\xa0build\\xa0upon\\xa0the\\xa0two\\xa0technological\\xa0\\nfoundations\\xa0of\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud,\\xa0which\\xa0clients\\xa0need\\xa0to\\xa0\\nunlock\\xa0the\\xa0full\\xa0value\\xa0of\\xa0their\\xa0data.\\xa0We\\xa0have\\xa0made\\xa0a\\xa0series\\xa0of\\xa0\\ninvestments\\xa0to\\xa0accelerate\\xa0the\\xa0delivery\\xa0of\\xa0that\\xa0value\\xa0to\\xa0our\\xa0\\nclients,\\xa0from\\xa0transforming\\xa0the\\xa0way\\xa0we\\xa0work\\xa0to\\xa0reorienting\\xa0our\\xa0\\nportfolio around powerful, AI-based solutions. \\nAs\\xa0this\\xa0report\\xa0demonstrates,\\xa0these\\xa0investments\\xa0are\\xa0paying\\xa0\\noff,\\xa0delivering\\xa0meaningful\\xa0returns\\xa0for\\xa0our\\xa0shareholders,\\xa0\\nclients, and partners. Today, IBM is a software-led, fully \\nintegrated\\xa0platform\\xa0company,\\xa0built\\xa0to\\xa0grow\\xa0sustainably.\\xa0This\\xa0\\nis\\xa0the\\xa0ROI\\xa0of\\xa0IBM.\\n2024\\xa0Performance\\nFor\\xa0the\\xa0year,\\xa0IBM\\xa0generated\\xa0$62.8\\xa0billion\\xa0in\\xa0revenue,\\xa0up\\xa03%\\xa0\\nat\\xa0constant\\xa0currency,\\xa0and\\xa0$12.7\\xa0billion\\xa0in\\xa0free\\xa0cash\\xa0flow\\xa0—\\xa0an\\xa0\\nincrease of $1.5 billion year-over-year. Our generative AI \\nbook\\xa0of\\xa0business\\xa0now\\xa0stands\\xa0at\\xa0more\\xa0than\\xa0$5\\xa0billion\\xa0since\\xa0\\ninception.\\xa0This\\xa0revenue\\xa0growth\\xa0and\\xa0cash\\xa0generation\\xa0enabled\\xa0\\nus to make significant investments in the business and deliver \\nvalue\\xa0to\\xa0our\\xa0shareholders.\\xa0In\\xa02024,\\xa0we\\xa0allocated\\xa0more\\xa0than\\xa0$7\\xa0\\nbillion\\xa0to\\xa0research\\xa0and\\xa0development,\\xa0closed\\xa011\\xa0acquisitions\\xa0\\nto\\xa0enhance\\xa0our\\xa0capabilities,\\xa0and\\xa0returned\\xa0more\\xa0than\\xa0$6\\xa0billion',\n",
       "   'In support for each business segment, our AI strategy focuses on four key differentiators to help address adoption and challenges: \\nOpen, Cost Efficient, Hybrid and Domain Expertise, which we deliver across our portfolio. We enable cheaper inferencing built for \\nhybrid cloud architectures with our Red Hat AI portfolio. We provide small, open Granite models that deliver better performance at a \\nfraction of the price. We embed domain expertise in our models, technologies, and consulting offerings to speed client adoption and \\nvalue.\\nIBM Research  continues to demonstrate the ability to transition research to market-ready solutions; reinventing how work gets \\ndone and building on its legacy of transforming innovation in computing into client-grade solutions. In 2024, we continued to \\ninnovate around hybrid cloud and AI which created new business opportunities for IBM, including Granite 3.0 models and \\nInstructLab. In quantum computing, we continue to progress along our Quantum Development & Innovation Roadmap, including the \\nrelease of the Heron quantum chip and launch of Qiskit 1.0 software development kit.\\nIn addition to organic innovation, we accelerate our strategy and client value with inorganic investments. Areas of focus include \\nhybrid cloud, data, and AI technology along with strategic consulting capabilities. In 2024 IBM closed multiple deals, the most \\nmaterial being the acquisition of assets from Software AG to bolster our automation, data and AI portfolios, and Neural Magic to fuel \\noptimized generative AI innovation across hybrid cloud. Additionally, we announced our intention to acquire HashiCorp, adding \\nadvanced capabilities in hybrid multi-cloud infrastructure automation and orchestration.\\nHybrid cloud and AI together have the power to unleash business productivity . IBM can bring hybrid cloud and AI to life for \\nclients through our portfolio across the various business segments. Each of our business segments contribute to and benefit from \\nthe hybrid cloud and AI strategy. Clients realize greater value when complementary parts of the portfolio come together. For \\nexample, within Consulting, we have the world’s largest Red Hat practice differentiated with hybrid by design methodologies, with \\nConsulting Advantage used to leverage AI across every stage of the project lifecycle. In IBM Z, watsonx code assistant for Z uses AI \\nto accelerate modernization journeys, delivering more value to clients.\\nCollaborating to create value with clients and ecosystem partners \\nBuilding our ecosystem is core to our overall strategy, focusing on helping clients transform their core operations and create new \\nsources of competitive advantage through the application of AI and hybrid cloud technologies. Our approach to client engagement \\nallows us to meet clients where they are. We bring our next-generation innovations and core platforms to a wide range of clients and \\npartners through our signature THINK event tour and IBM TechXchange conference. The Partner Plus program makes it easy for \\npartners to deepen technical expertise on IBM products, allowing clients more choice on who to partner with. Additionally, we \\ncontinue to co-invest with our strategic partners – Adobe, AWS, Microsoft, Oracle, Palo Alto Networks, Salesforce, SAP, ServiceNow \\n– to amplify joint impact for our clients by embedding IBM technology into core platforms that run their businesses.\\nWe also bring product innovations to clients through use cases, our internal “client zero” productivity proof points, and technical \\nexperiences to demonstrate the value of our technology as a source of competitive advantage. For example, we have resolved 94 \\npercent of low-level HR inquiries with our AskHR assistant, built on watsonx, freeing up HR professionals to focus on more complex \\nissues. We believe that being a client zero exemplar accelerates our product roadmap and commercial success in addition to \\ndelivering productivity to the business. \\nBusiness Segments and Capabilities\\nIBM operates in more than 175 countries around the world. Our platform-centric hybrid cloud and AI strategy is executed through \\nour operations and consists of four business segments: Software, Consulting, Infrastructure and Financing.\\nIn the first quarter of 2025, we announced\\xa0 changes\\xa0 to the reported revenue categories within our Software and Consulting \\nreportable segments effective January 1, 2025. These\\xa0 changes\\xa0 will not impact our Consolidated Financial Statements or our \\nreportable segments. Refer to “Looking Forward,” for additional information.\\nSoftware\\nSoftware provides software solutions that address client needs for a hybrid cloud platform, data and AI, automation, and security on \\ntheir journey to hybrid cloud. It includes all software, except operating system software reported in the Infrastructure segment.\\n12 Management Discussion\\nInternational Business Machines Corporation and Subsidiary Companies',\n",
       "   'OTHER INFORMATION\\nLooking Forward\\nTechnology has proven to be a fundamental source of competitive advantage and is now the key to sustainable growth and business \\ntransformation. Continued demand for technology will serve as a major driving force behind global economic and business growth \\nas businesses look to scale, offer better services, drive efficiencies and seize new market opportunities. AI-driven productivity, in \\nparticular, continues to be a top priority for businesses for both cost reductions and new revenue opportunities. \\nEnterprise AI continues to gain momentum. Our clients have moved beyond experimentation and are now looking to scale AI in their \\nbusinesses and generate return from their investments. The portfolio of AI offerings we have built is focused on generating that \\nreturn through productivity improvements and automation. We have infused AI across the business, from the tools clients use to \\nmanage and optimize their hybrid cloud environments, to the tools to deploy AI within their enterprise, to Infrastructure and \\nConsulting, there is AI innovation within all of our segments. For example, in Software, IBM watsonx provides a robust portfolio of AI \\nproducts for developing AI apps, managing data, and governing the entire lifecycle of AI models. Red Hat is bringing AI to the \\nplatform with innovation such as OpenShift AI and RHEL AI. In Transaction Processing, we are experiencing continued customer \\ninterest in our generative AI product, watsonx Code Assistant for Z. In Infrastructure, IBM Z is equipped with real time AI \\ninferencing capabilities. We continue to see Infrastructure play a larger role, enabling hybrid cloud environments for mission-critical \\ntransactions and AI workloads, as clients bring AI to their data. In Consulting, our experts are helping clients design and execute AI \\nstrategies by leveraging the IBM Consulting Advantage platform, an AI delivery platform designed to implement solutions at scale, \\ntransforming how our consultants work and harnessing AI across every stage of the project lifecycle.\\nWe are committed to an open innovation ecosystem around AI, to help our clients maximize flexibility and leverage skills, and IBM \\nwith Red Hat can be a key driver of open-source AI. In the second quarter of 2024, we open-sourced IBM’s Granite models, which \\nare designed for specific purposes and significantly more cost-efficient than larger alternatives, and we see parallels to how Linux \\nbecame a leader in the enterprise server space as a result of the speed and innovation offered by open source. Red Hat and IBM \\nalso launched InstructLab to evolve and improve AI models. Our partner ecosystem remains essential to both AI and hybrid cloud \\ngrowth and we continue to progress strategic partnerships with leading technology providers. In August 2024, we completed the \\nsale of certain IBM QRadar SaaS assets to Palo Alto, which is part of a partnership with them to deliver AI-powered security \\nsolutions using watsonx to clients. \\nWe continue to invest in emerging technologies, bringing new innovations to market. In 2024, we expanded our IBM Quantum Data \\nCenter in Poughkeepsie, New York and opened the first IBM Quantum Data Center in Europe. We also announced a partnership with \\nthe State of Illinois to build the National Quantum Algorithm Center in Chicago and deploy a next-generation IBM Quantum System \\nTwo, supporting the future of quantum-centric supercomputing and greatly advancing our goal of expanding access to the world’s \\nmost performant quantum computers. We also remained focused on portfolio optimization. In January 2024, we closed the \\ndivestiture of The Weather Company assets. To complement our portfolio, we completed eleven acquisitions in 2024, including the \\nacquisition of the StreamSets and webMethods assets from Software AG. This acquisition brings together leading capabilities in \\nintegration, API management, and data ingestion. At the end of 2024, we closed the acquisition of Neural Magic, which strengthens \\nour AI capabilities in performance engineering and model optimization.\\nOn April 24, 2024, we announced our intent to acquire all of the outstanding shares of HashiCorp. The combination of IBM’s and \\nHashiCorp’s combined portfolios will help clients manage growing application and infrastructure complexity and create a \\ncomprehensive end-to-end hybrid cloud platform designed for the AI era. Under the terms of the definitive agreement, HashiCorp \\nshareholders on record immediately prior to the effective time on the closing date will receive $35 per share in cash, representing a \\ntotal enterprise value of approximately $6.4 billion. On July 15, 2024, HashiCorp stockholders voted to approve the merger with \\nIBM. The transaction is expected to close in the first quarter of 2025, subject to regulatory approvals and other customary closing \\nconditions. Upon closing, HashiCorp will be integrated into the Software segment.',\n",
       "   'We\\xa0recognize\\xa0\\nthat\\xa0no\\xa0single\\xa0company\\xa0can\\xa0provide\\xa0all\\xa0the\\xa0technology\\xa0and\\xa0\\nskill\\xa0needed\\xa0to\\xa0drive\\xa0digital\\xa0transformation.\\xa0So,\\xa0we\\xa0have\\xa0\\nstrengthened\\xa0our\\xa0strategic\\xa0partnerships\\xa0with\\xa0key\\xa0industry\\xa0\\nleaders\\xa0like\\xa0AWS,\\xa0Microsoft,\\xa0Salesforce,\\xa0SAP,\\xa0Palo\\xa0Alto\\xa0\\nNetworks,\\xa0and\\xa0Oracle.\\xa0These\\xa0partnerships\\xa0serve\\xa0our\\xa0clients\\xa0\\nbetter\\xa0and\\xa0create\\xa0a\\xa0multiplier\\xa0effect\\xa0for\\xa0IBM.\\xa0\\nAdditionally,\\xa0IBM\\xa0has\\xa0adopted\\xa0a\\xa0“client\\xa0zero”\\xa0philosophy,\\xa0\\nmeaning we benefit from the same technology solutions \\nwe\\xa0offer\\xa0to\\xa0our\\xa0clients.\\xa0In\\xa0particular,\\xa0we\\xa0have\\xa0aggressively\\xa0\\nadopted AI-powered automation to drive productivity. For \\nexample,\\xa094%\\xa0of\\xa0IBM’s\\xa0basic\\xa0HR\\xa0queries\\xa0are\\xa0now\\xa0answered\\xa0\\nby\\xa0an\\xa0AI\\xa0assistant.\\xa0Our\\xa0contract\\xa0drafting\\xa0process\\xa0is\\xa0now\\xa080%\\xa0\\nfaster.\\xa0Overall,\\xa0we\\xa0have\\xa0delivered\\xa0approximately\\xa0$3.5\\xa0billion\\xa0in\\xa0\\nproductivity\\xa0savings\\xa0since\\xa0the\\xa0beginning\\xa0of\\xa02023.\\xa0These\\xa0efforts\\xa0\\nare not just about efficiency. They are the engine of innovation \\nand\\xa0growth\\xa0that\\xa0allows\\xa0us\\xa0to\\xa0invest\\xa0in\\xa0our\\xa0business\\xa0and\\xa0serve\\xa0\\nour\\xa0clients\\xa0better.\\xa0\\nA\\xa0new\\xa0era\\xa0of\\xa0innovation\\nThe\\xa0mission\\xa0of\\xa0IBM\\xa0Research\\xa0has\\xa0always\\xa0been\\xa0to\\xa0invent\\xa0\\nwhat’s\\xa0next\\xa0in\\xa0computing\\xa0–\\xa0creating\\xa0solutions\\xa0that\\xa0meet\\xa0the\\xa0\\nneeds of our clients, thereby defining the future of information \\ntechnology.\\xa0Today,\\xa0Research\\xa0is\\xa0driving\\xa0powerful\\xa0innovations\\xa0\\nacross\\xa0hardware,\\xa0software,\\xa0hybrid\\xa0cloud,\\xa0AI,\\xa0and\\xa0quantum\\xa0\\ncomputing,\\xa0all\\xa0of\\xa0which\\xa0creates\\xa0value\\xa0for\\xa0our\\xa0clients\\xa0and\\xa0\\ngrowth\\xa0opportunities\\xa0for\\xa0our\\xa0company.\\nFor\\xa0example,\\xa0to\\xa0better\\xa0serve\\xa0clients\\xa0who\\xa0told\\xa0us\\xa0that\\xa0the\\xa0\\nlarge,\\xa0unwieldy\\xa0generative\\xa0AI\\xa0models\\xa0on\\xa0the\\xa0market\\xa0were\\xa0\\ntoo\\xa0unreliable\\xa0and\\xa0expensive,\\xa0IBM\\xa0Research\\xa0developed\\xa0the\\xa0\\nopen\\xa0and\\xa0trusted\\xa0Granite\\xa0family\\xa0of\\xa0models,\\xa0released\\xa0under\\xa0\\nthe\\xa0permissive\\xa0Apache\\xa02.0\\xa0license.\\xa0The\\xa0models\\xa0deliver\\xa0\\nstrong\\xa0performance\\xa0across\\xa0many\\xa0academic\\xa0and\\xa0enterprise\\xa0\\nbenchmarks\\xa0at\\xa0a\\xa0fraction\\xa0of\\xa0the\\xa0cost.\\xa0\\nQuantum\\xa0computing\\xa0is\\xa0another\\xa0example\\xa0of\\xa0IBM\\xa0Research’s\\xa0\\nleadership.\\xa0We\\xa0have\\xa0deployed\\xa0more\\xa0than\\xa070\\xa0quantum\\xa0\\nsystems,\\xa0with\\xa0more\\xa0than\\xa0250\\xa0organizations\\xa0joining\\xa0our\\xa0\\nIBM\\xa0Quantum\\xa0Network.\\xa0We\\xa0have\\xa0also\\xa0scaled\\xa0the\\xa0industry’s\\xa0\\nbest-performing quantum software with Qiskit. In 2024, we \\nintroduced\\xa0the\\xa0IBM\\xa0Quantum\\xa0Heron\\xa0processor,\\xa0with\\xa0reduced\\xa0\\nerror rates, 16 times better performance, and a 25-fold \\nincrease\\xa0in\\xa0speed\\xa0over\\xa0previous\\xa0systems.\\xa0We\\xa0expanded\\xa0\\nour\\xa0IBM\\xa0Quantum\\xa0Data\\xa0Center\\xa0in\\xa0Poughkeepsie,\\xa0New\\xa0York\\xa0\\nand opened the first IBM Quantum Data Center in Europe',\n",
       "   'InfrastructureConsultingSoftware\\n2\\nto\\xa0shareholders\\xa0through\\xa0dividends.\\xa0IBM\\xa0expanded\\xa0operating\\xa0\\ngross profit margin by 130 basis points in 2024, driven by a \\nfocus on high-value offerings and productivity initiatives. \\nSoftware\\xa0revenue\\xa0grew\\xa09%\\xa0at\\xa0constant\\xa0currency,\\xa0reflecting\\xa0\\nstrong\\xa0demand\\xa0for\\xa0our\\xa0advanced\\xa0capabilities\\xa0in\\xa0hybrid\\xa0cloud,\\xa0\\ndata\\xa0and\\xa0AI,\\xa0automation,\\xa0transaction\\xa0processing,\\xa0and\\xa0security.\\xa0\\nRed\\xa0Hat\\xa0performed\\xa0well\\xa0as\\xa0clients\\xa0embraced\\xa0its\\xa0open\\xa0hybrid\\xa0\\ncloud\\xa0platform.\\xa0\\nConsulting\\xa0revenue\\xa0increased\\xa01%\\xa0at\\xa0constant\\xa0currency,\\xa0\\ndemonstrating\\xa0our\\xa0clients’\\xa0continued\\xa0need\\xa0for\\xa0expertise\\xa0in\\xa0AI\\xa0\\ndeployment,\\xa0digital\\xa0transformation,\\xa0and\\xa0cloud\\xa0modernization,\\xa0\\ndespite\\xa0a\\xa0dynamic\\xa0market\\xa0environment.\\nInfrastructure\\xa0revenue\\xa0declined\\xa03%\\xa0at\\xa0constant\\xa0currency,\\xa0in\\xa0\\nline\\xa0with\\xa0product\\xa0cycle\\xa0expectations.\\xa0IBM\\xa0z16\\xa0is\\xa0now\\xa0the\\xa0most\\xa0\\nsuccessful\\xa0mainframe\\xa0program\\xa0in\\xa0our\\xa0history,\\xa0highlighting\\xa0its\\xa0\\nenduring\\xa0value\\xa0to\\xa0clients.\\nTechnology\\xa0innovation\\xa0and\\xa0consulting\\xa0expertise\\nIBM’s\\xa0mission\\xa0to\\xa0help\\xa0businesses\\xa0leverage\\xa0technology\\xa0\\nto scale and grow profitably is more critical than ever. \\nTechnology\\xa0is\\xa0now\\xa0the\\xa0key\\xa0to\\xa0sustainable\\xa0growth\\xa0and\\xa0business\\xa0\\ntransformation.\\nAt the core of these transformations is artificial intelligence. \\nOur\\xa0clients\\xa0have\\xa0moved\\xa0beyond\\xa0experimentation\\xa0and\\xa0are\\xa0now\\xa0\\nlooking\\xa0to\\xa0scale\\xa0AI\\xa0in\\xa0their\\xa0businesses\\xa0and\\xa0generate\\xa0return\\xa0\\nfrom\\xa0their\\xa0investments.\\xa0To\\xa0achieve\\xa0that\\xa0return,\\xa0they\\xa0need\\xa0\\naccess to effective, affordable, and efficient enterprise AI. \\nIBM\\xa0has\\xa0established\\xa0an\\xa0early\\xa0leadership\\xa0position\\xa0in\\xa0this\\xa0\\nregard,\\xa0building\\xa0a\\xa0portfolio\\xa0of\\xa0enterprise\\xa0AI\\xa0offerings\\xa0focused\\xa0\\non\\xa0generating\\xa0ROI\\xa0through\\xa0productivity\\xa0improvements\\xa0and\\xa0\\nautomation.\\xa0IBM\\xa0watsonx\\xa0provides\\xa0a\\xa0robust\\xa0portfolio\\xa0of\\xa0\\nAI\\xa0products\\xa0for\\xa0developing\\xa0AI\\xa0apps,\\xa0managing\\xa0data,\\xa0and\\xa0\\ngoverning\\xa0the\\xa0entire\\xa0lifecycle\\xa0of\\xa0AI\\xa0models.\\xa0AI\\xa0assistants\\xa0\\nmanage\\xa0key\\xa0tasks,\\xa0including\\xa0customer\\xa0service\\xa0and\\xa0writing\\xa0\\ncode. We are developing pre-built AI agents that deliver \\nmultitask reasoning for specific business domains. And our \\nGranite family of fit-for-purpose AI models, when tuned with \\nproprietary data, can deliver enterprise-grade generative AI \\nwith up to 90% improved cost efficiency. Granite allows clients \\nto\\xa0bring\\xa0their\\xa0own\\xa0data\\xa0into\\xa0the\\xa0models,\\xa0and\\xa0can\\xa0be\\xa0trained\\xa0on\\xa0\\nthat\\xa0data\\xa0in\\xa0weeks,\\xa0not\\xa0months.\\nDeploying\\xa0AI\\xa0at\\xa0scale\\xa0across\\xa0an\\xa0enterprise\\xa0requires\\xa0seamless\\xa0\\naccess\\xa0to\\xa0the\\xa0data\\xa0that\\xa0feeds\\xa0it.\\xa0In\\xa0this\\xa0way,\\xa0hybrid\\xa0cloud\\xa0\\nis\\xa0an\\xa0essential\\xa0ingredient\\xa0for\\xa0maximizing\\xa0the\\xa0return\\xa0of\\xa0AI\\xa0\\ninvestments.\\xa0That\\xa0is\\xa0why\\xa075%\\xa0of\\xa0AI\\xa0deployments\\xa0are\\xa0expected\\xa0\\nto\\xa0use\\xa0containers\\xa0by\\xa02027,\\xa0and\\xa0demand\\xa0for\\xa0our\\xa0hybrid\\xa0cloud\\xa0\\nsolutions\\xa0remains\\xa0strong.\\xa0\\nAlready,\\xa0more\\xa0than\\xa090%\\xa0of\\xa0Fortune\\xa0500\\xa0companies\\xa0are\\xa0using\\xa0\\nIBM’s\\xa0hybrid\\xa0cloud\\xa0products\\xa0and\\xa0solutions.\\xa0And\\xa0last\\xa0year,\\xa0\\nwe\\xa0launched\\xa0two\\xa0new\\xa0offerings\\xa0to\\xa0give\\xa0clients\\xa0a\\xa0consistent,\\xa0\\nopen-source foundation for AI: Red Hat Enterprise Linux AI \\nand\\xa0OpenShift\\xa0AI.\\xa0Together,\\xa0our\\xa0AI\\xa0and\\xa0hybrid\\xa0cloud\\xa0platforms\\xa0\\nbring\\xa0together\\xa0the\\xa0data,\\xa0models,\\xa0governance\\xa0and\\xa0monitoring\\xa0\\ncapabilities\\xa0needed\\xa0to\\xa0automate\\xa0workflows\\xa0and\\xa0drive\\xa0\\nproductivity.']}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_datasets['LlamaIndex:meta-llama/llama-3-3-70b-instruct'][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the two sets of outputs\n",
    "\n",
    "Here we combine the outputs from Llama Stack and LlamaIndex into one data structure and save it to disk.  This data structure will then be used in later sections to do the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Llama Stack:meta-llama/llama-3-3-70b-instruct', 'LlamaIndex:meta-llama/llama-3-3-70b-instruct'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = lls_datasets | li_datasets\n",
    "\n",
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "evaluation_utilities.write_json(datasets, f\"./questions_and_reference_answers_and_system_answers-{count}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the checkpoint from disk.  This is just here to make it easier to restart the notebook from this point.\n",
    "\n",
    "datasets = evaluation_utilities.read_json(f\"./questions_and_reference_answers_and_system_answers-{count}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results using Ragas and the evaluator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference for LlamaIndexLLMWrapper: https://docs.ragas.io/en/stable/howtos/integrations/_llamaindex/#building-the-queryengine\n",
    "evaluator_llm_for_ragas = LlamaIndexLLMWrapper(evaluator_model)\n",
    "\n",
    "# Rubrics from https://github.com/instructlab/eval/blob/main/src/instructlab/eval/ragas.py which got them from ragas v0.2.11\n",
    "# and has them \"hardcoded in case ragas makes any changes to their DEFAULT_WITH_REFERENCE_RUBRICS in the future\".\n",
    "SCORING_RUBRICS = {\n",
    "    \"score1_description\": \"The response is entirely incorrect, irrelevant, or does not align with the reference in any meaningful way.\",\n",
    "    \"score2_description\": \"The response partially matches the reference but contains major errors, significant omissions, or irrelevant information.\",\n",
    "    \"score3_description\": \"The response aligns with the reference overall but lacks sufficient detail, clarity, or contains minor inaccuracies.\",\n",
    "    \"score4_description\": \"The response is mostly accurate, aligns closely with the reference, and contains only minor issues or omissions.\",\n",
    "    \"score5_description\": \"The response is fully accurate, completely aligns with the reference, and is clear, thorough, and detailed.\",\n",
    "}\n",
    "\n",
    "metrics = [\n",
    "    AnswerAccuracy(llm=evaluator_llm_for_ragas),\n",
    "    RubricsScore(llm=evaluator_llm_for_ragas, rubrics=SCORING_RUBRICS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1/353:   0%|          | 0/4 [00:00<?, ?it/s]INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 1/353:  25%|██▌       | 1/4 [00:02<00:06,  2.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 1/353:  50%|█████     | 2/4 [00:03<00:03,  1.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 1/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 2/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 2/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 2/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.29it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 3/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 3/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 3/353:  50%|█████     | 2/4 [00:01<00:01,  1.60it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 3/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 4/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 4/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 4/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 5/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 5/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 5/353:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 5/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 6/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 6/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 6/353:  50%|█████     | 2/4 [00:01<00:01,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 6/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 7/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 7/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 7/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 8/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 8/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 8/353:  50%|█████     | 2/4 [00:01<00:01,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 8/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 9/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 9/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 9/353:  50%|█████     | 2/4 [00:02<00:02,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 9/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 10/353:   0%|          | 0/4 [00:00<?, ?it/s]       INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 10/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 10/353:  50%|█████     | 2/4 [00:01<00:01,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 10/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 11/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 11/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 11/353:  50%|█████     | 2/4 [00:01<00:01,  1.91it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 11/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 12/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 12/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 12/353:  50%|█████     | 2/4 [00:01<00:01,  1.45it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 12/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 13/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 13/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 13/353:  50%|█████     | 2/4 [00:01<00:01,  1.56it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 13/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 14/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 14/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 14/353:  50%|█████     | 2/4 [00:01<00:01,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 14/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 15/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 15/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 15/353:  50%|█████     | 2/4 [00:01<00:01,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 15/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 16/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 16/353:  25%|██▌       | 1/4 [00:01<00:05,  1.85s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 16/353:  50%|█████     | 2/4 [00:02<00:01,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 16/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 17/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 17/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 17/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 18/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 18/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 18/353:  50%|█████     | 2/4 [00:01<00:01,  1.35it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 19/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 19/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 19/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 20/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 20/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 20/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 21/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 21/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 21/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 22/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 22/353:  25%|██▌       | 1/4 [00:01<00:04,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 22/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 23/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 23/353:  25%|██▌       | 1/4 [00:00<00:02,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 23/353:  50%|█████     | 2/4 [00:01<00:00,  2.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 23/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 24/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 24/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 24/353:  50%|█████     | 2/4 [00:02<00:02,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 25/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 25/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 25/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 26/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 26/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 26/353:  50%|█████     | 2/4 [00:01<00:01,  1.62it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 26/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 27/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 27/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 27/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 28/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 28/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 28/353:  50%|█████     | 2/4 [00:01<00:01,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 28/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 29/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 29/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 29/353:  50%|█████     | 2/4 [00:03<00:03,  1.71s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 30/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 30/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 30/353:  50%|█████     | 2/4 [00:01<00:01,  1.97it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 30/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 31/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 31/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 31/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 32/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 32/353:  25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 32/353:  50%|█████     | 2/4 [00:02<00:02,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 32/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 33/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 33/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 33/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 34/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 34/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 34/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 35/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 35/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 35/353:  50%|█████     | 2/4 [00:01<00:01,  1.77it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 35/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 36/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 36/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 36/353:  50%|█████     | 2/4 [00:01<00:01,  1.84it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 36/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 37/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 37/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 37/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 38/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 38/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 38/353:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 38/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 39/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 39/353:  25%|██▌       | 1/4 [00:01<00:03,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 39/353:  50%|█████     | 2/4 [00:03<00:03,  1.75s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 39/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 40/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 40/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 40/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 41/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 41/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 41/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 42/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 42/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 42/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 43/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 43/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 43/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 44/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 44/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 44/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 45/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 45/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 45/353:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 45/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 46/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 46/353:  25%|██▌       | 1/4 [00:01<00:04,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 46/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 47/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 47/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 47/353:  50%|█████     | 2/4 [00:01<00:01,  1.67it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 47/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 48/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 48/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 48/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 49/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 49/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 49/353:  50%|█████     | 2/4 [00:02<00:03,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 49/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.93s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 50/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 50/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 50/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 51/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 51/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 51/353:  50%|█████     | 2/4 [00:01<00:01,  1.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 51/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 52/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 52/353:  25%|██▌       | 1/4 [00:01<00:04,  1.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 52/353:  50%|█████     | 2/4 [00:01<00:01,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 52/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 53/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 53/353:  25%|██▌       | 1/4 [00:01<00:04,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 53/353:  50%|█████     | 2/4 [00:01<00:01,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 53/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 54/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 54/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 54/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 55/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 55/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 55/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 56/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 56/353:  25%|██▌       | 1/4 [00:01<00:04,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 56/353:  50%|█████     | 2/4 [00:01<00:01,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 56/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 57/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 57/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 57/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 58/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 58/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 58/353:  50%|█████     | 2/4 [00:01<00:01,  1.81it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 58/353:  75%|███████▌  | 3/4 [00:10<00:04,  4.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 59/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 59/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 59/353:  50%|█████     | 2/4 [00:01<00:01,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 59/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 60/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 60/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 60/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 61/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 61/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 61/353:  50%|█████     | 2/4 [00:01<00:01,  1.58it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 61/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 62/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 62/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 62/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 63/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 63/353:  25%|██▌       | 1/4 [00:01<00:04,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 63/353:  50%|█████     | 2/4 [00:03<00:03,  1.92s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 63/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 64/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 64/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 64/353:  50%|█████     | 2/4 [00:01<00:01,  1.76it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 64/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 65/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 65/353:  25%|██▌       | 1/4 [00:01<00:04,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 65/353:  50%|█████     | 2/4 [00:01<00:01,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 65/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 66/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 66/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 66/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 67/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 67/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 67/353:  50%|█████     | 2/4 [00:02<00:03,  1.55s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 67/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 68/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 68/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 68/353:  50%|█████     | 2/4 [00:01<00:01,  1.60it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 68/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 69/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 69/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 69/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 70/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 70/353:  25%|██▌       | 1/4 [00:01<00:04,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 70/353:  50%|█████     | 2/4 [00:02<00:01,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 70/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 71/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 71/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 71/353:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 71/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 72/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 72/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 72/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 73/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 73/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 73/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 74/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 74/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 74/353:  50%|█████     | 2/4 [00:01<00:01,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 74/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.78s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 75/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 75/353:  25%|██▌       | 1/4 [00:01<00:04,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 75/353:  50%|█████     | 2/4 [00:01<00:01,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 75/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 76/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 76/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 76/353:  50%|█████     | 2/4 [00:01<00:01,  1.69it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 76/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 77/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 77/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 77/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 78/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 78/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 78/353:  50%|█████     | 2/4 [00:01<00:01,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 78/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.39it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 79/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 79/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 79/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 80/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 80/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 80/353:  50%|█████     | 2/4 [00:01<00:01,  1.31it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 80/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 81/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 81/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 81/353:  50%|█████     | 2/4 [00:03<00:03,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 82/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 82/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 82/353:  50%|█████     | 2/4 [00:03<00:03,  1.84s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 82/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 83/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 83/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 83/353:  50%|█████     | 2/4 [00:01<00:01,  1.74it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 83/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 84/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 84/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 84/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 85/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 85/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 85/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 86/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 86/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 86/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 87/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 87/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 87/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 88/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 88/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 88/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 89/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 89/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 89/353:  50%|█████     | 2/4 [00:01<00:01,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 89/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 90/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 90/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 90/353:  50%|█████     | 2/4 [00:01<00:01,  1.61it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 90/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 91/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 91/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 91/353:  50%|█████     | 2/4 [00:01<00:01,  1.94it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 91/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 92/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 92/353:  25%|██▌       | 1/4 [00:01<00:04,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 92/353:  50%|█████     | 2/4 [00:02<00:02,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 92/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 93/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 93/353:  25%|██▌       | 1/4 [00:01<00:04,  1.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 93/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 94/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 94/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 94/353:  50%|█████     | 2/4 [00:02<00:02,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 94/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 95/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 95/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 95/353:  50%|█████     | 2/4 [00:01<00:01,  1.68it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 95/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 96/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 96/353:  25%|██▌       | 1/4 [00:01<00:04,  1.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 96/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 97/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 97/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 97/353:  50%|█████     | 2/4 [00:02<00:02,  1.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 97/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 98/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 98/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 98/353:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 98/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 99/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 99/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 99/353:  50%|█████     | 2/4 [00:01<00:01,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 99/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 100/353:   0%|          | 0/4 [00:00<?, ?it/s]       INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 100/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 100/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 101/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 101/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 101/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 102/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 102/353:  25%|██▌       | 1/4 [00:01<00:04,  1.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 102/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 103/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 103/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 103/353:  50%|█████     | 2/4 [00:01<00:01,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 103/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 104/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 104/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 104/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 105/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 105/353:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 105/353:  50%|█████     | 2/4 [00:01<00:01,  1.22it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 105/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 106/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 106/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 106/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 107/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 107/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 107/353:  50%|█████     | 2/4 [00:01<00:01,  1.74it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 108/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 108/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 108/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 109/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 109/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 109/353:  50%|█████     | 2/4 [00:01<00:01,  1.40it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 109/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 110/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 110/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 110/353:  50%|█████     | 2/4 [00:02<00:01,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 110/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 111/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 111/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 111/353:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 111/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 112/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 112/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 112/353:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 112/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 113/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 113/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 113/353:  50%|█████     | 2/4 [00:01<00:01,  1.62it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 113/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 114/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 114/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 114/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 115/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 115/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 115/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 116/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 116/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 116/353:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 116/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 117/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 117/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 117/353:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 117/353:  75%|███████▌  | 3/4 [00:10<00:04,  4.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 118/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 118/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 118/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 119/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "Batch 119/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 119/353:  50%|█████     | 2/4 [00:02<00:02,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 119/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 120/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 120/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 120/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 121/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 121/353:  25%|██▌       | 1/4 [00:01<00:04,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 121/353:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 121/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 122/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 122/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 122/353:  50%|█████     | 2/4 [00:03<00:04,  2.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 122/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 123/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 123/353:  25%|██▌       | 1/4 [00:01<00:04,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 123/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 124/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 124/353:  25%|██▌       | 1/4 [00:03<00:10,  3.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 124/353:  50%|█████     | 2/4 [00:04<00:03,  1.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 124/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 125/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 125/353:  25%|██▌       | 1/4 [00:01<00:04,  1.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 125/353:  50%|█████     | 2/4 [00:01<00:01,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 125/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 126/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 126/353:  25%|██▌       | 1/4 [00:01<00:04,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 126/353:  50%|█████     | 2/4 [00:02<00:02,  1.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 126/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 127/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 127/353:  25%|██▌       | 1/4 [00:02<00:08,  2.95s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 127/353:  50%|█████     | 2/4 [00:03<00:02,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 128/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 128/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 128/353:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 128/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 129/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 129/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 129/353:  50%|█████     | 2/4 [00:01<00:01,  1.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 129/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 130/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 130/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 130/353:  50%|█████     | 2/4 [00:01<00:01,  1.85it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 130/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 131/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 131/353:  25%|██▌       | 1/4 [00:01<00:04,  1.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 131/353:  50%|█████     | 2/4 [00:01<00:01,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 131/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 132/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 132/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 132/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 133/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 133/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 133/353:  50%|█████     | 2/4 [00:01<00:01,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 133/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 134/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 134/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 134/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 135/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 135/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 135/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 136/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 136/353:  25%|██▌       | 1/4 [00:01<00:04,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 136/353:  50%|█████     | 2/4 [00:01<00:01,  1.39it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 136/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 137/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 137/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 137/353:  50%|█████     | 2/4 [00:01<00:01,  1.58it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 137/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 138/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 138/353:  25%|██▌       | 1/4 [00:01<00:05,  1.98s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 138/353:  50%|█████     | 2/4 [00:02<00:02,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 138/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 139/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 139/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 139/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 140/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 140/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 140/353:  50%|█████     | 2/4 [00:01<00:01,  1.76it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 140/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 141/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "Batch 141/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 141/353:  50%|█████     | 2/4 [00:02<00:02,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 141/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 142/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 142/353:  25%|██▌       | 1/4 [00:01<00:03,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 142/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 143/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 143/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 143/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 144/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 144/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 144/353:  50%|█████     | 2/4 [00:01<00:01,  1.68it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 144/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 145/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 145/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 145/353:  50%|█████     | 2/4 [00:01<00:01,  1.90it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 145/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 146/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 146/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 146/353:  50%|█████     | 2/4 [00:01<00:01,  1.91it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 146/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 147/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 147/353:  25%|██▌       | 1/4 [00:01<00:03,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 147/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 148/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 148/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 148/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 149/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 149/353:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 149/353:  50%|█████     | 2/4 [00:01<00:01,  1.70it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 149/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 150/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 150/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 150/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 151/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 151/353:  25%|██▌       | 1/4 [00:00<00:02,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 151/353:  50%|█████     | 2/4 [00:01<00:00,  2.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 151/353:  75%|███████▌  | 3/4 [00:04<00:02,  2.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 152/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 152/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 152/353:  50%|█████     | 2/4 [00:01<00:01,  1.31it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 152/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 153/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 153/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 153/353:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 153/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.80s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 154/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 154/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 154/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 155/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 155/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 155/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 156/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 156/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 156/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 157/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 157/353:  25%|██▌       | 1/4 [00:01<00:04,  1.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 157/353:  50%|█████     | 2/4 [00:02<00:01,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 157/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 158/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 158/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 158/353:  50%|█████     | 2/4 [00:01<00:01,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 158/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 159/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 159/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 159/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 160/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 160/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 160/353:  50%|█████     | 2/4 [00:01<00:01,  1.62it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 160/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.81s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 161/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 161/353:  25%|██▌       | 1/4 [00:01<00:05,  1.74s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 161/353:  50%|█████     | 2/4 [00:02<00:02,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 161/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 162/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 162/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 162/353:  50%|█████     | 2/4 [00:01<00:01,  1.44it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 162/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 163/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 163/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 163/353:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 163/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 164/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 164/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 164/353:  50%|█████     | 2/4 [00:01<00:01,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 164/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 165/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 165/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 165/353:  50%|█████     | 2/4 [00:02<00:02,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 165/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 166/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 166/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 166/353:  75%|███████▌  | 3/4 [00:07<00:02,  2.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 167/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 167/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 167/353:  50%|█████     | 2/4 [00:01<00:01,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 167/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 168/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 168/353:  25%|██▌       | 1/4 [00:01<00:05,  1.86s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 168/353:  50%|█████     | 2/4 [00:02<00:01,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 168/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 169/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 169/353:  25%|██▌       | 1/4 [00:01<00:04,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 169/353:  50%|█████     | 2/4 [00:02<00:02,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 169/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 170/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 170/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 170/353:  50%|█████     | 2/4 [00:01<00:01,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 170/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.32it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 171/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 171/353:  25%|██▌       | 1/4 [00:01<00:03,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 171/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 172/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 172/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 172/353:  50%|█████     | 2/4 [00:01<00:01,  1.75it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 172/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 173/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 173/353:  25%|██▌       | 1/4 [00:01<00:04,  1.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 173/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 174/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 174/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 174/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 175/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 175/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 175/353:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 175/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 176/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 176/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 176/353:  50%|█████     | 2/4 [00:01<00:01,  1.30it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 176/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 177/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 177/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 177/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 178/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 178/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 178/353:  50%|█████     | 2/4 [00:01<00:01,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 178/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 179/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 179/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 179/353:  50%|█████     | 2/4 [00:02<00:02,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 179/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 180/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 180/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 180/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 181/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 181/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 181/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 182/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 182/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 182/353:  50%|█████     | 2/4 [00:01<00:01,  1.70it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 182/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 183/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 183/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 183/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 184/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 184/353:  25%|██▌       | 1/4 [00:01<00:04,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 184/353:  50%|█████     | 2/4 [00:02<00:02,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 184/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.55s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 185/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 185/353:  25%|██▌       | 1/4 [00:01<00:04,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 185/353:  50%|█████     | 2/4 [00:01<00:01,  1.22it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 185/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 186/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 186/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 186/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 187/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 187/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 187/353:  50%|█████     | 2/4 [00:02<00:02,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 187/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 188/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 188/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 188/353:  50%|█████     | 2/4 [00:01<00:01,  1.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 188/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 189/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 189/353:  25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 189/353:  50%|█████     | 2/4 [00:02<00:02,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 189/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 190/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 190/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 190/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 191/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 191/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 191/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 192/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 192/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 192/353:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 192/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 193/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 193/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 193/353:  50%|█████     | 2/4 [00:02<00:02,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 193/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 194/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 194/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 194/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 195/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 195/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 195/353:  50%|█████     | 2/4 [00:01<00:01,  1.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 195/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 196/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 196/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 196/353:  50%|█████     | 2/4 [00:01<00:01,  1.32it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 196/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 197/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 197/353:  25%|██▌       | 1/4 [00:01<00:04,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 197/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 198/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 198/353:  25%|██▌       | 1/4 [00:01<00:04,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 198/353:  50%|█████     | 2/4 [00:01<00:01,  1.39it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 198/353:  75%|███████▌  | 3/4 [00:07<00:03,  3.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 199/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 199/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 199/353:  50%|█████     | 2/4 [00:01<00:01,  1.41it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 199/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 200/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 200/353:  25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 200/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 201/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 201/353:  25%|██▌       | 1/4 [00:01<00:03,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 201/353:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 201/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 202/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 202/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 202/353:  50%|█████     | 2/4 [00:01<00:01,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 202/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 203/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 203/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 203/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 204/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 204/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 204/353:  50%|█████     | 2/4 [00:01<00:01,  1.56it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 204/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 205/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 205/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 205/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 206/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 206/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 206/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 207/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 207/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 207/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 208/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 208/353:  25%|██▌       | 1/4 [00:01<00:04,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 208/353:  50%|█████     | 2/4 [00:02<00:02,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 208/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 520 \"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395102 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 209/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 209/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 209/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 210/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "Batch 210/353:  25%|██▌       | 1/4 [00:01<00:04,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 210/353:  50%|█████     | 2/4 [00:01<00:01,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 210/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 211/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 211/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 211/353:  50%|█████     | 2/4 [00:01<00:01,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 211/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 212/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 212/353:  25%|██▌       | 1/4 [00:01<00:03,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 212/353:  50%|█████     | 2/4 [00:01<00:01,  1.61it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 212/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 213/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 213/353:  25%|██▌       | 1/4 [00:01<00:04,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 213/353:  50%|█████     | 2/4 [00:01<00:01,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 213/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 214/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 214/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 214/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 215/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 215/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 215/353:  50%|█████     | 2/4 [00:01<00:00,  2.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 215/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 216/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 216/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 216/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 217/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 217/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 217/353:  50%|█████     | 2/4 [00:01<00:01,  1.61it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 217/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 218/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 218/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 218/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 219/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 219/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 219/353:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 219/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 220/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 220/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 220/353:  50%|█████     | 2/4 [00:01<00:01,  1.77it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 220/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 221/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 221/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 221/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 222/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 222/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 222/353:  50%|█████     | 2/4 [00:01<00:01,  1.67it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 222/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 223/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 223/353:  25%|██▌       | 1/4 [00:01<00:03,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 223/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 224/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 224/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 224/353:  50%|█████     | 2/4 [00:01<00:01,  1.68it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 224/353:  75%|███████▌  | 3/4 [00:12<00:05,  5.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 225/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 225/353:  25%|██▌       | 1/4 [00:01<00:04,  1.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 225/353:  50%|█████     | 2/4 [00:02<00:02,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 225/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 226/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 226/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 226/353:  50%|█████     | 2/4 [00:02<00:02,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 226/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 227/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 227/353:  25%|██▌       | 1/4 [00:02<00:06,  2.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 227/353:  50%|█████     | 2/4 [00:02<00:02,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 227/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 228/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 228/353:  25%|██▌       | 1/4 [00:02<00:06,  2.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 228/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 229/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 229/353:  25%|██▌       | 1/4 [00:02<00:06,  2.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 229/353:  50%|█████     | 2/4 [00:03<00:03,  1.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 229/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 230/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 230/353:  25%|██▌       | 1/4 [00:01<00:04,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 230/353:  50%|█████     | 2/4 [00:01<00:01,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 230/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 231/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 231/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 231/353:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 231/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 232/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 232/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 232/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 233/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 233/353:  25%|██▌       | 1/4 [00:01<00:05,  1.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 233/353:  50%|█████     | 2/4 [00:02<00:02,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 233/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 234/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 234/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 234/353:  50%|█████     | 2/4 [00:03<00:03,  1.66s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 234/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.97s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 235/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 235/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 235/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 236/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 236/353:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 236/353:  50%|█████     | 2/4 [00:01<00:01,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 236/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.68s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 237/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 237/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 237/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 238/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "Batch 238/353:  25%|██▌       | 1/4 [00:01<00:04,  1.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 238/353:  50%|█████     | 2/4 [00:02<00:02,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 238/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 239/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 239/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 239/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 240/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 240/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 240/353:  50%|█████     | 2/4 [00:01<00:01,  1.57it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 240/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 241/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 241/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 241/353:  50%|█████     | 2/4 [00:01<00:01,  1.86it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 241/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 242/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 242/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 242/353:  50%|█████     | 2/4 [00:01<00:01,  1.35it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 242/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 243/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 243/353:  25%|██▌       | 1/4 [00:01<00:04,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 243/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 244/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 244/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 244/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 245/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 245/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 245/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 246/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 246/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 246/353:  50%|█████     | 2/4 [00:02<00:01,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 246/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 247/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 247/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 247/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 248/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 248/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 248/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 249/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 249/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 249/353:  50%|█████     | 2/4 [00:01<00:01,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 249/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 250/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 250/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 250/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 251/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 251/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 251/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.52it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 252/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 252/353:  25%|██▌       | 1/4 [00:00<00:02,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 252/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 253/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 253/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 253/353:  50%|█████     | 2/4 [00:02<00:02,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 253/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 254/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 254/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 254/353:  50%|█████     | 2/4 [00:01<00:01,  1.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 254/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 255/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 255/353:  25%|██▌       | 1/4 [00:01<00:03,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 255/353:  50%|█████     | 2/4 [00:01<00:01,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 255/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 256/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 256/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 256/353:  50%|█████     | 2/4 [00:01<00:01,  1.22it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 256/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 257/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 257/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 257/353:  50%|█████     | 2/4 [00:02<00:02,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 257/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 258/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 258/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 258/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.49it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 259/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 259/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 259/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.61it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 260/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 260/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 260/353:  50%|█████     | 2/4 [00:01<00:01,  1.92it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 260/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 261/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 261/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 261/353:  50%|█████     | 2/4 [00:01<00:01,  1.82it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 261/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 262/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 262/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 262/353:  50%|█████     | 2/4 [00:01<00:01,  1.70it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 262/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 263/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 263/353:  25%|██▌       | 1/4 [00:01<00:03,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 263/353:  50%|█████     | 2/4 [00:01<00:01,  1.71it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 263/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 264/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 264/353:  25%|██▌       | 1/4 [00:01<00:04,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 264/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 265/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 265/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 265/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 266/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 266/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 266/353:  50%|█████     | 2/4 [00:01<00:01,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 266/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 267/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 267/353:  25%|██▌       | 1/4 [00:01<00:04,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 267/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 268/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 268/353:  25%|██▌       | 1/4 [00:01<00:04,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 268/353:  50%|█████     | 2/4 [00:02<00:02,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 268/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 269/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 269/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 269/353:  50%|█████     | 2/4 [00:01<00:01,  1.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 269/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 270/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 270/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 270/353:  50%|█████     | 2/4 [00:01<00:01,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 270/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 271/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 271/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 271/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 272/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 272/353:  25%|██▌       | 1/4 [00:01<00:05,  1.68s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 272/353:  50%|█████     | 2/4 [00:02<00:01,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 272/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 273/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 273/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 273/353:  50%|█████     | 2/4 [00:01<00:01,  1.75it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 273/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 274/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 274/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 274/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 275/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 275/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 275/353:  50%|█████     | 2/4 [00:01<00:01,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 275/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 276/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 276/353:  25%|██▌       | 1/4 [00:01<00:04,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 276/353:  50%|█████     | 2/4 [00:02<00:02,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 276/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 277/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 277/353:  25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 277/353:  50%|█████     | 2/4 [00:01<00:01,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 277/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 278/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 278/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 278/353:  50%|█████     | 2/4 [00:01<00:01,  1.73it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 278/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.39it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 279/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 279/353:  25%|██▌       | 1/4 [00:01<00:04,  1.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 279/353:  50%|█████     | 2/4 [00:01<00:01,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 279/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 280/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 280/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 280/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.81s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 281/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 281/353:  25%|██▌       | 1/4 [00:01<00:04,  1.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 281/353:  50%|█████     | 2/4 [00:01<00:01,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 281/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 282/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 282/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 282/353:  50%|█████     | 2/4 [00:01<00:01,  1.98it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 282/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 283/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 283/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 283/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 284/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 284/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 284/353:  50%|█████     | 2/4 [00:01<00:01,  1.74it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 284/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 285/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 285/353:  25%|██▌       | 1/4 [00:00<00:02,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 285/353:  50%|█████     | 2/4 [00:02<00:02,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 285/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 286/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 286/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 286/353:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 286/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 287/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 287/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 287/353:  50%|█████     | 2/4 [00:01<00:01,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 287/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 288/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 288/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 288/353:  50%|█████     | 2/4 [00:03<00:03,  1.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 288/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 289/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 289/353:  25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 289/353:  50%|█████     | 2/4 [00:01<00:01,  1.29it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 289/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 290/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 290/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 290/353:  50%|█████     | 2/4 [00:02<00:02,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 290/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 291/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 291/353:  25%|██▌       | 1/4 [00:01<00:03,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 291/353:  50%|█████     | 2/4 [00:01<00:01,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 291/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 292/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 292/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 292/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 293/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 293/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 293/353:  50%|█████     | 2/4 [00:01<00:01,  1.69it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 294/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 294/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 294/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 295/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 295/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 295/353:  50%|█████     | 2/4 [00:01<00:01,  1.63it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 295/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 296/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 296/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 296/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 297/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 297/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 297/353:  50%|█████     | 2/4 [00:01<00:01,  1.94it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 297/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 298/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 298/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 298/353:  50%|█████     | 2/4 [00:01<00:01,  1.58it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 299/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 299/353:  25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 299/353:  75%|███████▌  | 3/4 [00:01<00:00,  2.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 300/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 300/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 300/353:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 300/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 301/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 301/353:  25%|██▌       | 1/4 [00:00<00:02,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 301/353:  50%|█████     | 2/4 [00:01<00:01,  1.94it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 301/353:  75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 302/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 302/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 302/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 303/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 303/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 303/353:  50%|█████     | 2/4 [00:01<00:01,  1.80it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 303/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.40it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 304/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 304/353:  25%|██▌       | 1/4 [00:01<00:04,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 304/353:  50%|█████     | 2/4 [00:01<00:01,  1.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 304/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.66it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 305/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 305/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 305/353:  75%|███████▌  | 3/4 [00:01<00:00,  3.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 306/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 306/353:  50%|█████     | 2/4 [00:01<00:01,  1.75it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 306/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 307/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 307/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 307/353:  50%|█████     | 2/4 [00:01<00:01,  1.63it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 307/353:  75%|███████▌  | 3/4 [00:01<00:00,  1.86it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 308/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 308/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 308/353:  50%|█████     | 2/4 [00:01<00:01,  1.84it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 308/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.40it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 309/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 309/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 309/353:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 309/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 310/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 310/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 310/353:  50%|█████     | 2/4 [00:02<00:02,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 310/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 311/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 311/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 311/353:  50%|█████     | 2/4 [00:01<00:01,  1.69it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 311/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 312/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 312/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 312/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 313/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 313/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 313/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 314/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 314/353:  25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 314/353:  50%|█████     | 2/4 [00:01<00:01,  1.79it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 314/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 315/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 315/353:  25%|██▌       | 1/4 [00:01<00:04,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 315/353:  50%|█████     | 2/4 [00:02<00:01,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 315/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 316/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 316/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 316/353:  50%|█████     | 2/4 [00:01<00:01,  1.80it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 316/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 317/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 317/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 317/353:  50%|█████     | 2/4 [00:02<00:02,  1.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 317/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 318/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 318/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 318/353:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 318/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 319/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 319/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 319/353:  50%|█████     | 2/4 [00:01<00:01,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 319/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.31it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 320/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 320/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 320/353:  50%|█████     | 2/4 [00:01<00:01,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 320/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 321/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 321/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 321/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 322/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 322/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 322/353:  50%|█████     | 2/4 [00:01<00:01,  1.71it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 322/353:  75%|███████▌  | 3/4 [00:01<00:00,  2.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 323/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 323/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 323/353:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 323/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 324/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 324/353:  25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 324/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 325/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 325/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 325/353:  75%|███████▌  | 3/4 [00:01<00:00,  3.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 326/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 326/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 326/353:  50%|█████     | 2/4 [00:01<00:01,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 326/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 327/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 327/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 327/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.45it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 328/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 328/353:  25%|██▌       | 1/4 [00:01<00:04,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 328/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.45it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 329/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 329/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 329/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 330/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 330/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 330/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 331/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 331/353:  25%|██▌       | 1/4 [00:01<00:04,  1.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 331/353:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 331/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.44it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 332/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 332/353:  25%|██▌       | 1/4 [00:01<00:04,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 332/353:  50%|█████     | 2/4 [00:02<00:01,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 332/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 333/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 333/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 333/353:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 333/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 334/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 334/353:  25%|██▌       | 1/4 [00:01<00:04,  1.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 334/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 335/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 335/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 335/353:  50%|█████     | 2/4 [00:01<00:01,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 335/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 336/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 336/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 336/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 337/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 337/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 337/353:  50%|█████     | 2/4 [00:01<00:01,  1.82it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 337/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 338/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 338/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 338/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 339/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 339/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 339/353:  50%|█████     | 2/4 [00:01<00:01,  1.30it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 339/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 340/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 340/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 340/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 341/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 341/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 341/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 342/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 342/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 342/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 343/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 343/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 343/353:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 343/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 344/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 344/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 344/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 345/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 345/353:  25%|██▌       | 1/4 [00:01<00:03,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 345/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 346/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 346/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 346/353:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 346/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 347/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 347/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 347/353:  50%|█████     | 2/4 [00:01<00:01,  1.90it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 347/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.61s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 348/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 348/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 348/353:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 348/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.45it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 349/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 349/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 349/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 350/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 350/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 350/353:  50%|█████     | 2/4 [00:01<00:01,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 350/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 351/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 351/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 351/353:  50%|█████     | 2/4 [00:01<00:01,  1.73it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 351/353:  75%|███████▌  | 3/4 [00:01<00:00,  1.73it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 352/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 352/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 352/353:  50%|█████     | 2/4 [00:01<00:01,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 352/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 353/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 353/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 353/353:  50%|█████     | 2/4 [00:01<00:01,  1.89it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 353/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating: 100%|██████████| 1412/1412 [27:35<00:00,  1.17s/it]\n",
      "Batch 1/353:   0%|          | 0/4 [00:00<?, ?it/s]INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 1/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 1/353:  50%|█████     | 2/4 [00:01<00:01,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 1/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 2/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 2/353:  25%|██▌       | 1/4 [00:01<00:04,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 2/353:  50%|█████     | 2/4 [00:01<00:01,  1.39it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 2/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 3/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 3/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 3/353:  50%|█████     | 2/4 [00:01<00:01,  1.40it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 3/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 4/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 4/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 4/353:  50%|█████     | 2/4 [00:01<00:01,  1.28it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 4/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 5/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 5/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 5/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 6/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 6/353:  25%|██▌       | 1/4 [00:00<00:02,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 6/353:  50%|█████     | 2/4 [00:01<00:00,  2.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 6/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 7/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 7/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 7/353:  50%|█████     | 2/4 [00:02<00:02,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 7/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 8/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 8/353:  25%|██▌       | 1/4 [00:01<00:05,  1.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 8/353:  50%|█████     | 2/4 [00:03<00:02,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 8/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 9/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 9/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 9/353:  50%|█████     | 2/4 [00:01<00:01,  1.89it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 9/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.94s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 10/353:   0%|          | 0/4 [00:00<?, ?it/s]       INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 10/353:  25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 10/353:  50%|█████     | 2/4 [00:01<00:01,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 10/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 11/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 11/353:  25%|██▌       | 1/4 [00:01<00:04,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 11/353:  50%|█████     | 2/4 [00:01<00:01,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 11/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 12/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 12/353:  25%|██▌       | 1/4 [00:01<00:03,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 12/353:  50%|█████     | 2/4 [00:01<00:01,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 12/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 13/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 13/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 13/353:  50%|█████     | 2/4 [00:02<00:03,  1.55s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 13/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 14/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 14/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 14/353:  50%|█████     | 2/4 [00:01<00:01,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 14/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 15/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 15/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 15/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 16/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 16/353:  25%|██▌       | 1/4 [00:01<00:04,  1.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 16/353:  50%|█████     | 2/4 [00:02<00:02,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 16/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 17/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 17/353:  25%|██▌       | 1/4 [00:01<00:05,  1.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 17/353:  50%|█████     | 2/4 [00:01<00:01,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 17/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 18/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 18/353:  25%|██▌       | 1/4 [00:01<00:04,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 18/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 19/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 19/353:  25%|██▌       | 1/4 [00:01<00:04,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 20/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 20/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 20/353:  50%|█████     | 2/4 [00:04<00:04,  2.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 20/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.68s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 21/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 21/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 21/353:  50%|█████     | 2/4 [00:01<00:01,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 21/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 22/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 22/353:  25%|██▌       | 1/4 [00:01<00:05,  1.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 22/353:  50%|█████     | 2/4 [00:01<00:01,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 22/353:  75%|███████▌  | 3/4 [00:05<00:01,  2.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 23/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 23/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 23/353:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 23/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 24/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 24/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 24/353:  50%|█████     | 2/4 [00:01<00:01,  1.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 24/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 25/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 25/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 25/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 26/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 26/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 26/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 27/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 27/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 27/353:  50%|█████     | 2/4 [00:02<00:02,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 27/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 28/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 28/353:  25%|██▌       | 1/4 [00:00<00:02,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 28/353:  50%|█████     | 2/4 [00:01<00:01,  1.56it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 28/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 29/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 29/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 29/353:  50%|█████     | 2/4 [00:01<00:01,  1.35it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 29/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 30/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 30/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 30/353:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 30/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.80s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 31/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 31/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 31/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 32/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 32/353:  25%|██▌       | 1/4 [00:01<00:05,  1.84s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 32/353:  50%|█████     | 2/4 [00:02<00:01,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 32/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 33/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 33/353:  25%|██▌       | 1/4 [00:00<00:02,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 33/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 34/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 34/353:  25%|██▌       | 1/4 [00:01<00:04,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 34/353:  50%|█████     | 2/4 [00:01<00:01,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 34/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 35/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 35/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 35/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 36/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 36/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 36/353:  50%|█████     | 2/4 [00:01<00:01,  1.30it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 36/353:  75%|███████▌  | 3/4 [00:12<00:05,  5.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 37/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 37/353:  25%|██▌       | 1/4 [00:01<00:04,  1.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 37/353:  50%|█████     | 2/4 [00:01<00:01,  1.29it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 37/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 38/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 38/353:  25%|██▌       | 1/4 [00:01<00:04,  1.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 38/353:  50%|█████     | 2/4 [00:01<00:01,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 38/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 39/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 39/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 39/353:  50%|█████     | 2/4 [00:01<00:01,  1.87it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 39/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 40/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 40/353:  25%|██▌       | 1/4 [00:00<00:02,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 40/353:  50%|█████     | 2/4 [00:01<00:01,  1.76it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 40/353:  75%|███████▌  | 3/4 [00:11<00:04,  4.81s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 41/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 41/353:  25%|██▌       | 1/4 [00:01<00:03,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 41/353:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 41/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 42/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 42/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 42/353:  50%|█████     | 2/4 [00:01<00:01,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 42/353:  75%|███████▌  | 3/4 [00:09<00:04,  4.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 43/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 43/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 43/353:  50%|█████     | 2/4 [00:01<00:01,  1.79it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 43/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 44/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 44/353:  25%|██▌       | 1/4 [00:02<00:06,  2.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 44/353:  75%|███████▌  | 3/4 [00:10<00:03,  3.80s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 45/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 45/353:  25%|██▌       | 1/4 [00:01<00:05,  1.86s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 45/353:  50%|█████     | 2/4 [00:02<00:01,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 45/353:  75%|███████▌  | 3/4 [00:09<00:03,  3.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 46/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 46/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 46/353:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 46/353:  75%|███████▌  | 3/4 [00:09<00:03,  3.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 47/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 47/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 47/353:  50%|█████     | 2/4 [00:01<00:01,  1.57it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 47/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 48/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 48/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 48/353:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 48/353:  75%|███████▌  | 3/4 [00:07<00:03,  3.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 49/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 49/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 49/353:  50%|█████     | 2/4 [00:01<00:01,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 49/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.73s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 50/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 50/353:  25%|██▌       | 1/4 [00:01<00:04,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 50/353:  50%|█████     | 2/4 [00:02<00:02,  1.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 50/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 51/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 51/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 51/353:  50%|█████     | 2/4 [00:01<00:01,  1.85it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 51/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 52/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 52/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 52/353:  50%|█████     | 2/4 [00:01<00:01,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 52/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 53/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 53/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 53/353:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 53/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.80s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 54/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 54/353:  25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 54/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 55/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 55/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 55/353:  50%|█████     | 2/4 [00:01<00:01,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 55/353:  75%|███████▌  | 3/4 [00:09<00:04,  4.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 56/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 56/353:  25%|██▌       | 1/4 [00:01<00:05,  1.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 56/353:  75%|███████▌  | 3/4 [00:11<00:03,  3.93s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 57/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 57/353:  25%|██▌       | 1/4 [00:01<00:04,  1.66s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 57/353:  50%|█████     | 2/4 [00:01<00:01,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 57/353:  75%|███████▌  | 3/4 [00:08<00:03,  3.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 58/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 58/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 58/353:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 58/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.82s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 59/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 59/353:  25%|██▌       | 1/4 [00:01<00:04,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 59/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 60/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 60/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 60/353:  50%|█████     | 2/4 [00:01<00:01,  1.57it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 60/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 61/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 61/353:  25%|██▌       | 1/4 [00:00<00:02,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 61/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.99s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 62/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 62/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 62/353:  50%|█████     | 2/4 [00:01<00:00,  2.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 62/353:  75%|███████▌  | 3/4 [00:07<00:03,  3.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 63/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 63/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 63/353:  50%|█████     | 2/4 [00:01<00:01,  1.74it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 63/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 64/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 64/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 64/353:  50%|█████     | 2/4 [00:01<00:01,  1.35it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 64/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 65/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 65/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 65/353:  50%|█████     | 2/4 [00:02<00:02,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 65/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.71s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 66/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 66/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 66/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 67/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 67/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 67/353:  50%|█████     | 2/4 [00:01<00:01,  1.45it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 67/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 68/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 68/353:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 68/353:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 68/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 69/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 69/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 69/353:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 69/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 70/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 70/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 70/353:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 70/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.61s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 71/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 71/353:  25%|██▌       | 1/4 [00:01<00:04,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 71/353:  50%|█████     | 2/4 [00:01<00:01,  1.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 71/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 72/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 72/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 72/353:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 72/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 73/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 73/353:  25%|██▌       | 1/4 [00:01<00:04,  1.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 73/353:  50%|█████     | 2/4 [00:02<00:02,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 73/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 74/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 74/353:  25%|██▌       | 1/4 [00:01<00:04,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 74/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 75/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 75/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 75/353:  50%|█████     | 2/4 [00:03<00:03,  1.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 75/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 76/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 76/353:  25%|██▌       | 1/4 [00:01<00:04,  1.60s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 76/353:  50%|█████     | 2/4 [00:02<00:02,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 76/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.73s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 77/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 77/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 77/353:  50%|█████     | 2/4 [00:01<00:01,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 77/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.55s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 78/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 78/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 78/353:  50%|█████     | 2/4 [00:01<00:01,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 78/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 79/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 79/353:  25%|██▌       | 1/4 [00:01<00:04,  1.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 79/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 80/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 80/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 80/353:  50%|█████     | 2/4 [00:01<00:01,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 80/353:  75%|███████▌  | 3/4 [00:10<00:04,  4.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 81/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 81/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 81/353:  50%|█████     | 2/4 [00:01<00:01,  1.81it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 81/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 82/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 82/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 82/353:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 82/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 83/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 83/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 83/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 84/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 84/353:  25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 84/353:  50%|█████     | 2/4 [00:01<00:01,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 84/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 85/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 85/353:  25%|██▌       | 1/4 [00:00<00:02,  1.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 85/353:  50%|█████     | 2/4 [00:01<00:01,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 85/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 86/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 86/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 86/353:  50%|█████     | 2/4 [00:01<00:01,  1.30it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 86/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 87/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 87/353:  25%|██▌       | 1/4 [00:01<00:04,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 87/353:  50%|█████     | 2/4 [00:01<00:01,  1.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 87/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.78s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 88/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 88/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 88/353:  50%|█████     | 2/4 [00:01<00:01,  1.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 88/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 89/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 89/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 89/353:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 89/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 90/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 90/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 90/353:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 90/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.71s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 91/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 91/353:  25%|██▌       | 1/4 [00:01<00:04,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 91/353:  50%|█████     | 2/4 [00:01<00:01,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 91/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.84s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 92/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 92/353:  25%|██▌       | 1/4 [00:01<00:04,  1.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 92/353:  50%|█████     | 2/4 [00:01<00:01,  1.29it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 92/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 93/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 93/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 93/353:  50%|█████     | 2/4 [00:01<00:01,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 93/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.73s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 94/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 94/353:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 94/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 95/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 95/353:  25%|██▌       | 1/4 [00:00<00:02,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 95/353:  50%|█████     | 2/4 [00:01<00:00,  2.22it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 95/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 96/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 96/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 96/353:  50%|█████     | 2/4 [00:01<00:01,  1.73it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 96/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.55s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 97/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 97/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 97/353:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 97/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 98/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 98/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 98/353:  50%|█████     | 2/4 [00:01<00:01,  1.58it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 98/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 99/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 99/353:  25%|██▌       | 1/4 [00:01<00:04,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 99/353:  50%|█████     | 2/4 [00:01<00:01,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 99/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 100/353:   0%|          | 0/4 [00:00<?, ?it/s]       INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 100/353:  25%|██▌       | 1/4 [00:00<00:02,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 100/353:  50%|█████     | 2/4 [00:01<00:01,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 100/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 101/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 101/353:  25%|██▌       | 1/4 [00:00<00:02,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 101/353:  50%|█████     | 2/4 [00:02<00:02,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 101/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 102/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 102/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 102/353:  50%|█████     | 2/4 [00:02<00:03,  1.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 102/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 103/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 103/353:  25%|██▌       | 1/4 [00:01<00:05,  1.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 103/353:  50%|█████     | 2/4 [00:03<00:03,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 103/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 104/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 104/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 104/353:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 104/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 105/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 105/353:  25%|██▌       | 1/4 [00:01<00:05,  1.97s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 105/353:  50%|█████     | 2/4 [00:02<00:02,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 105/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 106/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 106/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 106/353:  50%|█████     | 2/4 [00:01<00:01,  1.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 106/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 107/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 107/353:  25%|██▌       | 1/4 [00:01<00:04,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 107/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 108/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 108/353:  25%|██▌       | 1/4 [00:01<00:04,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 108/353:  50%|█████     | 2/4 [00:02<00:02,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 108/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.86s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 109/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 109/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 109/353:  50%|█████     | 2/4 [00:01<00:01,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 109/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 110/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 110/353:  25%|██▌       | 1/4 [00:01<00:04,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 110/353:  50%|█████     | 2/4 [00:01<00:01,  1.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 110/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 111/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 111/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 111/353:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 111/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 112/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 112/353:  25%|██▌       | 1/4 [00:00<00:02,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 112/353:  50%|█████     | 2/4 [00:01<00:01,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 112/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 113/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 113/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 113/353:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 113/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 114/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 114/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 114/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 115/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 115/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 115/353:  50%|█████     | 2/4 [00:01<00:01,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 115/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.72s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 116/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 116/353:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 116/353:  50%|█████     | 2/4 [00:01<00:00,  2.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 116/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 117/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 117/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 117/353:  50%|█████     | 2/4 [00:01<00:01,  1.81it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 117/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.90s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 118/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 118/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 118/353:  50%|█████     | 2/4 [00:01<00:01,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 118/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 119/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 119/353:  25%|██▌       | 1/4 [00:00<00:02,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 119/353:  50%|█████     | 2/4 [00:02<00:02,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 119/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 120/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 120/353:  25%|██▌       | 1/4 [00:01<00:04,  1.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 120/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 121/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 121/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 121/353:  50%|█████     | 2/4 [00:01<00:01,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 121/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 122/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 122/353:  25%|██▌       | 1/4 [00:02<00:07,  2.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 122/353:  50%|█████     | 2/4 [00:03<00:03,  1.61s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 122/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 123/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 123/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 123/353:  50%|█████     | 2/4 [00:01<00:01,  1.59it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 123/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 124/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 124/353:  25%|██▌       | 1/4 [00:01<00:04,  1.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 124/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 125/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 125/353:  25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 125/353:  50%|█████     | 2/4 [00:01<00:01,  1.88it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 125/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.68s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 126/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 126/353:  25%|██▌       | 1/4 [00:02<00:06,  2.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 126/353:  50%|█████     | 2/4 [00:02<00:02,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 126/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 127/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 127/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 127/353:  50%|█████     | 2/4 [00:02<00:02,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 127/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 128/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 128/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 128/353:  50%|█████     | 2/4 [00:01<00:01,  1.37it/s]INFO:openai._base_client:Retrying request to /chat/completions in 0.458812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493876 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 128/353:  75%|███████▌  | 3/4 [13:32<06:10, 370.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 129/353:   0%|          | 0/4 [00:00<?, ?it/s]         INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 129/353:  25%|██▌       | 1/4 [00:02<00:06,  2.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 129/353:  50%|█████     | 2/4 [00:03<00:02,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 129/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.55s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 130/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 130/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 130/353:  50%|█████     | 2/4 [00:02<00:02,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 130/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 131/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 131/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 131/353:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 131/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 132/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 132/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 132/353:  50%|█████     | 2/4 [00:01<00:01,  1.88it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 132/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 133/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 133/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 133/353:  50%|█████     | 2/4 [00:02<00:02,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 133/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 134/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 134/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 134/353:  50%|█████     | 2/4 [00:01<00:01,  1.44it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 134/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.60s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 135/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 135/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 135/353:  50%|█████     | 2/4 [00:01<00:01,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 135/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 136/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 136/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 136/353:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 136/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 137/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 137/353:  25%|██▌       | 1/4 [00:01<00:04,  1.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 137/353:  50%|█████     | 2/4 [00:02<00:02,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 137/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.75s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 138/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 138/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 138/353:  50%|█████     | 2/4 [00:01<00:01,  1.76it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 138/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 139/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 139/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 139/353:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 139/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 140/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 140/353:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 140/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 141/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 141/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 141/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 142/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 142/353:  25%|██▌       | 1/4 [00:01<00:04,  1.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 142/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.92s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 143/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 143/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 143/353:  50%|█████     | 2/4 [00:01<00:01,  1.82it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 143/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 144/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 144/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 144/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.74s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 145/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 145/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 145/353:  50%|█████     | 2/4 [00:01<00:01,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 145/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 146/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "Batch 146/353:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 146/353:  50%|█████     | 2/4 [00:01<00:01,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 146/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.61s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 147/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 147/353:  25%|██▌       | 1/4 [00:01<00:04,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 147/353:  50%|█████     | 2/4 [00:01<00:01,  1.31it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 147/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 148/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 148/353:  25%|██▌       | 1/4 [00:01<00:05,  1.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 148/353:  50%|█████     | 2/4 [00:01<00:01,  1.32it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 148/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 149/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 149/353:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 149/353:  50%|█████     | 2/4 [00:01<00:01,  1.41it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 149/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 150/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 150/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 150/353:  50%|█████     | 2/4 [00:01<00:01,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 150/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 151/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 151/353:  25%|██▌       | 1/4 [00:01<00:04,  1.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 151/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 152/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 152/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 152/353:  50%|█████     | 2/4 [00:01<00:01,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 152/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.86s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 153/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 153/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 153/353:  50%|█████     | 2/4 [00:01<00:01,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 153/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 154/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 154/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 154/353:  50%|█████     | 2/4 [00:01<00:01,  1.39it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 154/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 155/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 155/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 155/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 156/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 156/353:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 156/353:  50%|█████     | 2/4 [00:01<00:01,  1.98it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 156/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 157/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 157/353:  25%|██▌       | 1/4 [00:01<00:04,  1.55s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 157/353:  50%|█████     | 2/4 [00:04<00:04,  2.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 157/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 158/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 158/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 158/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 159/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 159/353:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 159/353:  50%|█████     | 2/4 [00:01<00:01,  1.97it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 159/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 160/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 160/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 160/353:  50%|█████     | 2/4 [00:01<00:01,  1.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 160/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 161/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 161/353:  25%|██▌       | 1/4 [00:01<00:05,  1.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 161/353:  50%|█████     | 2/4 [00:03<00:03,  1.75s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 161/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 162/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 162/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 162/353:  50%|█████     | 2/4 [00:01<00:01,  1.68it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 162/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 163/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 163/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 163/353:  50%|█████     | 2/4 [00:01<00:01,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 163/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.72s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 164/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 164/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 164/353:  50%|█████     | 2/4 [00:01<00:01,  1.59it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 164/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 165/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 165/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 165/353:  50%|█████     | 2/4 [00:01<00:01,  1.28it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 165/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 166/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 166/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 166/353:  50%|█████     | 2/4 [00:02<00:02,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 166/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 167/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 167/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 167/353:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 167/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 168/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 168/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 168/353:  50%|█████     | 2/4 [00:01<00:01,  1.32it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 168/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.96s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 169/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 169/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 169/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 170/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 170/353:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 170/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 171/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 171/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 171/353:  50%|█████     | 2/4 [00:03<00:03,  1.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 171/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.55s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 172/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 172/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 172/353:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 172/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 173/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 173/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 173/353:  50%|█████     | 2/4 [00:01<00:01,  1.58it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 173/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 174/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 174/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 174/353:  50%|█████     | 2/4 [00:01<00:01,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 174/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 175/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 175/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 175/353:  50%|█████     | 2/4 [00:01<00:01,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 175/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 176/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 176/353:  25%|██▌       | 1/4 [00:01<00:04,  1.60s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 176/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 177/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 177/353:  25%|██▌       | 1/4 [00:00<00:02,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 177/353:  50%|█████     | 2/4 [00:03<00:03,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 177/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 178/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 178/353:  25%|██▌       | 1/4 [00:01<00:04,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 178/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 179/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 179/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 179/353:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 179/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 180/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 180/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 180/353:  50%|█████     | 2/4 [00:01<00:01,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 180/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 181/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 181/353:  25%|██▌       | 1/4 [00:00<00:02,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 181/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.84s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 182/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 182/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 182/353:  50%|█████     | 2/4 [00:01<00:01,  1.29it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 182/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 183/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 183/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 183/353:  50%|█████     | 2/4 [00:02<00:02,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 183/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 184/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 184/353:  25%|██▌       | 1/4 [00:01<00:04,  1.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 184/353:  50%|█████     | 2/4 [00:02<00:01,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 184/353:  75%|███████▌  | 3/4 [00:07<00:02,  2.98s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 185/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 185/353:  25%|██▌       | 1/4 [00:01<00:04,  1.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 185/353:  50%|█████     | 2/4 [00:02<00:02,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 185/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 186/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 186/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 186/353:  50%|█████     | 2/4 [00:01<00:01,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 186/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 187/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 187/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 187/353:  50%|█████     | 2/4 [00:02<00:02,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 187/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 188/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 188/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 188/353:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 188/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 189/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 189/353:  25%|██▌       | 1/4 [00:01<00:04,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 189/353:  50%|█████     | 2/4 [00:01<00:01,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 189/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 190/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 190/353:  25%|██▌       | 1/4 [00:01<00:04,  1.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 190/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 191/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 191/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 191/353:  50%|█████     | 2/4 [00:01<00:01,  1.80it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 191/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 192/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 192/353:  25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 192/353:  75%|███████▌  | 3/4 [00:08<00:02,  2.95s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 193/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 193/353:  25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 193/353:  50%|█████     | 2/4 [00:01<00:01,  1.40it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 193/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.84s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 194/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 194/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 194/353:  50%|█████     | 2/4 [00:01<00:01,  1.73it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 194/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 195/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 195/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 195/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 196/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 196/353:  25%|██▌       | 1/4 [00:01<00:05,  1.90s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 196/353:  50%|█████     | 2/4 [00:02<00:02,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 196/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 197/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 197/353:  25%|██▌       | 1/4 [00:00<00:02,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 197/353:  50%|█████     | 2/4 [00:01<00:00,  2.22it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 197/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 198/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 198/353:  25%|██▌       | 1/4 [00:01<00:04,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 198/353:  50%|█████     | 2/4 [00:02<00:01,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 198/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 199/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 199/353:  25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 199/353:  50%|█████     | 2/4 [00:01<00:00,  2.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 199/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 200/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 200/353:  25%|██▌       | 1/4 [00:01<00:04,  1.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 200/353:  50%|█████     | 2/4 [00:02<00:02,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 200/353:  75%|███████▌  | 3/4 [00:07<00:02,  2.84s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 201/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 201/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 201/353:  50%|█████     | 2/4 [00:01<00:01,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 201/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 202/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 202/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 202/353:  50%|█████     | 2/4 [00:01<00:01,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 202/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 203/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 203/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 203/353:  50%|█████     | 2/4 [00:04<00:04,  2.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 203/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.85s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 204/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 204/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 204/353:  50%|█████     | 2/4 [00:01<00:01,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 204/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.90s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 205/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 205/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 205/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 206/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 206/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 206/353:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 206/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 207/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 207/353:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 207/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 208/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 208/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 208/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 209/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 209/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 209/353:  50%|█████     | 2/4 [00:01<00:01,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 209/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 210/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 210/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 210/353:  50%|█████     | 2/4 [00:01<00:01,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 210/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 211/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 211/353:  25%|██▌       | 1/4 [00:00<00:02,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 211/353:  50%|█████     | 2/4 [00:01<00:01,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 211/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.72s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 212/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 212/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 212/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 213/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 213/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 213/353:  50%|█████     | 2/4 [00:04<00:05,  2.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 213/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.73s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 214/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 214/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 214/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 215/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 215/353:  25%|██▌       | 1/4 [00:01<00:04,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 215/353:  50%|█████     | 2/4 [00:03<00:02,  1.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 215/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 216/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 216/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 216/353:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 216/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.97s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 217/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 217/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 217/353:  50%|█████     | 2/4 [00:01<00:01,  1.57it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 217/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 218/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 218/353:  25%|██▌       | 1/4 [00:00<00:02,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 218/353:  50%|█████     | 2/4 [00:01<00:01,  1.71it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 218/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 219/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 219/353:  25%|██▌       | 1/4 [00:00<00:02,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 219/353:  50%|█████     | 2/4 [00:01<00:01,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 219/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 220/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 220/353:  25%|██▌       | 1/4 [00:00<00:02,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 220/353:  50%|█████     | 2/4 [00:02<00:02,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 220/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 221/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 221/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 221/353:  50%|█████     | 2/4 [00:01<00:01,  1.71it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 221/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 222/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 222/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 222/353:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 222/353:  75%|███████▌  | 3/4 [00:07<00:03,  3.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 223/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 223/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 223/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 224/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 224/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 224/353:  50%|█████     | 2/4 [00:01<00:01,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 224/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 225/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 225/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 225/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 226/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 226/353:  25%|██▌       | 1/4 [00:01<00:04,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 226/353:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 226/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 227/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 227/353:  25%|██▌       | 1/4 [00:01<00:04,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 227/353:  50%|█████     | 2/4 [00:03<00:03,  1.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 227/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 228/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 228/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 228/353:  50%|█████     | 2/4 [00:01<00:01,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 228/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 229/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 229/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 229/353:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 229/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 230/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 230/353:  25%|██▌       | 1/4 [00:04<00:12,  4.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 230/353:  50%|█████     | 2/4 [00:04<00:03,  1.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 230/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 231/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 231/353:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 231/353:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 231/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 232/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 232/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 232/353:  50%|█████     | 2/4 [00:01<00:01,  1.74it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 232/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.61s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 233/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 233/353:  25%|██▌       | 1/4 [00:01<00:04,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 233/353:  50%|█████     | 2/4 [00:01<00:01,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 233/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 234/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 234/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 234/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 235/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 235/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 235/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 236/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 236/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 236/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 237/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 237/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 237/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 238/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 238/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 238/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 239/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 239/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 239/353:  50%|█████     | 2/4 [00:01<00:01,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 239/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 240/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 240/353:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 240/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 241/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 241/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 241/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 242/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 242/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 242/353:  50%|█████     | 2/4 [00:01<00:01,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 242/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 243/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 243/353:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 243/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 244/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 244/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 244/353:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 244/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.64s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 245/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 245/353:  25%|██▌       | 1/4 [00:01<00:04,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 245/353:  50%|█████     | 2/4 [00:01<00:01,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 245/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 246/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 246/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 246/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 247/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 247/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 247/353:  50%|█████     | 2/4 [00:01<00:01,  1.68it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 247/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 248/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 248/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 248/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 249/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 249/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 249/353:  50%|█████     | 2/4 [00:01<00:01,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 249/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 250/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 250/353:  25%|██▌       | 1/4 [00:01<00:04,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 250/353:  50%|█████     | 2/4 [00:01<00:01,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 250/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 251/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 251/353:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 251/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.40it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 252/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 252/353:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 252/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 253/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 253/353:  25%|██▌       | 1/4 [00:00<00:02,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 253/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 254/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 254/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 254/353:  50%|█████     | 2/4 [00:02<00:02,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 254/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 255/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 255/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 255/353:  50%|█████     | 2/4 [00:02<00:03,  1.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 255/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.78s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 256/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 256/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 256/353:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 256/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 257/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 257/353:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 257/353:  50%|█████     | 2/4 [00:01<00:01,  1.91it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 257/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 258/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 258/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 258/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 259/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 259/353:  25%|██▌       | 1/4 [00:01<00:03,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 259/353:  50%|█████     | 2/4 [00:01<00:01,  1.81it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 259/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 260/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 260/353:  25%|██▌       | 1/4 [00:01<00:04,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 260/353:  50%|█████     | 2/4 [00:01<00:01,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 260/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 261/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 261/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 261/353:  50%|█████     | 2/4 [00:01<00:01,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 261/353:  75%|███████▌  | 3/4 [00:05<00:01,  2.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 262/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 262/353:  25%|██▌       | 1/4 [00:01<00:04,  1.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 262/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 263/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 263/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 263/353:  50%|█████     | 2/4 [00:01<00:01,  1.71it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 263/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.81s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 264/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 264/353:  25%|██▌       | 1/4 [00:01<00:04,  1.66s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 264/353:  50%|█████     | 2/4 [00:04<00:05,  2.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 264/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 265/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 265/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 265/353:  50%|█████     | 2/4 [00:01<00:01,  1.89it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 265/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 266/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 266/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 266/353:  50%|█████     | 2/4 [00:01<00:00,  2.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 267/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 267/353:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 267/353:  50%|█████     | 2/4 [00:01<00:01,  1.66it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 267/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 268/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 268/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 268/353:  50%|█████     | 2/4 [00:01<00:01,  1.45it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 268/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 269/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 269/353:  25%|██▌       | 1/4 [00:01<00:03,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 269/353:  50%|█████     | 2/4 [00:01<00:01,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 269/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 270/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 270/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 270/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 271/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 271/353:  25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 271/353:  50%|█████     | 2/4 [00:01<00:01,  1.61it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 271/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 272/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 272/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 272/353:  50%|█████     | 2/4 [00:01<00:01,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 272/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 273/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 273/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 273/353:  50%|█████     | 2/4 [00:01<00:01,  1.81it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 273/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 274/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 274/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 274/353:  50%|█████     | 2/4 [00:01<00:01,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 274/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 275/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "Batch 275/353:  25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 275/353:  50%|█████     | 2/4 [00:01<00:01,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 275/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 276/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 276/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 276/353:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 276/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 277/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 277/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 277/353:  50%|█████     | 2/4 [00:04<00:04,  2.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 277/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 278/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 278/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 278/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 279/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 279/353:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 279/353:  50%|█████     | 2/4 [00:01<00:01,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 279/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 280/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 280/353:  25%|██▌       | 1/4 [00:01<00:04,  1.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 280/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 281/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 281/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 281/353:  50%|█████     | 2/4 [00:01<00:01,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 281/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 282/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 282/353:  25%|██▌       | 1/4 [00:01<00:05,  1.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 282/353:  50%|█████     | 2/4 [00:02<00:02,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 282/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 283/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 283/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 284/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 284/353:  25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 284/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.85s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 285/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 285/353:  25%|██▌       | 1/4 [00:01<00:05,  1.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 285/353:  50%|█████     | 2/4 [00:02<00:01,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 285/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 286/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 286/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 286/353:  50%|█████     | 2/4 [00:01<00:01,  1.56it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 286/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 287/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 287/353:  25%|██▌       | 1/4 [00:01<00:04,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 287/353:  50%|█████     | 2/4 [00:02<00:02,  1.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 287/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 288/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 288/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 288/353:  50%|█████     | 2/4 [00:01<00:01,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 288/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 289/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 289/353:  25%|██▌       | 1/4 [00:01<00:04,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 289/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 290/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 290/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 290/353:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 290/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 291/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 291/353:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 291/353:  50%|█████     | 2/4 [00:01<00:01,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 291/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 292/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 292/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 292/353:  50%|█████     | 2/4 [00:01<00:01,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 292/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 293/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 293/353:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 293/353:  50%|█████     | 2/4 [00:02<00:02,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 293/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 294/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 294/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 294/353:  50%|█████     | 2/4 [00:01<00:00,  2.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 294/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 295/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 295/353:  25%|██▌       | 1/4 [00:01<00:05,  1.94s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 295/353:  50%|█████     | 2/4 [00:02<00:01,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 295/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 296/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 296/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 296/353:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 297/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 297/353:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 297/353:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 297/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.66s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 298/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 298/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 299/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 299/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 299/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 300/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 300/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 300/353:  50%|█████     | 2/4 [00:02<00:01,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 300/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 301/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 301/353:  25%|██▌       | 1/4 [00:00<00:02,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 301/353:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 301/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 302/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 302/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 302/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 303/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 303/353:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 303/353:  50%|█████     | 2/4 [00:01<00:01,  1.58it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 303/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 304/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 304/353:  25%|██▌       | 1/4 [00:00<00:02,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 304/353:  50%|█████     | 2/4 [00:01<00:01,  1.87it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 304/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 305/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 305/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 305/353:  50%|█████     | 2/4 [00:01<00:01,  1.76it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 305/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 306/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 306/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 306/353:  50%|█████     | 2/4 [00:01<00:01,  1.82it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 306/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 307/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 307/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 307/353:  50%|█████     | 2/4 [00:01<00:01,  1.96it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 307/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 308/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 308/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 308/353:  50%|█████     | 2/4 [00:01<00:01,  1.78it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 308/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.22it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 309/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 309/353:  25%|██▌       | 1/4 [00:00<00:02,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 309/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 310/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 310/353:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 310/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 311/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 311/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 311/353:  50%|█████     | 2/4 [00:01<00:01,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 311/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 312/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 312/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 312/353:  50%|█████     | 2/4 [00:01<00:01,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 312/353:  75%|███████▌  | 3/4 [00:02<00:01,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 313/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 313/353:  25%|██▌       | 1/4 [00:01<00:03,  1.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 313/353:  50%|█████     | 2/4 [00:01<00:01,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 313/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 314/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 314/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 314/353:  50%|█████     | 2/4 [00:01<00:01,  1.92it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 314/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 315/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 315/353:  25%|██▌       | 1/4 [00:01<00:03,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 315/353:  50%|█████     | 2/4 [00:02<00:03,  1.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 315/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 316/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 316/353:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 316/353:  75%|███████▌  | 3/4 [00:09<00:03,  3.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 317/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 317/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 317/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 318/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 318/353:  25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 318/353:  50%|█████     | 2/4 [00:01<00:01,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 318/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 319/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 319/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 319/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.22it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 320/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 320/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 320/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 321/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 321/353:  25%|██▌       | 1/4 [00:00<00:02,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 321/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 322/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 322/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 322/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 323/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 323/353:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 323/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 324/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 324/353:  25%|██▌       | 1/4 [00:00<00:02,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 324/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 325/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 325/353:  25%|██▌       | 1/4 [00:00<00:02,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 325/353:  50%|█████     | 2/4 [00:01<00:00,  2.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 325/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 326/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 326/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 326/353:  50%|█████     | 2/4 [00:01<00:01,  1.44it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 326/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.60it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 327/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 327/353:  25%|██▌       | 1/4 [00:02<00:06,  2.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 327/353:  50%|█████     | 2/4 [00:05<00:05,  2.75s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 327/353:  75%|███████▌  | 3/4 [00:05<00:01,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 328/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 328/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 328/353:  50%|█████     | 2/4 [00:01<00:01,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 328/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 329/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 329/353:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 329/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 330/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 330/353:  25%|██▌       | 1/4 [00:00<00:02,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 330/353:  50%|█████     | 2/4 [00:02<00:02,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 330/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 331/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 331/353:  25%|██▌       | 1/4 [00:01<00:04,  1.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 331/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 332/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 332/353:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 332/353:  50%|█████     | 2/4 [00:01<00:01,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 332/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 333/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 333/353:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 333/353:  50%|█████     | 2/4 [00:01<00:01,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 333/353:  75%|███████▌  | 3/4 [00:08<00:03,  3.61s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 334/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 334/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 334/353:  50%|█████     | 2/4 [00:01<00:01,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 334/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 335/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 335/353:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 335/353:  50%|█████     | 2/4 [00:01<00:01,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 335/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 336/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 336/353:  25%|██▌       | 1/4 [00:01<00:04,  1.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 336/353:  50%|█████     | 2/4 [00:01<00:01,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 336/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 337/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 337/353:  25%|██▌       | 1/4 [00:01<00:04,  1.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 337/353:  50%|█████     | 2/4 [00:01<00:01,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 337/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 338/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 338/353:  25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 338/353:  50%|█████     | 2/4 [00:01<00:01,  1.94it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 338/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 339/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 339/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 339/353:  50%|█████     | 2/4 [00:01<00:01,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 339/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 340/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 340/353:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 340/353:  50%|█████     | 2/4 [00:01<00:01,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 340/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 341/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 341/353:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 341/353:  50%|█████     | 2/4 [00:01<00:01,  1.75it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 341/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 342/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 342/353:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 342/353:  50%|█████     | 2/4 [00:02<00:02,  1.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 342/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 343/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 343/353:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 343/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 344/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 344/353:  25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 344/353:  50%|█████     | 2/4 [00:01<00:01,  1.31it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 344/353:  75%|███████▌  | 3/4 [00:06<00:02,  2.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 345/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 345/353:  25%|██▌       | 1/4 [00:01<00:04,  1.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 345/353:  50%|█████     | 2/4 [00:02<00:01,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 345/353:  75%|███████▌  | 3/4 [00:05<00:02,  2.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 346/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 346/353:  25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 346/353:  75%|███████▌  | 3/4 [00:03<00:00,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 347/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 347/353:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 347/353:  50%|█████     | 2/4 [00:01<00:01,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 347/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.74s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 348/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 348/353:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 348/353:  50%|█████     | 2/4 [00:01<00:01,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 348/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 349/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 349/353:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 349/353:  50%|█████     | 2/4 [00:02<00:02,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 349/353:  75%|███████▌  | 3/4 [00:04<00:01,  1.72s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 350/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 350/353:  25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 350/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 351/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 351/353:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 351/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 352/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 352/353:  25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 352/353:  75%|███████▌  | 3/4 [00:02<00:00,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 353/353:   0%|          | 0/4 [00:00<?, ?it/s]        INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragas.llms.base:temperature kwarg passed to LlamaIndex LLM\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 353/353:  25%|██▌       | 1/4 [00:01<00:04,  1.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batch 353/353:  75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating: 100%|██████████| 1412/1412 [50:47<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "results = evaluation_utilities.run_ragas(datasets, evaluator_llm_for_ragas, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama Stack:meta-llama/llama-3-3-70b-instruct': {'nv_accuracy': 0.5089, 'domain_specific_rubrics': 4.0241},\n",
       " 'LlamaIndex:meta-llama/llama-3-3-70b-instruct': {'nv_accuracy': 0.4851, 'domain_specific_rubrics': 3.9618}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama Stack:meta-llama/llama-3-3-70b-instruct\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>nv_accuracy</th>\n",
       "      <th>domain_specific_rubrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on IBM's 2024 Annual Report, how might t...</td>\n",
       "      <td>[## Dear IBM Investor:\\n\\nIn 2024, IBM made si...</td>\n",
       "      <td>Based on the 2024 Annual Report, IBM's financi...</td>\n",
       "      <td>Based on IBM's 2024 Annual Report, the company...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Based on the trends and projections outlined i...</td>\n",
       "      <td>[## 2024 Performance\\n\\nFor the year, IBM gene...</td>\n",
       "      <td>Based on the IBM 2024 Annual Report, the compa...</td>\n",
       "      <td>Based on the trends and projections outlined i...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How could IBM's investment in research and dev...</td>\n",
       "      <td>[## Dear IBM Investor:\\n\\nIn 2024, IBM made si...</td>\n",
       "      <td>IBM's investment in research and development h...</td>\n",
       "      <td>IBM's investment in research and development (...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did IBM adapt its operations in response t...</td>\n",
       "      <td>[## DESCRIPTION OF BUSINESS\\n\\nPlease refer to...</td>\n",
       "      <td>In 2024, IBM adapted to technological disrupti...</td>\n",
       "      <td>In 2024, IBM adapted its operations in respons...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How did IBM measure the success of its digital...</td>\n",
       "      <td>[## Our go-to-market approach\\n\\nOver the last...</td>\n",
       "      <td>IBM measured the success of its digital innova...</td>\n",
       "      <td>In 2024, IBM measured the success of its digit...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Based on IBM's 2024 Annual Report, how might t...   \n",
       "1  Based on the trends and projections outlined i...   \n",
       "2  How could IBM's investment in research and dev...   \n",
       "3  How did IBM adapt its operations in response t...   \n",
       "4  How did IBM measure the success of its digital...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [## Dear IBM Investor:\\n\\nIn 2024, IBM made si...   \n",
       "1  [## 2024 Performance\\n\\nFor the year, IBM gene...   \n",
       "2  [## Dear IBM Investor:\\n\\nIn 2024, IBM made si...   \n",
       "3  [## DESCRIPTION OF BUSINESS\\n\\nPlease refer to...   \n",
       "4  [## Our go-to-market approach\\n\\nOver the last...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Based on the 2024 Annual Report, IBM's financi...   \n",
       "1  Based on the IBM 2024 Annual Report, the compa...   \n",
       "2  IBM's investment in research and development h...   \n",
       "3  In 2024, IBM adapted to technological disrupti...   \n",
       "4  IBM measured the success of its digital innova...   \n",
       "\n",
       "                                           reference  nv_accuracy  \\\n",
       "0  Based on IBM's 2024 Annual Report, the company...         1.00   \n",
       "1  Based on the trends and projections outlined i...         0.75   \n",
       "2  IBM's investment in research and development (...         0.75   \n",
       "3  In 2024, IBM adapted its operations in respons...         0.50   \n",
       "4  In 2024, IBM measured the success of its digit...         0.75   \n",
       "\n",
       "   domain_specific_rubrics  \n",
       "0                        5  \n",
       "1                        5  \n",
       "2                        5  \n",
       "3                        5  \n",
       "4                        4  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(results.keys())\n",
    "print(keys[0])\n",
    "results[keys[0]].to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaIndex:meta-llama/llama-3-3-70b-instruct\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>nv_accuracy</th>\n",
       "      <th>domain_specific_rubrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on IBM's 2024 Annual Report, how might t...</td>\n",
       "      <td>[1\\nFinancial Position\\nDynamics\\nOur balance ...</td>\n",
       "      <td>[## Dear IBM Investor:\\n\\nIn 2024, IBM made si...</td>\n",
       "      <td>Based on IBM's 2024 Annual Report, the company...</td>\n",
       "      <td>Based on IBM's 2024 Annual Report, the company...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Based on the trends and projections outlined i...</td>\n",
       "      <td>[IBM 2024 Annual Report 1\\nArvind Krishna\\nCha...</td>\n",
       "      <td>[## 2024 Performance\\n\\nFor the year, IBM gene...</td>\n",
       "      <td>1. Hybrid Cloud and AI Integration: IBM will l...</td>\n",
       "      <td>Based on the trends and projections outlined i...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How could IBM's investment in research and dev...</td>\n",
       "      <td>[In support for each business segment, our AI ...</td>\n",
       "      <td>[## Dear IBM Investor:\\n\\nIn 2024, IBM made si...</td>\n",
       "      <td>IBM's investment in research and development c...</td>\n",
       "      <td>IBM's investment in research and development (...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did IBM adapt its operations in response t...</td>\n",
       "      <td>[In support for each business segment, our AI ...</td>\n",
       "      <td>[## DESCRIPTION OF BUSINESS\\n\\nPlease refer to...</td>\n",
       "      <td>IBM adapted its operations in response to tech...</td>\n",
       "      <td>In 2024, IBM adapted its operations in respons...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How did IBM measure the success of its digital...</td>\n",
       "      <td>[We recognize \\nthat no single company can pro...</td>\n",
       "      <td>[## Our go-to-market approach\\n\\nOver the last...</td>\n",
       "      <td>IBM measured the success of its digital innova...</td>\n",
       "      <td>In 2024, IBM measured the success of its digit...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Based on IBM's 2024 Annual Report, how might t...   \n",
       "1  Based on the trends and projections outlined i...   \n",
       "2  How could IBM's investment in research and dev...   \n",
       "3  How did IBM adapt its operations in response t...   \n",
       "4  How did IBM measure the success of its digital...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [1\\nFinancial Position\\nDynamics\\nOur balance ...   \n",
       "1  [IBM 2024 Annual Report 1\\nArvind Krishna\\nCha...   \n",
       "2  [In support for each business segment, our AI ...   \n",
       "3  [In support for each business segment, our AI ...   \n",
       "4  [We recognize \\nthat no single company can pro...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [## Dear IBM Investor:\\n\\nIn 2024, IBM made si...   \n",
       "1  [## 2024 Performance\\n\\nFor the year, IBM gene...   \n",
       "2  [## Dear IBM Investor:\\n\\nIn 2024, IBM made si...   \n",
       "3  [## DESCRIPTION OF BUSINESS\\n\\nPlease refer to...   \n",
       "4  [## Our go-to-market approach\\n\\nOver the last...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Based on IBM's 2024 Annual Report, the company...   \n",
       "1  1. Hybrid Cloud and AI Integration: IBM will l...   \n",
       "2  IBM's investment in research and development c...   \n",
       "3  IBM adapted its operations in response to tech...   \n",
       "4  IBM measured the success of its digital innova...   \n",
       "\n",
       "                                           reference  nv_accuracy  \\\n",
       "0  Based on IBM's 2024 Annual Report, the company...         1.00   \n",
       "1  Based on the trends and projections outlined i...         0.50   \n",
       "2  IBM's investment in research and development (...         0.75   \n",
       "3  In 2024, IBM adapted its operations in respons...         0.50   \n",
       "4  In 2024, IBM measured the success of its digit...         0.75   \n",
       "\n",
       "   domain_specific_rubrics  \n",
       "0                        4  \n",
       "1                        5  \n",
       "2                        4  \n",
       "3                        5  \n",
       "4                        5  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(keys[1])\n",
    "results[keys[1]].to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess statistical significance\n",
    "\n",
    "Here we use Fisher's randomization test to judge whether those results are statistically significant both for the full set and for the subset that are marked as having complete reference answers.  We set the permutation_type='samples' because each of the models is using the same questions in the same order so we're doing a paired-sample test here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Llama Stack:meta-llama/llama-3-3-70b-instruct',\n",
       "  'LlamaIndex:meta-llama/llama-3-3-70b-instruct')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "result_pairs = list(itertools.combinations(results.keys(), 2))\n",
    "result_summary = []\n",
    "result_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_of_rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>nv_accuracy</th>\n",
       "      <th>domain_specific_rubrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on IBM's 2024 Annual Report, how might t...</td>\n",
       "      <td>[## Dear IBM Investor:\\n\\nIn 2024, IBM made si...</td>\n",
       "      <td>Based on the 2024 Annual Report, IBM's financi...</td>\n",
       "      <td>Based on IBM's 2024 Annual Report, the company...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Based on the trends and projections outlined i...</td>\n",
       "      <td>[## 2024 Performance\\n\\nFor the year, IBM gene...</td>\n",
       "      <td>Based on the IBM 2024 Annual Report, the compa...</td>\n",
       "      <td>Based on the trends and projections outlined i...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How could IBM's investment in research and dev...</td>\n",
       "      <td>[## Dear IBM Investor:\\n\\nIn 2024, IBM made si...</td>\n",
       "      <td>IBM's investment in research and development h...</td>\n",
       "      <td>IBM's investment in research and development (...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did IBM adapt its operations in response t...</td>\n",
       "      <td>[## DESCRIPTION OF BUSINESS\\n\\nPlease refer to...</td>\n",
       "      <td>In 2024, IBM adapted to technological disrupti...</td>\n",
       "      <td>In 2024, IBM adapted its operations in respons...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How did IBM measure the success of its digital...</td>\n",
       "      <td>[## Our go-to-market approach\\n\\nOver the last...</td>\n",
       "      <td>IBM measured the success of its digital innova...</td>\n",
       "      <td>In 2024, IBM measured the success of its digit...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Who is the Chairman of the Board at IBM accord...</td>\n",
       "      <td>[## Arvind Krishna\\n\\nChairman, President and ...</td>\n",
       "      <td>The Chairman of the Board at IBM according to ...</td>\n",
       "      <td>I'm sorry, but I don't have access to the 2024...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Who is the chairperson of IBM's Board of Direc...</td>\n",
       "      <td>[## Arvind Krishna\\n\\nChairman, President and ...</td>\n",
       "      <td>The chairperson of IBM's Board of Directors in...</td>\n",
       "      <td>Arvind Krishna is the Chairman of IBM.</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Who is the current CEO of IBM as mentioned in ...</td>\n",
       "      <td>[## Arvind Krishna\\n\\nChairman, President and ...</td>\n",
       "      <td>The current CEO of IBM as mentioned in the 202...</td>\n",
       "      <td>The context information provided does not spec...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Who is the intended audience for IBM's vision ...</td>\n",
       "      <td>[## Dear IBM Investor:\\n\\nIn 2024, IBM made si...</td>\n",
       "      <td>The intended audience for IBM's vision and mis...</td>\n",
       "      <td>The intended audience for IBM's vision and mis...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Who is the target audience for IBM's education...</td>\n",
       "      <td>[## Talent, Skills and Culture\\n\\nAt IBM, we'r...</td>\n",
       "      <td>The target audience for IBM's educational and ...</td>\n",
       "      <td>The target audience for IBM's educational and ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            user_input  \\\n",
       "0    Based on IBM's 2024 Annual Report, how might t...   \n",
       "1    Based on the trends and projections outlined i...   \n",
       "2    How could IBM's investment in research and dev...   \n",
       "3    How did IBM adapt its operations in response t...   \n",
       "4    How did IBM measure the success of its digital...   \n",
       "..                                                 ...   \n",
       "701  Who is the Chairman of the Board at IBM accord...   \n",
       "702  Who is the chairperson of IBM's Board of Direc...   \n",
       "703  Who is the current CEO of IBM as mentioned in ...   \n",
       "704  Who is the intended audience for IBM's vision ...   \n",
       "705  Who is the target audience for IBM's education...   \n",
       "\n",
       "                                    reference_contexts  \\\n",
       "0    [## Dear IBM Investor:\\n\\nIn 2024, IBM made si...   \n",
       "1    [## 2024 Performance\\n\\nFor the year, IBM gene...   \n",
       "2    [## Dear IBM Investor:\\n\\nIn 2024, IBM made si...   \n",
       "3    [## DESCRIPTION OF BUSINESS\\n\\nPlease refer to...   \n",
       "4    [## Our go-to-market approach\\n\\nOver the last...   \n",
       "..                                                 ...   \n",
       "701  [## Arvind Krishna\\n\\nChairman, President and ...   \n",
       "702  [## Arvind Krishna\\n\\nChairman, President and ...   \n",
       "703  [## Arvind Krishna\\n\\nChairman, President and ...   \n",
       "704  [## Dear IBM Investor:\\n\\nIn 2024, IBM made si...   \n",
       "705  [## Talent, Skills and Culture\\n\\nAt IBM, we'r...   \n",
       "\n",
       "                                              response  \\\n",
       "0    Based on the 2024 Annual Report, IBM's financi...   \n",
       "1    Based on the IBM 2024 Annual Report, the compa...   \n",
       "2    IBM's investment in research and development h...   \n",
       "3    In 2024, IBM adapted to technological disrupti...   \n",
       "4    IBM measured the success of its digital innova...   \n",
       "..                                                 ...   \n",
       "701  The Chairman of the Board at IBM according to ...   \n",
       "702  The chairperson of IBM's Board of Directors in...   \n",
       "703  The current CEO of IBM as mentioned in the 202...   \n",
       "704  The intended audience for IBM's vision and mis...   \n",
       "705  The target audience for IBM's educational and ...   \n",
       "\n",
       "                                             reference  nv_accuracy  \\\n",
       "0    Based on IBM's 2024 Annual Report, the company...         1.00   \n",
       "1    Based on the trends and projections outlined i...         0.75   \n",
       "2    IBM's investment in research and development (...         0.75   \n",
       "3    In 2024, IBM adapted its operations in respons...         0.50   \n",
       "4    In 2024, IBM measured the success of its digit...         0.75   \n",
       "..                                                 ...          ...   \n",
       "701  I'm sorry, but I don't have access to the 2024...         0.75   \n",
       "702             Arvind Krishna is the Chairman of IBM.         0.75   \n",
       "703  The context information provided does not spec...         1.00   \n",
       "704  The intended audience for IBM's vision and mis...         0.50   \n",
       "705  The target audience for IBM's educational and ...         0.00   \n",
       "\n",
       "     domain_specific_rubrics  \n",
       "0                          5  \n",
       "1                          5  \n",
       "2                          5  \n",
       "3                          5  \n",
       "4                          4  \n",
       "..                       ...  \n",
       "701                        4  \n",
       "702                        4  \n",
       "703                        4  \n",
       "704                        4  \n",
       "705                        2  \n",
       "\n",
       "[706 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results0 = results[result_pairs[0][0]].to_pandas()\n",
    "results0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama Stack:meta-llama/llama-3-3-70b-instruct LlamaIndex:meta-llama/llama-3-3-70b-instruct nv_accuracy\n",
      " Llama Stack:meta-llama/llama-3-3-70b-instruct     :     0.5089\n",
      " LlamaIndex:meta-llama/llama-3-3-70b-instruct      :     0.4851\n",
      " p_value                                           :     0.0634\n",
      "  p_value>=0.05 so this result is NOT statistically significant.\n",
      "  You can conclude that there is not enough data to tell which is better.\n",
      "  Note that this data includes 706 questions which typically produces a margin of error of around +/-3.8%.\n",
      "  So the two are probably roughly within that margin of error or so.\n",
      "Llama Stack:meta-llama/llama-3-3-70b-instruct LlamaIndex:meta-llama/llama-3-3-70b-instruct domain_specific_rubrics\n",
      " Llama Stack:meta-llama/llama-3-3-70b-instruct     :     4.0241\n",
      " LlamaIndex:meta-llama/llama-3-3-70b-instruct      :     3.9618\n",
      " p_value                                           :     0.1440\n",
      "  p_value>=0.05 so this result is NOT statistically significant.\n",
      "  You can conclude that there is not enough data to tell which is better.\n",
      "  Note that this data includes 706 questions which typically produces a margin of error of around +/-3.8%.\n",
      "  So the two are probably roughly within that margin of error or so.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for result_pair in result_pairs:\n",
    "    result_summary_for_metric = {}\n",
    "    for metric in metrics:\n",
    "        results0 = results[result_pair[0]].to_pandas()\n",
    "        results1 = results[result_pair[1]].to_pandas()\n",
    "\n",
    "        if subset_of_rows:\n",
    "            results0 = results0.iloc[subset_of_rows]\n",
    "            results1 = results1.iloc[subset_of_rows]\n",
    "\n",
    "        overview_label = f\"{result_pair[0]} {result_pair[1]} {metric.name}\"\n",
    "        _, p_value, score0, score1 = evaluation_utilities.print_stats_significance(results0[metric.name], results1[metric.name], overview_label, result_pair[0], result_pair[1])\n",
    "\n",
    "        result_summary_for_metric[metric.name] = {\n",
    "            result_pair[0]: float(score0),\n",
    "            result_pair[1]: float(score1),\n",
    "            \"p\": p_value\n",
    "        }\n",
    "    result_summary.append(result_summary_for_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data (706)\n",
      "Llama Stack:meta-llama/llama-3-3-70b-instruct LlamaIndex:meta-llama/llama-3-3-70b-instruct nv_accuracy\n",
      " Llama Stack:meta-llama/llama-3-3-70b-instruct     :     0.5089\n",
      " LlamaIndex:meta-llama/llama-3-3-70b-instruct      :     0.4851\n",
      " p_value                                           :     0.0520\n",
      "  p_value>=0.05 so this result is NOT statistically significant.\n",
      "  You can conclude that there is not enough data to tell which is better.\n",
      "  Note that this data includes 706 questions which typically produces a margin of error of around +/-3.8%.\n",
      "  So the two are probably roughly within that margin of error or so.\n",
      "Llama Stack:meta-llama/llama-3-3-70b-instruct LlamaIndex:meta-llama/llama-3-3-70b-instruct domain_specific_rubrics\n",
      " Llama Stack:meta-llama/llama-3-3-70b-instruct     :     4.0241\n",
      " LlamaIndex:meta-llama/llama-3-3-70b-instruct      :     3.9618\n",
      " p_value                                           :     0.1476\n",
      "  p_value>=0.05 so this result is NOT statistically significant.\n",
      "  You can conclude that there is not enough data to tell which is better.\n",
      "  Note that this data includes 706 questions which typically produces a margin of error of around +/-3.8%.\n",
      "  So the two are probably roughly within that margin of error or so.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'nv_accuracy': {'Llama Stack:meta-llama/llama-3-3-70b-instruct': 0.5088526912181303,\n",
       "   'LlamaIndex:meta-llama/llama-3-3-70b-instruct': 0.48512747875354106,\n",
       "   'p': 0.051994800519948},\n",
       "  'domain_specific_rubrics': {'Llama Stack:meta-llama/llama-3-3-70b-instruct': 4.024079320113314,\n",
       "   'LlamaIndex:meta-llama/llama-3-3-70b-instruct': 3.961756373937677,\n",
       "   'p': 0.14758524147585242}}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"All data ({len(results[next(iter(results.keys()))].to_pandas())})\")\n",
    "result_summary_all_rows = evaluation_utilities.report_results_with_significance(results, metrics)\n",
    "result_summary_all_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_utilities.write_excel(results, result_summary_all_rows, None, f\"report-lls-vs-li-{count}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-llscomp-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
